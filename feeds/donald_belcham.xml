<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Western Devs</title>
  
  <link href="/feeds/donald_belcham" rel="self" type="application/atom+xml"/>
  <link href="https://westerndevs.com" rel="alternate" type="application/atom+xml"/>
  
  <updated>2021-05-08T22:24:20.565Z</updated>
  <id>https://westerndevs.com/</id>
  
  <author>
    <name>Western Devs</name>
	<uri>https://westerndevs.com</uri>
    <email>info@westerndevs.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title type="html">Pi Day 2018</title>
    <link href="https://westerndevs.com/Development/PiDay/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/Development/PiDay/</id>
    <published>2018-03-14T13:00:00.000Z</published>
    <updated>2021-05-08T22:24:20.565Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p><img src="https://www.igloocoder.com/images/RPi-Logo.png" alt=""></p><p>I have a bunch of <a href="https://www.raspberrypi.org" target="_blank" rel="noopener">RaspberryPi devices</a> kicking around the house and office. There are some Pi 2s, Pi 3s, and a Pi Zero. I use them for a lot of different things. I just setup a Pi 3 to act as a scanning server for the <a href="http://www.fujitsu.com/uk/products/computing/peripheral/scanners/scansnap/ix500/" target="_blank" rel="noopener">Fujitsu iX500 ScanSnap</a> that we use to keep a paperless home. There's a Pi 2 running <a href="http://networkupstools.org/" target="_blank" rel="noopener">NUT</a>, some cron scripts, and some other admin stuff for my home network. We got a Pi Zero from an <a href="https://www.adafruit.com/adabox/" target="_blank" rel="noopener">Ada Box</a> that we setup to run <a href="https://retropie.org.uk/" target="_blank" rel="noopener">RetroPie</a>. While interesting, it's not overly complicated stuff. Places like <a href="https://www.youtube.com/watch?v=78H-4KqVvrg" target="_blank" rel="noopener">Los Alamos National Labratory use Raspberry Pis for prototyping their large systems</a>.</p><a id="more"></a><p>The versatility of the Raspberry Pi is undeniable. When my colleagues at Particular Software started working on a .NET Core version of NServiceBus I had to know; would NServiceBus run on the Pi? An hour of .NET Core research plus the <a href="https://docs.particular.net/samples/learning-transport/" target="_blank" rel="noopener">Learning Transport sample</a> and I had this</p><blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Step 2 complete: <a href="https://twitter.com/hashtag/NServiceBus?src=hash&amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener">#NServiceBus</a> running the Learning Transport in Docker on a RaspberryPi3. <a href="https://t.co/OixMIjWbCB" target="_blank" rel="noopener">pic.twitter.com/OixMIjWbCB</a></p>&mdash; Donald Belcham (@dbelcham) <a href="https://twitter.com/dbelcham/status/903418955989217280?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">September 1, 2017</a></blockquote><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><p>The only trick with it was that I had to <code>dotnet publish</code> using the <code>-r linux-arm</code> parameter.</p><p>This doesn't seem like much, but it can open up a lot of options for a team developing distributed apps. One of the biggest challenges for those teams is having a non-production environment that mimics the topology of the ultimate solution.. In my experience teams struggle with getting the infrastructure required to properly test. Servers are allocated by a different team. Once setup, the topology is fixed which makes it difficult for the team to experiment and/or adjust their architecture.</p><p>Now, what could you do with 8 Raspberry Pis if you were building a distributed system? Well you could have one running a database server (SQL Server, MySQL, and Postgres will all run on ARM hardware), one Pi could run your messaging system (RabbitMQ for example), and the rest could represent nodes for your distributed code. Great, but that's no different than using 8 VMs you say?</p><p>Unplug one of the distributed nodes. Just unplug it. Don't shut it down gracefully. With a Pi that's easy, you just reach for the plug and pull. With a VM it's a fair bit harder, and if you can the infrastructure folks will blow a gasket that you just did that to their precious, stable systems. This is really important in a distributed system though. How does your system handle uncontrolled shutdowns? How do you plan your recovery in that scenario? What if you just pull the network cable but leave the power on? How does recovery differ? What do your reporting tools tell you when this happens, and what do they tell you right after the problem is fixed?</p><p>There are a lot more moving parts in a distributed system which lead to a lot more disaster prevention and recovery needs. A collection of Raspberry Pis running as a testing or development environment gives you a great platform to simulate many of these situations. They don't allow you to do all your testing though. I'd never pretend that a setup of Pis would be adequate, or appropriate, for load testing a system.</p><p>Raspberry Pi is a great platform for prototyping (and more). Don't relegate it to just prototyping things you'd like to play with at home. They can be a huge tool for distributed system development too. Heck, if Los Alamos is using them, why can't you?</p><p>Happy Pi Day!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.igloocoder.com/images/RPi-Logo.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;I have a bunch of &lt;a href=&quot;https://www.raspberrypi.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RaspberryPi devices&lt;/a&gt; kicking around the house and office. There are some Pi 2s, Pi 3s, and a Pi Zero. I use them for a lot of different things. I just setup a Pi 3 to act as a scanning server for the &lt;a href=&quot;http://www.fujitsu.com/uk/products/computing/peripheral/scanners/scansnap/ix500/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Fujitsu iX500 ScanSnap&lt;/a&gt; that we use to keep a paperless home. There&#39;s a Pi 2 running &lt;a href=&quot;http://networkupstools.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NUT&lt;/a&gt;, some cron scripts, and some other admin stuff for my home network. We got a Pi Zero from an &lt;a href=&quot;https://www.adafruit.com/adabox/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Ada Box&lt;/a&gt; that we setup to run &lt;a href=&quot;https://retropie.org.uk/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RetroPie&lt;/a&gt;. While interesting, it&#39;s not overly complicated stuff. Places like &lt;a href=&quot;https://www.youtube.com/watch?v=78H-4KqVvrg&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Los Alamos National Labratory use Raspberry Pis for prototyping their large systems&lt;/a&gt;.&lt;/p&gt;
    
    </summary>
    
      <category term="Development" scheme="https://westerndevs.com/categories/Development/"/>
    
    
      <category term="RPi" scheme="https://westerndevs.com/tags/RPi/"/>
    
  </entry>
  
  <entry>
    <title type="html">Home Networking - Racking</title>
    <link href="https://westerndevs.com/Networking/Home-Networking-3/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/Networking/Home-Networking-3/</id>
    <published>2018-01-10T04:00:00.000Z</published>
    <updated>2021-05-08T22:24:20.565Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/raw-wiring.jpg"/><p>As you can see in the picture, I didn't just terminate cables in a mechanical room and mount a few pieces of hardware directly to a wall. Instead I got a wall mount rack to organize everything in. The rack I chose had to meet a few base criteria:</p><ul><li>standard <code>U</code> sizing so mounting equipment would be easy</li><li>significant number of <code>U</code>s to fit current and future equipment</li><li>easy open access for setup and maintenance</li><li>enough depth to accept the networking hardware I had chosen</li></ul><p>In the end I got a <a href="https://www.amazon.ca/Tripp-Lite-SRW08U22-2-Post-Cabinet/dp/B0041W55YE/ref=sr_1_6?ie=UTF8&amp;qid=1515542698&amp;sr=8-6&amp;keywords=wall+mount+rack" target="_blank" rel="noopener">Tripp Lite rack</a> that I could lag into some wall studs and fill with up to 150lbs of equipment. The one thing that is weak on this kind of solution is the cable management options. There are no cable raceways down the sides that you can use and third-party options are limited if they exist at all. If you look closely at the picture you can see that I ended up having to velcro strap the cable bundles to the rack posts and supports to be able to maintain some semblance of cabling hygiene.</p><p>Getting the rack setup was pretty easy, but I did run into one issue that slowed me down. The rack has threaded holes for mounting, not holes for cage nuts. The threaded holes are ever so slightly smaller than those in cage nuts which made it impossible to use the bolts that came with most of the hardware I was mounting. If I were to do this again, I'd make the effort (and pay the necessary price) to get a wall rack that used cage nuts.</p><p>In addition to mounting the rack on the wall I had the electricians (who pulled all my Cat6 cabling) put two plugs on the all behind the rack. The plugs are on separate circuits for future expansion and/or high draw equipment. As of now, I only need one but I did not want to have to watch someone pounding nails or running screws behind my rack in the future. I'll cover the whole power system in another post, but safe to say it's not just a bunch of wall-warts plugged into power bars.</p><p>The last pieces added to the rack were accessories; horizontal cable management, shelves, and blank face plates. Of those, probably the only truly necessary items were the shelves. I have one mounted at the top of the rack that holds all of my ISP's hardware. I wanted to keep that crap isolated. The other shelf is mounted near the bottom of the rack and holds a collection of Raspberry Pi computers that I use for various things.</p><img src="https://www.igloocoder.com/images/rack-layout.jpg"/><p>I spent a lot of time planning how to fill the rack. I didn't want network wires running all over the place, and I didn't want a mess of power cables either. In fact, I decided early on that I didn't want the networking and power cables to intermingle at all. The best tool that I found for doing this was Google Sheets (or Excel if you must). The diagram above shows the plan that I came up with to meet those goals.</p><p>When I started the process of building this infrastructure, I figured getting the rack mounted was going to be one of the easier tasks. It turned out not to be hard, but to be quite time consuming as I searched for the best setup.</p>]]></content>
    
    <summary type="html">
    
      I didn&#39;t just terminate cables in a mechanical room and mount a few pieces of hardware directly to a wall. Instead I got a wall mount rack to organize everything in.
    
    </summary>
    
      <category term="Networking" scheme="https://westerndevs.com/categories/Networking/"/>
    
    
      <category term="networking" scheme="https://westerndevs.com/tags/networking/"/>
    
  </entry>
  
  <entry>
    <title type="html">Home Networking - Cabling</title>
    <link href="https://westerndevs.com/Networking/Home-Networking-2/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/Networking/Home-Networking-2/</id>
    <published>2017-10-03T03:00:00.000Z</published>
    <updated>2021-05-08T22:24:20.565Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/raw-wiring.jpg"/><p>One of the things that I knew I wanted to do with this home network was run cables to as many places as possible. Some were non-negotiable:</p><ul><li>the office needed multiple drops (8 in the end)</li><li>the TV areas needed multiple drops</li><li>each of the wireless access points needed a drop</li></ul><p>I really didn't want to deal with pulling the cable into some of those areas. Hanging out in the attic wasn't way up on my list of fun things. And, to be honest, I had no clue how I was going to get cables from the main house into the attached in-law suite. So I called the local electrician. I needed a couple of circuits to power the equipment in the server rack so it seemed like something that would make sense to bundle together.</p><p>This was the best option. The electrician and his helper pulled about 1700 feet of Cat6 cable for me. Some were my required cables and a few were extras that they pulled to the attics so that I had extra capacity when I need it. They spent a bunch of time in the heat of the attic. They also pulled cables into wall cavities so that it looks like the house has always had Cat6.</p><p>All of the cable drops were pulled to the area that I was going to put the server racks. All of this is pretty basic stuff, but I did do one thing different than I did in my last house; I didn't cut the cables short on the rack end. Instead I terminated them into Cat6 female keystone jacks as close to the ends as possible.</p><p>This left a lot of extra cable by the rack. And that's fine. Heck, in the end I had to re-terminate a handful of the cables because I screwed them up or did them poorly.</p><blockquote><p>NOTE: It's worth buying a proper punch down tool if you're going to go do your own ends. Between my patch panel and the wall plates around the house I terminated about 50 keystones.</p></blockquote><p>So what do you do with all that excess cable? You dress it of course. If you've never seen well dressed network cables, you need to spend a bit of time over at <a href="/r/cableporn">https://cableporn.reddit.com</a>. I hate messy cables. It could be my desk, behind the TV, or my networking stuff, so the people of /r/cableporn have a dear place in my heart.</p><p>I dressed all the excess cables into what's known as a &quot;service loop&quot;. The loop provides you with an excess of cable really close to the rack. If you have to fix terminations you have extra cable that you can use. This was something that I didn't have at the old house and it almost bit me in the ass. So now I have a service loop attached right to the rack which gives me about 4-5 ft of extra cable.</p><blockquote><p>I had so much excess cable that I ended up with a second service loop that has about 8ft of cable in it too...so I should never have short cable problems.</p></blockquote><p>Having a service loop is great, but having a messy one is almost as bad as not having one at all. I bundled up all of the cables in the service loop using <a href="https://www.amazon.ca/gp/product/B001E1Y5O6/ref=oh_aui_detailpage_o00_s00?ie=UTF8&amp;psc=1" target="_blank" rel="noopener">velcro straps</a>. Not zip ties, velcro straps. You can easily undo them and move cables as needed. With zip ties I'd have to cut them and add new ones every time. It's also possible to over tighten a zip tie and end up cutting into the cabling...not good. Velcro straps were the right choice based on the amount of times that I had to loosen them to move cables.</p><img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/rack-loop.jpg"/><p>I probably could have bundled the cables better if I'd used a <a href="https://www.amazon.ca/ACOM-PIECE-CONTRACTOR-INSTALLATION-YELLOW/dp/B01BTUI1TQ/ref=sr_1_1?ie=UTF8&amp;qid=1501120387&amp;sr=8-1&amp;keywords=cable+comb" target="_blank" rel="noopener">cable comb</a>, but for the amount of cables that I had I didn't think buying one was worth it.</p><p>The only other Cat6 cable work that I did was to make a bunch of short cables to go between the patch panel and the switch. Yah, I probably could have bought them and saved myself a bunch of time. I needed something to do in my evenings, and getting them the exact length that I wanted would make the front of the panel look a little better too.</p><p>So all that Cat6 cable management is great, but there are other cables in my rack area that needed to be managed too. The switches, routers, UPS, power distribution, etc all had power cables. Instead of running them all over the place to get them plugged in, I bundled them up too. I didn't bundle them with the Cat6 though. Power cables can cause interference in unshielded network cabling. So with the Cat6 service loop attached to one side of the rack, I bundled the power cables and ran them along the other side of the rack.</p><p>So cabling was important, and maybe I went a bit overboard on it for a house. I should never have issues with the cables I have, and if I do I have extra cable in the service loops to fix it. I have an organized rack cabling solution that makes it really easy to trace and replace/fix cables as required. It's also really easy to move things around, change ports being used, or completely remove hardware as needed.</p><p>Put some time into planning your cable needs, some effort into installing them, and some patience into organizing them. The end result will pay off.</p>]]></content>
    
    <summary type="html">
    
      One of the things that I knew I wanted to do with this home network was run cables to as many places as possible
    
    </summary>
    
      <category term="Networking" scheme="https://westerndevs.com/categories/Networking/"/>
    
    
      <category term="networking" scheme="https://westerndevs.com/tags/networking/"/>
    
  </entry>
  
  <entry>
    <title type="html">Home Networking - What and Why</title>
    <link href="https://westerndevs.com/Networking/Home-Networking-1/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/Networking/Home-Networking-1/</id>
    <published>2017-07-03T00:00:00.000Z</published>
    <updated>2021-05-08T22:24:20.565Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/network-cables.jpg"/><p>Late last year we moved into a new house. Leaving the other house was tough, and not just because I had built out a <a href="https://www.igloocoder.com/2014/03/25/A-solid-foundation/" target="_blank" rel="noopener">fairly good networking solution</a> for it. Moving into the new house meant a new internet provider and the standard installation of home networking gear that exists in (hundreds of) thousands of houses throughout North America. Not only did we have crap hardward, the installer obviously had taken the path of least resistence when running the wire from the street and locating it in the house. The best part of the installation was that the wire from the street entered into the mechanical room. The install or previous owners had also run a small mess of Cat5 to get from the mechanical room to a central location where the ISP's router was expected to be located. From that location, they had run more wire to an &quot;office&quot; room in another part of the house.</p><p>This setup wasn't a bad one, but it did have it's limitations. The main router had to sit along a wall in the eating area of the kitchen. That router was also the single wireless access point in the house. ISP provided hardware being what it is (substandard at best), the wifi wasn't stable and, in some locations of the house, there was no identifiable signal. The first 6 months living in the new house have been filled with a host of first world problems. But, being the first world, we had solutions at our disposal.</p><h3>Past experience</h3><p>Our old home had similar issues and I solved many of them, but I also introduced a few different problems along the way. At it's roots that house used a Rosewill gigabit switch and a handful of DD-WRT powered routers. If nothing else, these devices were stable...after I solved the long-running issue of random router reboots that, ultimately, were being caused by a loose power plug.</p><p>Probably the biggest ongoing problem in that house was wifi handoffs. There was one DD-WRT wireless access point on each of the three floors in the house. If I moved from the basement to the main floor, my phone (or other device) would stay connected to the basement access point...even if the signal strength dropped to barely noticeable levels. The result was that you could be standing right next to an access point but you wouldn't be connected to it and you'd likely be suffering from a poor connection to another access point. Definitely not a good thing in a house of highly connected and frequently moving people.</p><p>There were a number of things that I really liked about the physical setup in that house, and I knew that I needed to carry them forward to the new one. One of those was the use of a patch panel where all of the wired connections in the house terminated. Being able to easily interact with the different locations throughout the house was a godsend many times. I added more than just the network cables to the patch panel. Using a Keystone based panel I was able to have all of the Cat5e cables in the panel, the coaxial cables and the phone lines all in that one place. Interestingly, I benefited from the patch panel flexibility more times with the coax and phone lines than I did with the network cables.</p><p>One of the other nice thing was the use of a <a href="https://www.amazon.ca/StarTech-com-RKPW081915-19-Inch-Rackmount-Distribution/dp/B0035PS5AE/ref=sr_1_4?ie=UTF8&amp;qid=1493169057&amp;sr=8-4&amp;keywords=rack+pdu" target="_blank" rel="noopener">PDU in the rack</a>. Instead of having multiple powered devices all searching for a wall plug and, ultimately, resorting to some kind of consumer power bar, I was able to nicely organize the power distribution.</p><p>The final &quot;must have&quot; that I learned in the old house was the use of a wall mount rack. Originally I had aspirations of using a 48U free standing rack for my networking and entertainment needs. Realistically I didn't need that much space. It wasn't just the vertical space of the free standing rack that was overkill, but also the depth. Most rack mount networking hardware doesn't need more than 20 inches of depth. A good wall mount rack can easily provide the depth required. A rack also saves you from having a bunch of crappy shelves holding one-off hardware and a tangle of cables. For me, a wall-mount rack was a must-have.</p><p>I did a lot of good things in the old house. I did a number of bad things too. My only goal was making home-network-v2 better than its predecessor.</p><h3>Needs</h3><img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/MaslowsHierarchyOfNeeds.jpg"/><p>Obviously there were things I thought we needed in our new house network. They weren't &quot;needs&quot; in the same sense as <a href="https://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs" target="_blank" rel="noopener">Maslow's Hierarchy</a>, but they sure felt important to me.</p><p>Top of the list, which I was constantly hearing about from the other people in the house, was strong, stable WiFi that covered all the areas we used around the house, the inlaw suite and the pool. The longer I waited to build this network, the more I was being reminded of how important this was to the other people in the house.</p><p>I also wanted to setup a good infrastructure base to build from. Strong hardware, good cable management and room for expansion. The expansion part was key. I have lots of plans.</p><h3>Wants</h3><p>There are a lot of things that I want to do with a home network. A big one is supporting my desire to build a full sensor network to track things like water spills/leaks, windows, doors, and many other things. One of the biggest issues with adding those features to a house is that the sensor devices require power. The easiest solution to that was a PoE capable switch and a full 48 ports.</p><p>I also really wanted to completely eliminate all of the ISP provided hardware. The WiFi on it sucks, it reboots randomly and I have little or no control over the patching of it. The biggest challenge here is that the ISP router also provides our TV service.</p><p>One of the goals with moving to this new house was for me to spend some more time in a workshop making sawdust. I'd love to be 100% disconnected while doing that, but the reality is that I do a lot of research/learning about woodworking online. Some internet connectivity in my shop, which is about 150 feet from the house, was pretty high up on my list.</p><h3>Dreams</h3><p>We all have them: plans for our &quot;ideal&quot; network. The platinum plated solution. I'm definitely not immune to this.</p><p>One of the things I hate the most about the default ISP provided solution is that all of the TV set-top boxes get their signals via WiFi. Obviously, the farther from the base unit, the more walls, bad weather, invisible temporary Faraday Cage's, days that end in 'Y' and other things will cause instability in the TV signals. I really wanted to get rid of this and go to a wired solution so that I would know that the TVs would all work whenever I needed to binge watch <s>Master Chef Junior</s> The Expanse. This is <em>not</em> a normal way to configure this provider's TV sytems.</p><p>Another dream was to setup the telephone wiring in a patch panel like I had done at the old house. This might seem like a simple thing to do, but you haven't seen the wiring in the new house. It's a 40+ year old place that has had low voltage wiring cobbled together through its life. Getting all of the different phone jacks routed back to a central location was going to be no small task.</p><h3>Thinking and Planning and Thinking</h3><p>I spent somewhere between 4 and 6 months formulating ideas, prioritizing them, re-thinking possible solutions and scrapping some of them. It was probably one of the best things that I could have done. Instead of rushing into any solution that looked and felt better than what was available when we moved in, I lived with what we had (much to the chagrin of the other WiFi users in the house). I didn't just go out and buy the hardware I thought I needed. I thought through the problem area, researched options, considered if the problem really would exist, looked for alternatives and then re-thought everything.</p><p>I discovered a lot of problems that I would have overlooked if I'd moved faster. Things like the importance of having system management solutions when you're using enterprise level hardware. I found a lot of hardware solutions that I didn't know existed. One of those was front and back cable management trays. I also scrapped a few ideas, like running a buried strand of fiber from the house to the garage.</p><p>There were a few adjustments and ideas that did surface that I couldn't ignore though.</p><h3>Adjustments</h3><img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/deskphone.jpg"/><p>Our new house has the main living quarters and an attached in-law suite. When people are staying in the suite the only way to communicate with them is to walk to their door and knock or to call their cell phones. Since that space isn't going to be occupied full time, installing a separate land-line isn't a good option. I did, however, run across some information on open source VoIP solutions. All I needed was a PoE powered data line and I could put a phone anywhere in the house, inlaw suite or the garage. While not a &quot;need&quot; or a &quot;want&quot;, this idea is certainly on the &quot;dreams&quot; list and likely will happen at some point in the future.</p><p>Another problem that I struggled to solve was how I could monitor people who came to the door of the inlaw suite. It is situated such that I can't see the door or the driveway from any part of the main house. I looked at some IoT-ish video doorbells, but none of them gave me the warm and fuzzies. One night I went down a rabbit hole around IP based video monitoring systems. Not only could I see who was knocking at the door, but I could also put some eyes on other parts of the yard like the detatched garage and the pool. IP based video was not just going to get added to the list or requirements, but it was going to apparear at the &quot;want&quot; level.</p><p>I read a lot of forums as I did research for this project. One night while looking for something completely unrelated I stumbled across a conversation that had an off-hand comment about the UPS that my ISP provides for some of their hardware. It turns out that the way this UPS is connected to the hardware, it only powered the phone functionality when it was running on the battery. That meant that all internet would be cutoff immediately when the power went out...even if there still was signal in the fibre lines. Prior to this little bit of information I had only intended on using a PDU in the rack. A quick trip to Amazon and I was expecting delivery of a 1U UPS that could provide battery backup to the UPS that provides battery backup to the ISP hardware. Because daddy can't be without his internet when the power bumps.</p><h3>Filled to overflowing</h3><p>Our new house has a very nice wood burning fireplace in it, and I spent the better part of the winter sitting by it reading and researching all things networking. It was fun to spend time looking at concepts and problem areas that I used to work with early in my career. I'm not sure if it is the variety of new (to me) hardware and software, or the prospect of building v2 of something, but either way it is something that I was energized by.</p><p>Some of the other Western Devs have asked that I publish a bunch of content around this project, so this is just the first of many.</p>]]></content>
    
    <summary type="html">
    
      Moving into the new house meant a new internet provider and the standard installation of home networking gear that exists in (hundreds of) thousands of houses throughout North America
    
    </summary>
    
      <category term="Networking" scheme="https://westerndevs.com/categories/Networking/"/>
    
    
      <category term="networking" scheme="https://westerndevs.com/tags/networking/"/>
    
  </entry>
  
  <entry>
    <title type="html">Issues are not free</title>
    <link href="https://westerndevs.com/_/Issues-are-not-cheap/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/Issues-are-not-cheap/</id>
    <published>2017-03-14T02:00:00.000Z</published>
    <updated>2021-05-08T22:24:20.561Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>At <a href="https://particular.net/" target="_blank" rel="noopener">Particular Software</a> we manage all of our work flow using <a href="https://github.com/" target="_blank" rel="noopener">Github</a> repositories and the issues in them. These issues are what drive our work day-to-day, week-to-week and all the way into longer periods of time like years. If an issue doesn't exist for a topic, that topic doesn't exist within the organization.</p><p>A while back I declared in a meeting that &quot;Issues are cheap&quot;. The context around the comment was such that I was suggesting that we can just create more issues when we need to surface a topic. If that issue goes away (closed, lost, whatever) and the topic surfaces again, create another issue. It's cheap...all you have to do is a bit of typing.</p><p>My comment was met with the statement that, in fact, issues are not cheap. At first I was taken aback. My little world was being shaken by this statement. How could an issue not be cheap? It took mere minutes to create one. We don't get charged for disk space or issue count by Github. The person that made that comment went on to clarify their position by saying that &quot;Ideas are cheap&quot;.</p><p>I forget what the rest of that meeting was about. My mind was racing to rationalize this distinction. In my world issues and ideas were one and the same. But in this person's world they were clearly different. And it turns out they are right.</p><p>Ideas are the nascent concept that is represented within an issue. The issue is just the envelope that carries the message. Like a letter, the cost of writing a partially formed idea onto paper is trivial. A few minutes of your time, a pen and paper. This is cheap.</p><p>Unlike the writing on the paper however, envelopes have a lifetime cost associate with them. Mail needs to be picked up, transported, sorted, transported again, and delivered. Issues have this cost too. They must be triaged, prioritized, backlogged, re-prioritized, worked on, closed and retrospected on.</p><p>When you think about it from that standpoint, issues are <em>really</em> expensive. The thought that you can just create an issue doesn't remove the fact that they will incur a cost throughout their lifetime.</p><p>Probably the most insidious type of issue is the drive-by one. You get an idea, you create an issue and you just keep right on moving. You don't spend any time curating that idea, but instead push that workload to other people. Not only are you creating an expense for your process, but you're asking other people to pay it off for you. I had a roommate like that once. I'm sure you know how that ended.</p><p>It's important to remember that there can be hidden costs in the actions that we take. This was a bit of an eye opener to me. Having ideas isn't a bad thing. Spending the time to make the well formed so that they carry value that warrants the effort that they will require as issues is a good first step.</p>]]></content>
    
    <summary type="html">
    
      Thoughts about the hidden costs of actions
    
    </summary>
    
    
      <category term="process" scheme="https://westerndevs.com/tags/process/"/>
    
  </entry>
  
  <entry>
    <title type="html">Prairie Dev Con 2016 Wrapup</title>
    <link href="https://westerndevs.com/conferences/PrDC-Wrapup-DB/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/conferences/PrDC-Wrapup-DB/</id>
    <published>2016-04-18T17:56:56.000Z</published>
    <updated>2021-05-08T22:24:20.561Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p><img src="http://content.igloocoder.com/images/PrDCLogo_Small.png" alt=""><br>Last week I spoke at Prairie Dev Con in wonderful Winnipeg and while the city lived up to it's moniker of &quot;Winterpeg&quot;, the conference was fantastic!</p><p>I noticed that there was a lot of buzz around microservices and distributed systems at the conference this year. It seemed like there were endless conversations happening in the halls and at meals about the topic. While there were a lot of sessions that touched on the topic, or topics in the same space, there were a lot of areas that went untouched. For those that missed my sessions or those that are looking for a refresher here are the slide decks.</p><h3>Slides</h3><iframe src="//www.slideshare.net/slideshow/embed_code/key/uQ4xqsIBJy8nHM" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/igloocoder/microservices-a-gentle-introduction" title="Microservices: A Gentle Introduction" target="_blank">Microservices: A Gentle Introduction</a> </strong> </div><iframe src="//www.slideshare.net/slideshow/embed_code/key/K2ur1a17XwPhmQ" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/igloocoder/microservices-the-nitty-gritty" title="Microservices: The Nitty Gritty" target="_blank">Microservices: The Nitty Gritty</a> </strong>  </div><h3>Additional materials</h3><p>If you're interested in diving deeper into microservices I have a Github repo that contains all the articles and videos that I've absorbed in the last year. If you find materials that are missing please send me a pull request. I'd love to read/watch more on the subject. <a href="https://github.com/dbelcham/microservice-material" target="_blank" rel="noopener">https://github.com/dbelcham/microservice-material</a></p>]]></content>
    
    <summary type="html">
    
      Slides and other materials from PrDC 2016
    
    </summary>
    
      <category term="conferences" scheme="https://westerndevs.com/categories/conferences/"/>
    
    
  </entry>
  
  <entry>
    <title type="html">Truly Ergonomic Keyboard</title>
    <link href="https://westerndevs.com/Ergonomics/truly-ergonomic-review/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/Ergonomics/truly-ergonomic-review/</id>
    <published>2016-03-19T21:25:28.000Z</published>
    <updated>2021-05-08T22:24:20.577Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Back in February I joined a bunch of the other WesternDevs to <a href="http://www.westerndevs.com/podcasts/Ergonomics/" target="_blank" rel="noopener">talk about Ergonomics</a> and one of the topics we touched on was ergonomic keyboards. As I said in the podcast, years ago when I worked on a factory line I got carpal tunnel really bad. Ever since I have to watch the peripherals that I use when I work for long periods on the computer. If I don't, and a good example of this is if I use a built in laptop keyboard for a two to three 8+ hour days in a row, I will get crippling pain in my fore-arm and elbow. Since I spent no less than 8 hours a day in front of a computer, choosing a keyboard and mouse combination is pretty important for me.</p><p>Historically I've used a <a href="https://www.amazon.ca/Microsoft-Comfort-Blue-Track-Desktop/dp/B002DY7M66/ref=sr_1_fkmr1_1?ie=UTF8&amp;qid=1458259452&amp;sr=8-1-fkmr1&amp;keywords=ms+wireless+comfort+5000" target="_blank" rel="noopener">Microsoft Wireless Comfort Keyboard 5000</a> and it has served me well. Make no mistake, this is <strong>not</strong> an ergonomic keyboard. It simply has a few keys in the middle that are wider than normal to provide a bit of a spread between your hands.</p><p>Fellow WesternDev <a href="http://www.westerndevs.com/bios/simon_timms/" target="_blank" rel="noopener">Simon Timms</a> makes use of a clickety-clackety keyboard and swears up and down by it's <a href="http://cherryamericas.com/product-category/keyswitch/" target="_blank" rel="noopener">Cherry keys</a>. Sure it makes him sound like he's got a teleprinter machine pumping out the news in the back of his office, but for some reason the idea of a mechanical keyboard appealed to me. I don't think I've had one since back in my 386 days.</p><p>After a bunch of research on ergonomic mechanical keyboards I settled on getting the <a href="https://www.trulyergonomic.com" target="_blank" rel="noopener">Truly Ergonomic Keyboard</a> (TEK). The only real decision you have to make when ordering is choosing between two models that have slightly different key layouts (double vs single keys in the lower corners of the keyboard).</p><p>The first two things that I noticed when the keyboard arrived were the size of it and the weight. The keyboard is narrower than the main keypad on the Comfort 5000 (note that the Comfort 5000 also has a number pad that the TEK doesn't). The TEK is about 1.5 times heavier than the Comfort 5000 which not only makes it feel more substantial, it also makes it harder to push it around on your desk surface.</p><p><img src="http://content.igloocoder.com/images/TEK_size_comparison.jpg" alt=""></p><p>Getting started with the TEK is no more difficult than plugging in the USB cord. There's no driver disk or software to install. Windows (10 in my case) recognized it straight away and I was off to the races....snail races that is.</p><p>Typing on the TEK takes a bit of getting used to if you're a touch typist. The first touch typing issue that I ran into was the different orientation of the keys on the keyboard. On traditional keyboards, the main four rows of keys are arranged in columns that are angled from the bottom right to the top left.</p><p><img src="http://content.igloocoder.com/images/traditional_ergo_finger_movement.jpg" alt=""></p><p>On the TEK the columns of keys converge at the top middle of the keyboard, similar in pattern to an upside down V. What this means for your transition to the TEK is that you'll constantly be reaching too far to the left when you move up from the home row and too far to the right when you move down from it. For me that meant that I was constantly reaching for the <code>B</code> key and, instead, getting the <code>Backspace</code> key (more about why it was the <code>Backspace</code> key shortly). There were other keys that I had similar problems on, but this was the most obvious since I was killing letters when I didn't want to.</p><p>The second transition issue that I had was the location of many of the keys. Instead of having dead space in the middle like many ergonomic keyboards have, the TEK fills that space with a number of commonly used secondary keys. <code>Windows | Command</code>, <code>Delete</code>, <code>-_</code>, <code>Backspace</code> (which I just hit again while trying to type <code>B</code>) and <code>Return</code> all reside in the middle. When you first look at the keyboard it's a novel layout. The <code>Spacebar</code> is split in two with the <code>Return</code> in the middle of them. The <code>Shift</code> and <code>Ctrl</code> keys also move up the keyboard by one row with <code>Ctrl</code> taking the places traditionally held by <code>CAPS</code> and <code>Return</code>. Getting used to <code>Return</code> being between the <code>Spacebars</code> was one of the tougher things for me at the start. I would type away and go to hit <code>Return</code> and get nothing....because I was actually pushing the <code>Ctrl</code> key. I have to say that having the <code>Return</code> key in the bottom middle of the keyboard between the <code>Spacebars</code> is a delight. I can't imagine why this isn't part of the standard layout.</p><p><img src="http://content.igloocoder.com/images/TEK_finger_movement.jpg" alt=""></p><p>The layout of the TEK does have some things that didn't initially work for me. As a developer I tend to use some of the secondary and tertiary keys pretty frequently. For example <code>{</code> and <code>}</code> are almost as common as <code>A</code> and <code>E</code>. Those two keys are not located on the far right one row above the home row. Instead they're on the complete opposite side of that row. I'm still working on getting fluent with typing those keys.</p><p>I also <code>Tab</code> a lot and I'm very used to using <code>Alt+Tab</code> and <code>Ctrl+Tab</code> to work my way through UIs. The <code>Tab</code> key is moved to the top left of the keyboard and is a single width key instead of the more traditional double width. Learning on a double width key made me very lazy in my finger placement when I was typing <code>Tab</code>. I learned fairly quickly to reach up a row to get to <code>Tab</code> but I couldn't gain the pinky finger control to both reach up and accurately push the right key and this really affected the speed of my keyboarding when working in code. Luckily TEK has a solution.</p><p>The TEK is fully programmable. Simply create your layout <a href="https://www.trulyergonomic.com/store/features/fully-programmable-in-firmware--truly-ergonomic-mechanical-keyboard" target="_blank" rel="noopener">on the website</a> and save a file that it will generate for you. Flip a DIP switch on the back of the keyboard and flash the new programming onto it. Now I have a <code>Tab</code> key in the middle of the keyboard between the <code>5</code> and <code>6</code>. Striking that 1.5x sized key with my index finger is much more accurate and fast. I reprogrammed the <code>CAPS</code> key so that it was reversed and <code>Insert</code> was the default with <code>Fn+CAPS</code> becoming the alternate. These are the only two tweaks that I've done thus far but it's nice to have this option if I notice inefficiencies in the future.</p><p>So far I'm very happy with the Truly Ergonomic Keyboard. The mechanical keys are a dream to type on and the layout feels as if it is more efficient (my typing speed is about the same as on a more traditional keyboard even though I'm still working on muscle memory). Most importantly I haven't yet noticed any hint of carpal pain which tells me that this keyboard is, at a minimum, no worse for me physically than what I was using before.</p><p>The biggest question you're all probably asking is if it's worth the (at the time of writing) $250 USD price tag. It's hard to say. I'm not disappointed with having spent that kind of money on it, but each to their own.</p><p>All images provided courtesy of <a href="http://www.trulyergonomic.com" target="_blank" rel="noopener">Truly Ergonomic</a></p>]]></content>
    
    <summary type="html">
    
      It was time for a new keyboard and I was looking for something mechanical and ergonomic.
    
    </summary>
    
      <category term="Ergonomics" scheme="https://westerndevs.com/categories/Ergonomics/"/>
    
    
      <category term="Ergonomics" scheme="https://westerndevs.com/tags/Ergonomics/"/>
    
      <category term="Office" scheme="https://westerndevs.com/tags/Office/"/>
    
  </entry>
  
  <entry>
    <title type="html">DDWRT and logentries</title>
    <link href="https://westerndevs.com/Networking/DDWRT-and-logentries/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/Networking/DDWRT-and-logentries/</id>
    <published>2016-02-17T04:10:46.000Z</published>
    <updated>2021-05-08T22:24:20.557Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I've had <a href="http://www.dd-wrt.com/site/index" target="_blank" rel="noopener" title="dd-wrt.com">DD-WRT</a> setup on all the routers/repeaters in my house for a few years now. The platform, generally, is great. It has it's quirks, and you're not going to get my mother to install and administer it on her home network. Overall, I think it works just fine for a guy like me though.</p><p>Over the last few months I've been seeing some intermittent stability issues. It seems that at the most random times the main router in the house will lock up and not respond to any pings. I have to then go downstairs, unplug the router for 30 seconds and plug it back in. By the time I'm back upstairs at my computer it's all working again.</p><p>Thus far the disconnections haven't happened during any meetings. When you work from home, having that happen would be a royal pain in the ass. As it is, going up and down the stairs during a train of thought is a complete pain in the ass so I've wanted to get to the bottom of it.</p><h3>Logging in DD-WRT</h3><p>By default logs for DD-WRT are stored in volatile memory. When you have to hard reset the router you, of course, lose those logs. This makes it really hard to track down the source of the problem.</p><p>An alternative is to log to the volatile memory location and then have a scheduled cron job to move those log files to an attached USB storage device. While this seems a bit better, you are never going to get the log entries that happened immediately before the router went down. There just isn't time for the cron job to run and it's on a schedule so it might not even be time for it to run.</p><p>A third option is to push the logging information to a remote server. Most examples out there show a configuration where the router is pushing the log entries to a computer on the internal network. This is all well and good, but I don't want to have to guarantee that my desktop/laptop is running to receive and archive that data.</p><p>Buried in <a href="https://www.dd-wrt.com/wiki/index.php/Logging_with_DD-WRT" target="_blank" rel="noopener" title="Logging with DD-WRT">a wiki page on logging</a> is mention of being able to log to a service called <a href="https://papertrailapp.com/" target="_blank" rel="noopener" title="papertrailapp.com">Papertrail</a>. This got me thinking; I've logged from my <a href="http://www.igloocoder.com/2015/04/09/Arduino-and-logging-to-the-cloud/" target="_blank" rel="noopener">Arduino and Netduino</a> to <a href="http://www.logentries.com" target="_blank" rel="noopener" title="logentries.com">logentries.com</a> before. Why couldn't I configure DD-WRT to do the same thing?</p><h3>Configuration</h3><p>There are three steps you need to do to get DD-WRT to log to logentries.com.</p><ol><li>Setup a Log Set and Log on logentries.com</li><li>Configure DD-WRT</li><li>Restart DD-WRT</li></ol><h5>logentries.com</h5><p>If you don't already have one, create an account with logentries.com for their <a href="https://logentries.com/pricing/" target="_blank" rel="noopener" title="logentries.com Pricing">Free Plan</a>. Once you're logged into the website, open the Logs tab. Then click the &quot;+ Add New&quot; button and select &quot;Add a log&quot;.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-1.png" alt=""></p><p>The will put you into the page where you select the type of logging source you're going to use. In the case of DD-WRT the logger is Syslogd so we select that one.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-2.png" alt=""></p><p>In the Configure screen you will want to add this Log to a Log Set. If you're new to logentries.com you'll want to select &quot;New Set&quot; and type a meaningful name in (i.e. Home Router). If you already have logs on logentries.com you may want to use an Existing Set.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-3.png" alt=""></p><p>The last step you need to take is to click on the &quot;Create Log Token&quot; button. This will open a bunch more information in a Configuration section of the same page.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-4.png" alt=""></p><p>The only thing you need to worry about at this time is what appears in the first command area. In my case it's telling me to use <code>*.* @@data.logentries.com:13630</code> which includes the endpoint information. This information is what you will need for configuring DD-WRT so don't ignore it.</p><p>After you take note of the endpoint, you can click the &quot;Finish &amp; View Log&quot; button. At this point your Log will be put into &quot;Discovery Mode&quot;. You have 15 minutes to make the first call to this endpoint to activate it. That call to the logentries.com endpoint needs to happen from the IP address of your router. This will configure the Log to only accept data from that IP address.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-5.png" alt=""></p><h5>DD-WRT</h5><p>Now that you have logentries.com configured you need to quickly move through the DD-WRT setup. Remember that you only have 15 minutes to get this done. It should be easy, but don't wander off to the bowels of YouTube to watch cat videos.</p><p>First step, log into your DD-WRT router's web interface and navigate to the Services tab.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-6.png" alt=""></p><p>Towards the bottom of that page you will find the System Log section. Enable Syslogd and enter the endpoint information that you got from logentries.com earlier. You will want to ignore the <code>*.* @@</code> and only use the <code>data.logentries.com:XXXXX</code> portion, where XXXXX is the port that you were assigned.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-7.png" alt=""></p><p>Once you have this done, click Apply Settings followed by the Save button. After you've added the settings you can click the Reboot Router button and wait for your router to come back online.</p><p>Once your router has come back online and you have internet access you should be able to go to logentries.com and see that the &quot;Discovery on Port XXXXX&quot; has changed to show the IP address of your router. When I did mine it took a couple of minutes for logentries.com to process in the incoming messages and make this change. If you don't see the IP address then you weren't successful in connecting your router to logentries.com. I didn't have the happen so the only suggestion I can give you is to verify that the Syslogd settings in DD-WRT were saved and then do a reboot of the router again.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-8.png" alt=""></p><p>Once you have successfully connected the two systems you should be able to open the Log for your router and see the logging that occurs when it goes through it's startup process.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-9.png" alt=""></p><p>You could stop at this point and have all your system logging taken care of. But you can go one step further and enable firewall logging if you want. Note that when I tried this it made my router horrifically unstable and I had to completely disable it to get more than 5 consecutive minutes of uptime.<br>Open the Security | Firewall tabs and look to the bottom of the page. There, you will see a section for Log Management. Click Enable and set up the log levels and options as you desire.</p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-10.png" alt=""></p><p><img src="http://content.igloocoder.com/images/ddwrt-logentries-11.png" alt=""></p><h3>Conclusion</h3><p>Setting up DD-WRT and logentries.com isn't very difficult. DD-WRT can be a bit persnickety but otherwise it's a straight forward endeavour. Things you should note about this configuration:</p><ul><li>if your internet goes down you don't get logging</li><li>I've not had my router freeze up since doing this so I'm not sure what, if anything, I'll capture</li><li>if you only configure and run the Syslogd logging you will not get much activity in the log file</li></ul><p>When my router craps out on me again I'll post something about what I saw, or didn't see, in the log files.</p>]]></content>
    
    <summary type="html">
    
      Logging DD-WRT system entries to the cloud
    
    </summary>
    
      <category term="Networking" scheme="https://westerndevs.com/categories/Networking/"/>
    
    
      <category term="Networking" scheme="https://westerndevs.com/tags/Networking/"/>
    
  </entry>
  
  <entry>
    <title type="html">Microservice Sizing</title>
    <link href="https://westerndevs.com/_/microservices-sizing/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/microservices-sizing/</id>
    <published>2015-10-12T20:01:34.000Z</published>
    <updated>2021-05-08T22:24:20.577Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>As I mentioned in my last blog post (<a href="http://www.westerndevs.com/microservices-and-boundaries/" target="_blank" rel="noopener">Microservices and Boundaries</a>), I regularly see the question &quot;How big should my microservice be?&quot; The fast answer, albeit not the easy one, is that they should be the 'right' size. In that last blog post I talked about getting the right functionality into the right places (Antel for phone related functionality, Abitab for payment related functionality). There are a lot of people giving a lot of advise about scoping microservices, and I disagree with the majority of it. Here are some of the suggestions I've seen.</p><a id="more"></a><h2>One Week's Work</h2><p>This scoping idea follows the premise that any microservice that you make should only take one week to write. There's no discussion about the difficulty of the task at hand, the proper encapsulation, what the bounded context is or what the velocity of your development team is. Without fail, every one of your microservices should fit into a work week.</p><p>My question is what if the work isn't done at the end of one week? I was once told that at that point you should throw it away and start over with a smaller scope. I'm not sure about you but to me that is about as wasteful as you could be. Run into a problem with a third party API that you can't get resolved in a week? Scrap that work and start again.</p><p>Don't think that what I'm saying is that we should allow our teams to take months to build microservices. We should be able to iterate on them quickly. This is one of the biggest benefits of taking the microservices approach. I think that the approach to writing your microservices should be one of Minimum Viable Product (MVP). If you write the bare minimum to have a functioning product, you will minimize the time spent on it. If the problem space is well bounded you will likely be working on microservices for very short periods of time. You shouldn't, however, set an arbitrary timebox as a means to scope the work.</p><h2>X Number of Lines</h2><p>I can't count the number of times that I've heard/read &quot;your microservice should be no more than X lines of code.&quot; Usually the value of X is absurdly small, even for the most terse programming languages. Common numbers I've seen thrown around are 250, 100 and 10. Yes, 10. Can you imagine trying to write a 10 line microservice that does everything that I explained that Antel was doing in my previous post? Of course not. You couldn't even write the business logic for that process let alone all the infrastructure code that would be required (transactioning, logging, diagnostics) to create a healthy and sustainable microservice (more on this in a future post).</p><p>Long ago we decided that LoC was a horrible metric for measuring anything to do with software development. Why would we introduce it again? The number of Lines of Code required for a microservice will only be known once all the functionality has been written. Sure, you might be able to shrink that count with some judicious refactoring, but you're not going to change 1500 lines of code into 100. If you can I'd suggest that you have a bigger cultural, or staffing, issue at hand.</p><h2>Two Pizza Team</h2><p>I <em>hate</em> this metric. I've seen it pop up in so many different discussions for so many different things. First, why pizza? Are we just a bunch of frat kids that haven't let our culinary preferences evolve? Second, have you seen the size of pizzas in some countries (looking at you United States of Gluttony)? You could feed a batallion with two large pizzas. Third, what if you can't decide on only two combinations of toppings? Sure you could get half-and-half done, but there's only so combinations you can request before the pizza joint hangs up on you.</p><p>More importantly I'd like to ask what does this metric prove? Focus on technical and team structure concerns when you think about that. The only thing that I can think of is that it could cap the size of the team. What does that mean for code? Lower overall velocity? Maybe, but that is probably more influenced by the quality of the individuals on the team.</p><h2>Summary</h2><p>I'm a firm believer in working on microservices based on bounded contexts and minimum viable products. I don't need some catchy phrase telling me how I need to staff up my team or plan my work. Instead I know that I need to invest time into understanding my problem and setting expectations on the work.Just like microservices aren't a panacea for software development, none of these are for sizing your microservices.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;As I mentioned in my last blog post (&lt;a href=&quot;http://www.westerndevs.com/microservices-and-boundaries/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Microservices and Boundaries&lt;/a&gt;), I regularly see the question &amp;quot;How big should my microservice be?&amp;quot; The fast answer, albeit not the easy one, is that they should be the &#39;right&#39; size. In that last blog post I talked about getting the right functionality into the right places (Antel for phone related functionality, Abitab for payment related functionality). There are a lot of people giving a lot of advise about scoping microservices, and I disagree with the majority of it. Here are some of the suggestions I&#39;ve seen.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Microservices and Boundaries</title>
    <link href="https://westerndevs.com/_/microservices-and-boundaries/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/microservices-and-boundaries/</id>
    <published>2015-09-29T23:30:00.000Z</published>
    <updated>2021-05-08T22:24:20.577Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>One of the most common questions I’ve been getting asked about microservices is “How big?” I was recently down in Montevideo Uruguay speaking at the <a href="http://www.netconf.uy" target="_blank" rel="noopener">.NetConf UY</a> Meetup speaking about microservices. As part of my vacation in Uruguay I wanted to get a local SIM card for my phone so that I would have data without relying on free WiFi. At the time I was getting the SIM and making things work it seemed like one of the most frustrating experiences I’ve ever had. Lots of running around, lots of wasted time. Once I got onto the plane home I started thinking about it in a different light.</p><a id="more"></a><p>Here’s the process I went through to get data on a SIM.</p><p><img src="http://farm6.staticflickr.com/5737/21313922360_6daa6624d8_m.jpg" alt="Antel"></p><p>First I went to an <a href="http://www.antel.com.uy/antel/" target="_blank" rel="noopener">ANTEL</a> store. ANTEL is the state owned telecom. It’s cheap, but like any good state company it has bureaucracy. I went into the store and the first stop is a concierge/secretary desk. Once I explained, through bad spanish and worse charades, what I wanted I was told that they would need my passport. Of course I didn’t have it so it was back to the hotel to get a passport. Back at the ANTEL store there was, of course, a new person manning the front desk so it was more bad spanish and Italian inspired charades. My request was understood and I was given a number and told to wait (Uruguay <em>loves</em> its number dispensers). About 5 minutes later I was called to a desk and the process of signing up begins.</p><p>After some furious keyboard smashing, and more horrible spanish on my part, I was told to go to the cashier to pay. I went across the lobby (really it’s all just one big room) and waited in line for the guy working the cashier wicket to finish with his mobile phone. I walk up and brutalize his native tongue. He looks at me, spins his chair around and pulls some paper off the printer. More furious keyboard smashing, a test of my rudimentary understanding of numbers in spanish and my payment was made. The hands me some paper and points me to another line and another wicket.</p><p>I line up once again and was called to the counter. I handed over the paperwork, the lady disappeared into the back room and re-appeared with the SIM card. A brief explanation of the phone number and security code and I was told I was done there. So I headed back over to the original gentleman that was helping me. At that point I was told that I was finished.</p><p>The SIM card went into the phone and I was connected to the ANTEL network…except I had no service. I couldn’t text, call or use data. I went back to the hotel where I had WiFi figuring that I needed to simply tweak some settings for the APN. An hour later I had changed the APN and still had nothing. At this point I gave up and called my friends at <a href="http://www.kzsoftworks.com/" target="_blank" rel="noopener">Kaizen Softworks</a>. Within a minute I was told that I needed to go visit a place called Abitab. Once there we could charge our phone number with money. So off I go to the local Abitab (which I luckily knew about since I changed money at it earlier in the day).</p><p><img src="http://farm6.staticflickr.com/5691/21490886762_0d42a67d7b_m.jpg" alt="Abitab"></p><p>I get to Abitab, go to a wicket, show them the paperwork with my phone number on it, tell them I want to put 400 pesos on the account and 3 minutes later I’m done. So now I have a SIM card, it has funds, but I still don’t have service. I needed to request a “plan” to use. Luckily when I was sitting in the hotel trying to figure out how to get service I found the magic code to do that. So I send an SMS to a predetermined number and boom….internet access.</p><p>There were a lot of steps in that process. More than what was needed some might say. If you think about it, there are good separation of concerns and lessons for microservices here. Let’s take a look at the process a different way.</p><p>ANTEL provides telecom services. I was a consumer (UI if you will) in need of those services so I reached out to their endpoints. From 40,000 feet this is a pretty standard microservice interaction. The first thing that the microservice required is that I authenticate myself (provide a passport). Once I’ve done that they start the process of creating a client record for me and putting in the purchase order for the SIM card. This is a pretty straight forward synchronous operation. In essence this is the code that runs in the controller of your REST WebAPI endpoint.</p><p><img src="http://farm1.staticflickr.com/584/21817801705_5f577c2843_z.jpg" alt="Image1"></p><p>When the purchase order is successfully created anyone that cares is notified. In this case the cashier is notified by having a print out appear on his printer. I’m also notified that I need to go to a new location to do more ‘stuff’. In technical terms an event was published onto some kind of service bus. The cashier subscribed to that event type and printed a purchase order. The original service that I contacted provided a URI as part of its result to me that I needed to navigate to. That URI pointed me to the cashier service.</p><p>Once I made payment to the cashier service it published a successful payment event onto a service bus. The cashier service also provided me with a URI to visit to get the SIM card, which was the new line-up. The fulfillment service listened to that event and when I made my request to them they provided me with the SIM card and a bunch of meta data to go with it.</p><p>Like a good little consumer (UI) I made a call final call to an endpoint (the original person I dealt with) to check to see if my transaction was complete.</p><p>After dealing with ANTEL I moved on to Abitab, or the payment services. I called on one of their endpoints to make a payment. Again, I need to provide “proof” of who I am. In this case the level of proof is lower; I only need to provide the account number I want to deposit money to. The fact is, I can deposit money to any account I want and the service isn’t going to complain. It’s not hurting anyone but me if I do it wrong. So to make this payment I provided the amount of the payment, the means of payment and the account the payment should be applied to. I got a receipt. That concludes my interaction with the payment service.</p><p>Behind the scenes the Abitab service sent a message to some ANTEL service that notified ANTEL that the account needed to have credit applied to it and how much that credit should be. This is a service-to-service communication. Abitab knows nothing about the functionality of Antel. All Abitab does is publish a message that an event (payment) occurred. Abitab doesn’t need to know if, when, or how Antel applies the credit to the account so there is no need for a confirmation message so it can use a messaging pattern effectively here.</p><p><img src="http://farm1.staticflickr.com/641/21817803695_c8444f341e_z.jpg" alt="Image2"></p><p>The separations of concerns in this case was very clear. One microservice (company) was responsible for all things phone related (SIM card, activation, etc) and another microservice was responsible for payments. If you’ve dealt with a system like this (Antel and Abitab) you’ll know that there are some significant benefits from this separation. First, and foremost, you can pay anything imaginable at Abitab. Need to pay your water bill? Go to Abitab. You TV bill? Go to Abitab. All Abitab does is take the payment and send a message to the company concerned tell them that a payment has been received.</p><p>When you’re writing microservices you need to look at the responsibilities and concerns of the services.  They need to be well encapsulated but also single-y responsible. If it feels like one microservice needs the functionality of another, look at ways to communicate between them. Ideally this communication should be unidirectional and in the form of commands. By taking this approach you will create microservices that do not effect each other in deployment, down(up)-time or changes.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;One of the most common questions I’ve been getting asked about microservices is “How big?” I was recently down in Montevideo Uruguay speaking at the &lt;a href=&quot;http://www.netconf.uy&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;.NetConf UY&lt;/a&gt; Meetup speaking about microservices. As part of my vacation in Uruguay I wanted to get a local SIM card for my phone so that I would have data without relying on free WiFi. At the time I was getting the SIM and making things work it seemed like one of the most frustrating experiences I’ve ever had. Lots of running around, lots of wasted time. Once I got onto the plane home I started thinking about it in a different light.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Task could not find sgen.exe using SdkToolPath</title>
    <link href="https://westerndevs.com/_/sgen-not-found/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/sgen-not-found/</id>
    <published>2015-09-18T02:20:00.000Z</published>
    <updated>2021-05-08T22:24:20.577Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I spent the better part of this afternoon fighting with this error (and arguing Canadian voting rights with the <a href="http://www.westerndevs.com" target="_blank" rel="noopener">Western Devs</a>). I was trying to run our project’s build script which uses nAnt and MSBuild to work all the compilation magic we need. There are a lot of pieces of information on how to solve this on the web. Most solutions revolve around <em>&quot;Install Visual Studio 2010&quot;</em>, <em>&quot;Install the Windows Software Development Kit for Windows X&quot;</em>, or <em>&quot;Turn off the generation of serialization assemblies in your projects/solution&quot;</em>. Some of these are just downright scary solutions…others won’t work in my situation.</p><a id="more"></a><p>I do almost all of my development work in Azure VMs these days. I can spin up a new one with Visual Studio already installed in minutes. This allows me to easily and quickly keep all of my different clients and projects in isolated buckets. So for one of my current projects I created a Windows 2012 R2 + Visual Studio 2015 VM. This is the VM that started throwing the above error. So when I asked the all knowing Google (and its smarter friend StackOverflow) I was perplexed by those three common solutions that I was finding.</p><ul><li><strong>Install Visual Studio 2010</strong> – ummmm….no. Why should I need to do that?</li><li><strong>Install the Windows SDK</strong> – there really isn’t one for Windows 2012.</li><li><strong>Turn of generation of serialization assemblies</strong> – I have no idea if this project needs them or not so I’m not willing to make that change</li></ul><p>This left me to piece together a solution on my own…which is likely why it took all afternoon. After looking through all the information that was buried in comments on answers for issues on StackOverflow, I managed to come up with this:</p><p>Open up regedit on your computer. You’re not going to change anything so just calm down. Navigate to <strong>Computer\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\MSBuild\ToolsVersions\4.0</strong></p><p><img src="http://farm6.staticflickr.com/5618/21309498739_f91817e2d6_z.jpg" alt="Step 1"></p><p>Note the <strong>SDK40ToolsPath</strong> entry and the value for it. This value will point to another registry key which you need to go find next. It’s likely going to point at something that starts with *<em>Computer\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows*</em></p><p><img src="http://farm6.staticflickr.com/5727/21309498889_112153e5f6_z.jpg" alt="Step 2"></p><p>As you can see here there’s an InstallationFolder key that has a file path for you to go find in Windows Explorer.</p><p><img src="http://farm1.staticflickr.com/757/21308591438_fbc2579c84_z.jpg" alt="Step 3"></p><p>When you get to that folder you’ll probably see what I saw above…no sgen.exe file. This is what the problem is. MSBuild is looking for sgen.exe in this location and can’t find it. How do you fix that? You could change registry settings, but there is risk in that…and I told you earlier that you wouldn’t have to. Another option is to find a copy of sgen.exe and put it in that folder. From what I can tell sgen.exe is pretty stand alone and any version you find should work. I went to a slightly newer SDK version on my machine and copied the file from there.</p><p><img src="http://farm1.staticflickr.com/700/21470168646_90a88cf5b3_z.jpg" alt="Step 4"></p><p>With sgen.exe now in the right folder, my build works just fine…so fine that removing the file keeps the build working and I wasn’t able to get a screenshot of the error for this post.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I spent the better part of this afternoon fighting with this error (and arguing Canadian voting rights with the &lt;a href=&quot;http://www.westerndevs.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Western Devs&lt;/a&gt;). I was trying to run our project’s build script which uses nAnt and MSBuild to work all the compilation magic we need. There are a lot of pieces of information on how to solve this on the web. Most solutions revolve around &lt;em&gt;&amp;quot;Install Visual Studio 2010&amp;quot;&lt;/em&gt;, &lt;em&gt;&amp;quot;Install the Windows Software Development Kit for Windows X&amp;quot;&lt;/em&gt;, or &lt;em&gt;&amp;quot;Turn off the generation of serialization assemblies in your projects/solution&amp;quot;&lt;/em&gt;. Some of these are just downright scary solutions…others won’t work in my situation.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Microservices and Isolation</title>
    <link href="https://westerndevs.com/_/Microservices-and-isolation/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/Microservices-and-isolation/</id>
    <published>2015-08-12T07:09:40.000Z</published>
    <updated>2021-05-08T22:24:20.573Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>In my <a href="http://www.westerndevs.com/microservices-a-gentle-introduction" target="_blank" rel="noopener">first post</a> I made reference to the idea of microservice isolation a number of times. I figured that this is as good of a topic as any to start with. The concept of isolation and boundaries is core to how you build your microservices. Let's leave boundaries for another post because it's a complicated and deep concept by itself.</p><a id="more"></a><p>It doesn't matter who you listen to or read, microservice isolation is going to be in the content. Why are they consistently bringing it up? Isolation is at the heart of microservices. A microservice is meant to be architected, created, deployed, maintained and retired without affecting any other microservice. You can't do any, let alone all, of that without good isolation.</p><h2>Databases</h2><p>Probably the most common point made when talking about isolation is database sharing, or better stated, the idea that you should avoid it. Traditional monolithic application development usually sees that one large codebase working with one large database. Any area of the monolith can access any area of the database. Not only does the monolith's codebase usually end up looking like a plate of spaghetti, so does the monolithic database. I can't tell you the number of times that I've worked on brownfield codebases that have issues with data access, deadlocks being the most common. No matter how well factored a monolithic codebase is, the fact remains that the single database is an integration point for all the different moving pieces in that codebase.</p><p>To be able to release a microservice without affecting any other microservice we need to eliminate any integration that occurs at the database level. If you isolate the database so that only one microservice has access to it you've just said that the only thing that will be affected if the database changes is that one microservice. The testing surface area just shrunk for any of those changes. Another benefit is that have fewer pieces of code interacting with the database so you can, in theory, better control how and when that code does its thing. This makes it easier to write code that avoids deadlocks, row locks, and other performance killing or error inducing situations.</p><p><img src="http://farm1.staticflickr.com/311/20501646971_8ba8beb442_c.jpg" alt=""></p><p>If you listen to enough people talk about microservices for a long enough time you'll hear a common theme; 1 database per microservice. I'm going to disagree with the masses here and tell you something slightly different. You should have a <strong><em>minimum</em> of 1 data <em>store</em></strong> for each of your microservices. The difference is subtle but it's important in my mind. There are times when you might want to store data in multiple different ways within one microservice. As an example you may be writing a Marketing  Campaign microservice. A RDBMS or noSQL database makes a lot of sense for storing the information about campaigns, content, targets, etc. But if you need to do statistical analysis of the campaign feedback (i.e. email bounces, unsubscribes, click-throughs, etc.) RDBMS and noSQL might not make the most sense. You might be better served with a data cube or some other type of data storage.</p><p>Is it going to be normal to have multiple data stores for one microservice? No…but you shouldn't be worried if it does happen as long as you stay true to one thing: the microservice owns the data stores and no other microservices can access them.</p><h2>Deployment Isolation</h2><p>One of the primary goals of moving to a microservices architecture is that you're able to deploy changes to one microservice without affecting any others. Additionally you want to ensure that if a microservice starts to fail it's not going to bring down the other microservices around it. As such, this means that you're going to need to have each microservice deployed in complete isolation. If you're on a .NET stack you can't share AppPools between them. If they do changes to the permissions or availability of that AppPool could (or likely will) affect other microservices. My experience with Apache is quite limited, but I'm sure there are similar concerns there.</p><p>One of the big current talking points around microservices is <a href="https://www.docker.com" target="_blank" rel="noopener">Docker</a>. Building compartmentalized and deployable contiguous packages seems to address this goal. The only current issue is that Docker builds a smaller fence around the technologies that you can choose when solving your problems.  Docker, currently, doesn't support Windows based applications. You can build your <a href="http://www.hanselman.com/blog/PublishingAnASPNET5AppToDockerOnLinuxWithVisualStudio.aspx" target="_blank" rel="noopener">.NET apps and run them in a Linux Docker</a> container, but that's as close as you get…which might not be close enough for some &quot;E&quot;nterprise-y places.</p><p>Another piece of the deployment puzzle is what is commonly referred to as 'lock-step' deployments. A lock-step deployment is one where deploying one microservice requires a mandatory deployment of a different one. Usually this happens because the two components (or microservices in this case) are tightly coupled. Usually that coupling is related to api signature changes. I'm going to do a whole blog post on this later in the series, but its suffice to say for now that if you are doing lock-step deployments you need to stop and solve that problem before anything else. If you aren't doing lock-step deployments you need to be vigilant to the signs of them and fight them off as they pop up.</p><p>Something that makes noticing lock-step deployments more difficult to notice, but is going to be mandatory in your deployment situation, is automation. Everything about your deployment process will need to be automated. If you're coming from a mentality, or reality, of deploying single, monolithic applications you're in for a big shock. You're no longer deploying one application. You're deploying many different microservices. There are a lot more deployable parts, and they're all individually deployable. My project only had 4 microservices and we found that manual deployment was worse than onerous. Everything from the installation of the microservice to the provisioning of the environments that the microservice will run in has to be automated. Ideally you're going to have automated verification tests as part of your deployment. The automation process gives you the ability to easily create frictionless lock-step deployments though…so you're going to have to be vigilant with your automation.</p><p>I know that some of you are probably think &quot;That's all fine and good but I will always have to change APIs at some point which means that I need to deploy both the API and the consumers of the API together&quot;. Well, you don't have to…which kind of leads to…</p><h2>Microservice &lt;-&gt; Microservice communication</h2><p>At times there will be no way to avoid communication between two microservices. Sometimes this need to communicate is a sign that you have your bounded context wrong (I'll be going over bounded contexts in a future post). Sometimes the communication is warranted. Let's assume that the bounded contexts are correct for this discussion.</p><p>To keep microservices isolated we need to pay attention to how they communicate with each other. I'm going to do an entire blog post on this but because there can be so many things that come into play. It's safe to say that you need to pay attention to a couple of different key pieces. First, take the approach of having very strict standards for communication between microservices, and loose standards for the technology implementations within each microservice. If you're going to use REST and JSON (which seems to be the winning standard) for communication. Be strict about how those endpoints are created and exist. Also, don't be afraid to use messaging and pub/sub patterns to notify subscribing microservices about events that happen in publishing microservices.</p><p><img src="http://farm1.staticflickr.com/261/20307629680_1731d3ea66_c.jpg" alt=""></p><p>The second thing that you need to do, which is related to the first, is spend some time up front in deciding what your API versioning story is going to be. API versioning is going to play a big part in maintaining deployment isolation. Your solution will probably require more than simply 'adding a version header' to the communication. You're probably going to need infrastructure to route communications to different deployed versions of the APIs. Remember that each microservice is an isolated deployable so there is no reason that you couldn't have two or more instances (say v1 and v2) up and running at any one time. Consuming microservices can continue to make uninterrupted use of the v1 endpoints and as they have time/need they can migrate to v2.</p><h2>Source code</h2><p>Now that we've talked about the architecture of your microservices let's take a look at the source code. So far we've been talking about isolating the microservice data stores, the deployment strategy and cross microservice communication. In all of those areas we didn't come straight out and say it but each microservice is a separate application. How do you currently organize separate applications in your source control tool? Probably as separate repositories. Keep doing this. Every microservice gets its own repository. Full Stop. The result is that you're going to see an increase in the number of repositories that you have to manage. Instead of one (as you'd probably have with a monolith) repository you're going to have 1+N where N is the growing number of microservices that you're going to have.</p><p>How you organize the pieces of the puzzle within that application is going to depend on many things. It's going to depend on the components the microservice needs. The more &quot;things&quot; (service buses, web services, background processing, etc) then the more complicated the application's source code structure is likely to be. You might have four or five assemblies, a couple or executables and other deliverables in a single microservice. As long as you have the minimum required to deliver the required functionality then I think you'll be okay. More moving pieces can mean that you're doing too much in the microservice though. It could be creeping towards monolith territory. So carefully watch how each microservice evolves into it's final deliverable.</p><p>Another thing to consider is how you perform development isolation in your VCS. I'm not going to get into a branches vs feature-toggles discussion here, but you have to do something like that in your development practices. Things are going to move a lot faster when you're developing, enhancing and maintaining microservices. Being able to rapidly turn around bug fixes, feature additions or changes becomes a competitive advantage. You need to work within your VCS in a manner that supports this advantage.</p><h2>Continuous Integration</h2><p>Following in the steps of the source code is the continuous integration process. Because every microservices is an independent application you're going to need to have CI processes to support each and every microservice. This was one of the things that caught my project off guard. We didn't see it coming but we sure noticed it when it happened. As we created new microservices we needed to create all of the supporting CI infrastructure too. In our case we needed to create a build project for every deployment environment that we had to support. We didn't have this automated and we felt the pain. <a href="http://www.jetbrains.com/teamcity/" target="_blank" rel="noopener">TeamCity</a> helped us a lot but it still took time to setup everything. This was the first hint to us that we needed to automate everything.</p><h2>Teams</h2><p>There is a lot of talk about sizing microservices (which, again, I'll cover in a future post). One of the things that continually seems to come up in that discussion is the size of teams. What is often lost is that teams developing microservices should be both independent and isolated…just like the applications that they're building. <a href="http://www.thoughtworks.com/insights/blog/demystifying-conways-law" target="_blank" rel="noopener">Conway's law</a> usually makes this a difficult prospect in a 'E'nterprise development environment. The change to developing isolated and compartmentalized microservices is going to require team reorganization to better align the teams and the products being produced.</p><p>Teams need to be fully responsible for the entirety of the microservice that they're developing. They can't rely on &quot;the database guys to make those changes&quot; or &quot;infrastructure to create that VM for us&quot;. All of those capabilities have to be enabled for and entrusted to the team doing the development. Of course these independent teams will need to communicate with each other, especially if there one of the teams is consuming the other's microservice. I think I'll have a future post talking about <a href="http://martinfowler.com/articles/consumerDrivenContracts.html" target="_blank" rel="noopener">Consumer Driven Contracts</a> and how that enhances the communication between the teams.</p><h2>Summary</h2><p>When talking about isolation and microservices many conversations tend to stop at the &quot;one microservice, one database&quot; level. There are so many other isolation concerns that will appear during the process of building, deploying and maintaining those microservices. The more I've researched and worked on microservices the more I've become of the opinion that there are a bunch of things related to microservices that we used to get away not doing on monolithic projects but that we absolutely can't ignore anymore. You can't put off figuring out an API versioning scheme. You're going to need it sooner than you think. You can't &quot;figure out your branching strategy when the time comes&quot; because you're going to be working on v2 much sooner than you think.</p><p>Isolation is going to save you a lot of headaches. In the case microservices I'd probably consider leaning towards what feels like 'too much' isolation when making decisions rather than taking what likely will be the easier way out of the problem at hand.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In my &lt;a href=&quot;http://www.westerndevs.com/microservices-a-gentle-introduction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;first post&lt;/a&gt; I made reference to the idea of microservice isolation a number of times. I figured that this is as good of a topic as any to start with. The concept of isolation and boundaries is core to how you build your microservices. Let&#39;s leave boundaries for another post because it&#39;s a complicated and deep concept by itself.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Microservices: A Gentle Introduction</title>
    <link href="https://westerndevs.com/_/microservices-a-gentle-introduction/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/microservices-a-gentle-introduction/</id>
    <published>2015-08-05T18:40:50.000Z</published>
    <updated>2021-05-08T22:24:20.577Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>This past winter I started working on a project that was being architected with a mind towards using microservices. Prior to this I'd only seen the term 'microservices' floating around in the ether and really hadn't paid much attention to it. I wanted to share what we did and what I learned through the process and my subsequent research. That experience and research has led me to one belief: the microservice topic is massive. This post is going to be a kick-off to a series that will cover that material. With that, let's dig in.</p><a id="more"></a><h2>What are microservices?</h2><p>Sometimes its easier to start by describing what something isn't. Microservices are not monolithic applications. That's to say our traditional application was one unit of code. It is:</p><ul><li>developed together (even split as multiple assemblies, it was developed as one codebase)</li><li>deployed together (the vague promise of &quot;just deploy one dll from the application by itself&quot; has never been practical or practiced)</li><li>goes through the full application lifecycle as one contiguous unit (it is built as one, maintained as one and dies as one application)</li></ul><p>So a microservice is none of these things. In fact, to start the definition of what a microservice is you'd be safe in saying that, at a high level, microservices are the opposite of all these things. Microservices are a bunch of small applications that represent the functionality we once considered as one application. They are:</p><ul><li>developed in isolation (contracts between microservices are established but this is the extent of their knowledge of each other)</li><li>deployed in isolation (each microservices is it's own encapsulated application)</li><li>lives and dies no relationship to any other microservice (each microservice's application lifecycle is managed independently)</li></ul><p>There's a pretty common comparison between microservices and SOA. If you missed the whole SOA bandwagon then 1) you're younger than me, 2) I'm envious of you, and 3) it had its merits. Some people will say &quot;microservices are just SOA done right&quot;. I'm not sure that I fully agree with that statement. I don't know that I disagree with it either. As an introduction to microservices you should understand that there are many parallels between them and SOA. Applications that aren't monolithic tend to be distributed. Both SOA and microservice architectures are decidedly distributed. Probably the biggest difference between SOA and microservices is that SOA was quickly absconded by the big software manufacturing companies. According to them, doing SOA right meant using an Enterprise Service Bus (most likely an Enterprise Service Broker being marketed and pitched as a service bus)…and preferably using their ESB, not a competitors. Gradually those SOA implementations became ESB implementations driven by software vendors and licensing and the architectural drive of SOA was lost. Instead of a distributed system business logic was moved out of application codebases and into centralized ESB implementations. If you've ever had to debug a system that had business logic in BizTalk then you know what the result of vendors taking over SOA was.</p><p>Thus far (and microservices are older as an architecture than you probably think) the microservice architecture hasn't been turned into a piece of software that companies are flogging licenses for. It's questionable whether the hype (justified or not) around Docker as a core component of a microservices implementation is just the start of microservices heading the same direction as SOA. It might be, it might not be.</p><p>Each microservice is a well encapsulated, independent and isolated application. If someone pitches microservices at you and there's a shared database, or two microservices must be deployed in unison, or changes to one microservice forces changes on another then they're pitching you something that's not a true microservice. These concepts are going to lead to a bunch of the items I will discuss in future blog posts.</p><h2>What does all of this mean?</h2><p>Good question. The short story, from what I've been able to collate, is that microservices promise a bunch of things that we all want in our applications; ease of deployment, isolation, technology freedom, strong encapsulation, extensibility and more. The thing that people don't always immediately see is the pain that they can bring. Most organizations are used to building and managing large monolithic codebases. They struggle in many different ways with these applications, but the way that they work is driven by the monolithic application. As we covered earlier, microservices are nothing like monoliths. The processes, organizational structures and even technologies used for monolithic applications are not going to work when you make the move to microservices.</p><p>Think about this: how does your team/organization deal with deploying your monolithic application to a development environment? What about to Dev and Test? Dev, Test and UAT? Dev, Test, UAT and Prod? I'm sure there's some friction there. I'm sure each one of those environment deployments takes time, possibly is done manually, and requires verification before its declared &quot;ready&quot;. Now thinking about all the time you spend working through those environment releases and imagine doing it for 5 applications. Now 10. What would happen if you used the same processes but had 25 applications to deploy? This is what your world will be like with microservices.</p><p>Part of what I hope to convey in this series of blog posts is a sense of what pain you're going to see. There's going to be technical pain as well as organizational pain. And, as I know from experience over the last 6 months, there is going to be a learning curve. To help you with that learning curve I've created a list of resources as part of a github repository (<a href="https://github.com/dbelcham/microservice-material" target="_blank" rel="noopener">https://github.com/dbelcham/microservice-material</a>) that you can go through. Its not complete. It's not finished. If you find something you think should be added please submit a pull request and I'll look at getting it added. As of the moment I'm writing this it's probably weakest in the Tooling, Techniques and Platforms section. I'm hoping to give that some love soon as it will be important to my writing.</p><h2>In closing</h2><p>Microservices are a topic that is gaining traction and there's a lot of information that needs to be disseminated. I don't think I'm going to post any earth shattering new concepts on the topic but I want to get one location where I can put my thoughts and, hopefully, others can come for a cohesive read on the topic. I am, by no means, an expert on the topic. Feel free to disagree with what I say. Ask questions, engage in thoughtful conversation and tell me if you think there's an area that needs to be covered in more depth.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This past winter I started working on a project that was being architected with a mind towards using microservices. Prior to this I&#39;d only seen the term &#39;microservices&#39; floating around in the ether and really hadn&#39;t paid much attention to it. I wanted to share what we did and what I learned through the process and my subsequent research. That experience and research has led me to one belief: the microservice topic is massive. This post is going to be a kick-off to a series that will cover that material. With that, let&#39;s dig in.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">SaaS and Commodities</title>
    <link href="https://westerndevs.com/_/saas-and-commodities/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/saas-and-commodities/</id>
    <published>2015-07-28T18:40:50.000Z</published>
    <updated>2021-05-08T22:24:20.577Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I'm doing some work right now that requires us to send SMS messages. The organization I'm working with has never had this capability before so we are starting at ground level when it comes to looking at options. As part of our process we evaluated a number of different criteria on about four different SaaS options; <a href="http://twilio.com" target="_blank" rel="noopener">twilio</a>, <a href="http://plivo.com" target="_blank" rel="noopener">plivo</a>, <a href="http://nexmo.com" target="_blank" rel="noopener">nexmo</a> and <a href="http://sendinblue.com" target="_blank" rel="noopener">sendinblue</a>. For reasons not relevant to this post, plivo was the initial choice of the client. We moved from analysis to writing a proof of concept.</p><a id="more"></a><p>The first stage of doing a proof of concept is getting a user account set up. When I tried registering a new account with plivo I got the following message:</p><p><img src="https://farm4.staticflickr.com/3739/19464256764_33dd8b79b9_z.jpg" alt="plivo_error"></p><p>I did, however, receive an account confirmation email. I clicked on the link in the email and received the same message. Thinking that this might just be a UI issue and that the confirmation was accepted I decided to try to login. Click the login button and wham…same error message…before you even get to see the username and password screen. This, obviously, is starting to become an issue for our proof of concept. I decide, as a last resort, to reach out to plivo to get a conversation going. I navigate to the Contact Us page to, once again, see the same error message before I see the screen. At this point the website is obviously not healthy so I navigate to the status page and see this</p><p><img src="https://farm1.staticflickr.com/318/19465913243_18bd4dca97_z.jpg" alt="plivo_status"></p><p>So everything is healthy….but it's not. A quick glance at their twitter account shows that plivo attempted to do some database maintenance the day prior to this effort and they claimed it was successful. Related to the database maintenance or not, I needed to move on.</p><p>This is the part that gets interesting (for me anyways). Our choice in SMS provider was a commodity selection. We went the store, looked on the shelf, read the boxes and picked one. It very well could have been any box that we selected. But the fact that making that selection was so simple means that changing the selection was equally simple. We weren't (in this specific case which may not always be the case) heavily invested in the original provider so the cost of change was minimal (zero in our case). All we had to do was make a different selection.</p><p>This highlighted something that hadn't clicked for me before. Software as commodities makes our developer experience both more dynamic and more resilient. We are able to change our minds quickly and avoid unwanted interruptions easily. The flip side of the coin is that if you're a SaaS provider you need to have your A game on all the time. Any outage, error or friction means that your potential (or current) customer will quickly and easily move to a competitor.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I&#39;m doing some work right now that requires us to send SMS messages. The organization I&#39;m working with has never had this capability before so we are starting at ground level when it comes to looking at options. As part of our process we evaluated a number of different criteria on about four different SaaS options; &lt;a href=&quot;http://twilio.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;twilio&lt;/a&gt;, &lt;a href=&quot;http://plivo.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;plivo&lt;/a&gt;, &lt;a href=&quot;http://nexmo.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;nexmo&lt;/a&gt; and &lt;a href=&quot;http://sendinblue.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sendinblue&lt;/a&gt;. For reasons not relevant to this post, plivo was the initial choice of the client. We moved from analysis to writing a proof of concept.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Sharpening chisels</title>
    <link href="https://westerndevs.com/_/sharpening-chisels/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/sharpening-chisels/</id>
    <published>2015-07-08T21:38:46.000Z</published>
    <updated>2021-05-08T22:24:20.577Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I'm working on a cedar garden gate for our back yard. It's all mortise and tenon joinery which means I make a lot of use of my <a href="http://www.narexchisels.com/Narex_Chisels/Home.html" target="_blank" rel="noopener">Narex</a> <a href="http://www.leevalley.com/en/wood/page.aspx?p=67707&amp;cat=1,41504" target="_blank" rel="noopener">bench</a> and <a href="http://www.leevalley.com/en/wood/page.aspx?p=66737&amp;cat=1,41504" target="_blank" rel="noopener">mortise</a> chisels. The more you use chisels the duller they get. Dull chisels cause you two problems; you can't be as precise with them, and you run the very real risk of amputating a finger. As much as I have two of each finger I really do want to keep all eleven of them. Getting tight fitting tenons requires fine tuning of their thicknesses by the thousandth of an inch. Both of those fly directly in the face of what dull chisels are good at…so tonight was all about sharpening them up.</p><a id="more"></a><p>There are a number of different ways that you can sharpen edged tools (chisels and hand planes). There are machines, you can use water stones, Arkansas stones, diamond stones or, my personal choice, the &quot;<a href="https://groups.google.com/forum/?hl=en#!topic/rec.woodworking/rGAGAPR-6ks" target="_blank" rel="noopener">Scary Sharp Technique</a>&quot;. For those of you that couldn't be bothered click that link and read through the original usenet posting on the topic in detail (and who can blame you, this is a software blog after all) here's the TL;DR; for Scary Sharp.</p><ul><li>Sharpening is done with wet dry automotive sand paper, not stones</li><li>Progression is made to finer and finer grits as you get sharper. i.e.  400 –&gt; 800 –&gt; 1200 –&gt; 2000 grit</li><li>Sandpaper is glued down to a perfectly flat surface such as float glass, a tile, or granite counter top (ask the missus first if you're planning on using the kitchen)</li></ul><p>My station for tonight looked like this (400 grit to the left, 2000 grit on the far right):</p><p><img src="https://farm1.staticflickr.com/373/19487481376_c527907bae_z.jpg" alt="sharpening station"></p><p>So, why am I boring you with all this detail about sharpening my chisels? There's a story to be told about software tools and woodworking tools. The part of it that I'm going tell in this post is the part about maintaining and fine tuning them.</p><h3>Maintaining your tools</h3><p>For me to be able to effectively, and safely, create my next woodworking project I need to constantly maintain my chisels (amongst other tools). I have to stop my project work and take the time to perform this maintenance. Yes, it's time that I could be getting closer to being finished, but at what cost? Poor fitting joinery? Avoidable gouges? Self amputation? The trade off is project velocity for project quality.</p><p>Now think about a development tool that you use on a regular basis for your coding work. Maybe it's Visual Studio, or IntelliJ, or ReSharper, or PowerShell, or…or…or. You get the point. You open these tools on an almost daily basis. You're (hopefully) adept at using them. But do you ever stop and take the time to maintain them? If it weren't for auto-updating/reminder services would you even keep as close to the most recent release version as you currently are? Why don't we do more? I currently have an install of Resharper that I use almost daily that doesn't correctly perform the clean-up command when I hit Ctrl-Shift-F. I know this. Every time I hit Ctrl-Shift-F I cuss about the fact it doesn't work. But I haven't taken the time to go fix it. I've numbed myself to it.</p><p>Alternatively, imagine if you knew that once a week/month/sprint/ you were going to set aside time to go into the deep settings of your tool (i.e. ReSharper | Options) and perform maintenance on it. What if you smoke tested the shortcuts, cleaned up the templates, updated to the latest bits? Would your (or mine in the above example) development experience be better? Would you perform better work as a result? Possibly. Probably.</p><h3>Tools for tools</h3><p>I have tools for my woodworking tools. I can't own and use my chisels without having the necessary tools to keep them sharp. I need a honing guide, sand paper, and granite just to be able to maintain my primary woodworking tools. None of those things directly contribute to the production of the final project. All their contributions are indirect at best. This goes for any number of tools that I have on my shelves. Tools for tools is a necessity, not a luxury. Like your first level tools, your second level of tools need to be maintained and cared for too. Before I moved to the Scary Sharp system I used water stones. As you repetitively stroke the edge over the stone it naturally creates a concave in the middle of the stone. This rounded surface makes it impossible to create a proper bevel angle. To get the bevel angle dead on I needed to constantly flatten my stone. Sharpen a tool for a while, flatten the stone surface…repeat. Tools to maintain tools that are used to maintain tools.</p><p>Now think about your software development tools. How many of you have tools for those tools? Granted, some of them don't require tools to maintain them….or do they? So you do some configuration changes for git bash's .config file. Maybe you open that with Notepad ++. Now you have a tool (Notepad++), for your tool (git bash). How do you install Notepad++? With <a href="https://chocolatey.org/" target="_blank" rel="noopener">chocolatey</a> you say? Have you been maintaining your chocolatey install? Tools to maintain tools that are used to maintain tools.</p><p>Sadly we developers don't put much importance on the secondary and tertiary tools in our toolboxes. We should. We need to. If we don't our primary tools will never be in optimal working condition and, as a result, we will never perform at our peaks.</p><h3>Make time</h3><p>Find the time in your day/week/sprint/month to pay a little bit of attention to your secondary and tertiary tools. Don't forget to spend some quality time with your primary tools. Understand them, tweak them, optimize them, keep them healthy. Yes, it will take time away from delivering your project/product. Consider that working with un-tuned tools will take time away as well.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I&#39;m working on a cedar garden gate for our back yard. It&#39;s all mortise and tenon joinery which means I make a lot of use of my &lt;a href=&quot;http://www.narexchisels.com/Narex_Chisels/Home.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Narex&lt;/a&gt; &lt;a href=&quot;http://www.leevalley.com/en/wood/page.aspx?p=67707&amp;amp;cat=1,41504&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;bench&lt;/a&gt; and &lt;a href=&quot;http://www.leevalley.com/en/wood/page.aspx?p=66737&amp;amp;cat=1,41504&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;mortise&lt;/a&gt; chisels. The more you use chisels the duller they get. Dull chisels cause you two problems; you can&#39;t be as precise with them, and you run the very real risk of amputating a finger. As much as I have two of each finger I really do want to keep all eleven of them. Getting tight fitting tenons requires fine tuning of their thicknesses by the thousandth of an inch. Both of those fly directly in the face of what dull chisels are good at…so tonight was all about sharpening them up.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
