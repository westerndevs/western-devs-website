<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Western Devs</title>
  
  <link href="/feeds/simon_timms" rel="self" type="application/atom+xml"/>
  <link href="https://westerndevs.com" rel="alternate" type="application/atom+xml"/>
  
  <updated>2021-05-10T16:14:31.384Z</updated>
  <id>https://westerndevs.com/</id>
  
  <author>
    <name>Western Devs</name>
	<uri>https://westerndevs.com</uri>
    <email>info@westerndevs.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title type="html">Setting Timezone from Powershell</title>
    <link href="https://westerndevs.com/_/set-timezone/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/set-timezone/</id>
    <published>2021-05-10T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.384Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>This is pretty easy.</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Set-Timezone</span> <span class="literal">-Id</span> <span class="string">"US Eastern Standard Time"</span></span><br></pre></td></tr></table></figure><p>You need to know the id of the timezone and you can figure that out using</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Get-Timezones</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Id                         :</span> <span class="string">Dateline</span> <span class="string">Standard</span> <span class="string">Time</span></span><br><span class="line"><span class="attr">DisplayName                :</span> <span class="string">(UTC-12:00)</span> <span class="string">International</span> <span class="string">Date</span> <span class="string">Line</span> <span class="string">West</span></span><br><span class="line"><span class="attr">StandardName               :</span> <span class="string">Dateline</span> <span class="string">Standard</span> <span class="string">Time</span></span><br><span class="line"><span class="attr">DaylightName               :</span> <span class="string">Dateline</span> <span class="string">Daylight</span> <span class="string">Time</span></span><br><span class="line"><span class="attr">BaseUtcOffset              :</span> <span class="number">-12</span><span class="string">:00:00</span></span><br><span class="line"><span class="attr">SupportsDaylightSavingTime :</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Id                         :</span> <span class="string">UTC-11</span></span><br><span class="line"><span class="attr">DisplayName                :</span> <span class="string">(UTC-11:00)</span> <span class="string">Coordinated</span> <span class="string">Universal</span> <span class="string">Time-11</span></span><br><span class="line"><span class="attr">StandardName               :</span> <span class="string">UTC-11</span></span><br><span class="line"><span class="attr">DaylightName               :</span> <span class="string">UTC-11</span></span><br><span class="line"><span class="attr">BaseUtcOffset              :</span> <span class="number">-11</span><span class="string">:00:00</span></span><br><span class="line"><span class="attr">SupportsDaylightSavingTime :</span> <span class="literal">False</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p>You can also see the current timezone by running</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Get-Timezone</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Id                         :</span> <span class="string">Mountain</span> <span class="string">Standard</span> <span class="string">Time</span></span><br><span class="line"><span class="attr">DisplayName                :</span> <span class="string">(UTC-07:00)</span> <span class="string">Mountain</span> <span class="string">Time</span> <span class="string">(US</span> <span class="string">&amp;</span> <span class="string">Canada)</span></span><br><span class="line"><span class="attr">StandardName               :</span> <span class="string">Mountain</span> <span class="string">Standard</span> <span class="string">Time</span></span><br><span class="line"><span class="attr">DaylightName               :</span> <span class="string">Mountain</span> <span class="string">Daylight</span> <span class="string">Time</span></span><br><span class="line"><span class="attr">BaseUtcOffset              :</span> <span class="number">-07</span><span class="string">:00:00</span></span><br><span class="line"><span class="attr">SupportsDaylightSavingTime :</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is pretty easy.&lt;/p&gt;
&lt;figure class=&quot;highlight powershell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/t
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Download a file in powershell</title>
    <link href="https://westerndevs.com/_/download-file/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/download-file/</id>
    <published>2021-05-08T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.380Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Here is a quick way to download a file in powershell:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Invoke-WebRequest -Uri <span class="tag">&lt;<span class="name">source</span>&gt;</span> -OutFile <span class="tag">&lt;<span class="name">destination</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Here is a quick way to download a file in powershell:&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;l
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Create or Update Index</title>
    <link href="https://westerndevs.com/_/drop-existing-index/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/drop-existing-index/</id>
    <published>2021-05-08T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.380Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Of course the SQL server syntax for this doesn't quite jive with what I want but you can use the clause <code>WITH (DROP_EXISTING = ON)</code> to have SQL server handle updating an existing index keeping the old index live until the new version is ready. You use it like</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> NONCLUSTERED <span class="keyword">INDEX</span> idxMonthlyParkers_vendor_expiry_issue</span><br><span class="line"><span class="keyword">ON</span> [dbo].[tblParkers] ([VendorId],[LotTimezoneExpiryDate],[LotTimezoneIssueDate])</span><br><span class="line"><span class="keyword">INCLUDE</span> ([HangTagCode],[FirstName],[LastName])</span><br><span class="line"> <span class="keyword">WITH</span> (DROP_EXISTING = <span class="keyword">ON</span>)</span><br></pre></td></tr></table></figure><p>However that will throw an error if the index doesn't exist (of course) so you need to wrap it with an <code>if</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">if exists (<span class="keyword">SELECT</span> * </span><br><span class="line"><span class="keyword">FROM</span> sys.indexes </span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">name</span>=<span class="string">'idxMonthlyParkers_vendor_expiry_issue'</span> <span class="keyword">AND</span> object_id = OBJECT_ID(<span class="string">'dbo.tblMonthlyParker'</span>))</span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">CREATE</span> NONCLUSTERED <span class="keyword">INDEX</span> idxMonthlyParkers_vendor_expiry_issue</span><br><span class="line">    <span class="keyword">ON</span> [dbo].[tblParkers] ([VendorId],[LotTimezoneExpiryDate],[LotTimezoneIssueDate])</span><br><span class="line">    <span class="keyword">INCLUDE</span> ([HangTagCode],[FirstName],[LastName])</span><br><span class="line">    <span class="keyword">WITH</span> (DROP_EXISTING = <span class="keyword">ON</span>)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">else</span> </span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">CREATE</span> NONCLUSTERED <span class="keyword">INDEX</span> idxMonthlyParkers_vendor_expiry_issue</span><br><span class="line">    <span class="keyword">ON</span> [dbo].[tblParkers] ([VendorId],[LotTimezoneExpiryDate],[LotTimezoneIssueDate])</span><br><span class="line">    <span class="keyword">INCLUDE</span> ([HangTagCode],[FirstName],[LastName])</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Of course the SQL server syntax for this doesn&#39;t quite jive with what I want but you can use the clause &lt;code&gt;WITH (DROP_EXISTING = ON)&lt;/
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Logging in Functions</title>
    <link href="https://westerndevs.com/_/function-appinsights/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/function-appinsights/</id>
    <published>2021-05-08T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.380Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Looks like by default functions log at the <code>info</code> level. To change the level you can use set the application setting <code>AzureFunctionsJobHost__logging__LogLevel__Default</code> to some other value like <code>Error</code> or <code>Info</code>.</p><p>If you want to disable adaptive sampling then that can be done in the host.json</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"version"</span>: <span class="string">"2.0"</span>,</span><br><span class="line">  <span class="attr">"extensions"</span>: &#123;</span><br><span class="line">    <span class="attr">"queues"</span>: &#123;</span><br><span class="line">      <span class="attr">"maxPollingInterval"</span>: <span class="string">"00:00:05"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"logging"</span>: &#123;</span><br><span class="line">    <span class="attr">"logLevel"</span>: &#123;</span><br><span class="line">      <span class="attr">"default"</span>: <span class="string">"Information"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"applicationInsights"</span>: &#123;</span><br><span class="line">      <span class="attr">"samplingSettings"</span>: &#123;</span><br><span class="line">        <span class="attr">"isEnabled"</span>: <span class="literal">false</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"functionTimeout"</span>: <span class="string">"00:10:00"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In this example adaptive sampling is turned off so you get every log message.</p><p>A thing to note is that if you crank down logging to Error you won't see the invocations at all in the portal but they're still running.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Looks like by default functions log at the &lt;code&gt;info&lt;/code&gt; level. To change the level you can use set the application setting &lt;code&gt;Azu
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Query BigTable Events</title>
    <link href="https://westerndevs.com/_/query-collections-in-big-table/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/query-collections-in-big-table/</id>
    <published>2021-05-08T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.384Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Firebase can feed its data to bigtable and then you can run queries there. The syntax is SQL like but not quite because they have internal record types. So for the data that is fed across from firebase you get a structure that looks like</p><p><img src="/images/2021-03-05-query-collections-in-big-table.md/2021-03-05-10-39-05.png" alt=""></p><p>You can see that event_params and user_properties are these kind of collection things. The easiest way to deal with them is to flatten the structure and internally join the table against itself</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> r.event_name, p.key, p.value <span class="keyword">FROM</span> <span class="string">`pocketgeek-auto.analytics_258213689.events_intraday_20210305`</span> r <span class="keyword">cross</span> <span class="keyword">join</span> <span class="keyword">unnest</span>(r.event_params) <span class="keyword">as</span> p <span class="keyword">where</span> <span class="keyword">key</span> = <span class="string">'DealerName'</span></span><br></pre></td></tr></table></figure><p>This gets you a dataset like</p><p><img src="/images/2021-03-05-query-collections-in-big-table.md/2021-03-05-10-39-05.png" alt=""></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> r.event_name, p.key, p.value <span class="keyword">FROM</span> <span class="string">`pocketgeek-auto.analytics_258213689.events_intraday_20210305`</span> r <span class="keyword">cross</span> <span class="keyword">join</span> <span class="keyword">unnest</span>(r.event_params) <span class="keyword">as</span> p <span class="keyword">where</span> <span class="keyword">key</span> = <span class="string">'DealerName'</span> <span class="keyword">and</span> p.value.string_value &lt;&gt; <span class="string">'none'</span></span><br></pre></td></tr></table></figure><p>is probably even better with the filter</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Firebase can feed its data to bigtable and then you can run queries there. The syntax is SQL like but not quite because they have interna
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Setting a persistent environment variable</title>
    <link href="https://westerndevs.com/_/set-env-variable/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/set-env-variable/</id>
    <published>2021-05-08T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.384Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>If you want to set a variable but you want it to live forever then you can use</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">System.Environment</span>]::SetEnvironmentVariable(<span class="string">"JAVA_HOME"</span>, <span class="string">"c:\program files\openjdk\jdk-13.0.2"</span>, <span class="string">"Machine"</span>)</span><br></pre></td></tr></table></figure><p>That last argument can take on the values {<code>Process</code>, <code>User</code>, <code>Machine</code>}</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;If you want to set a variable but you want it to live forever then you can use&lt;/p&gt;
&lt;figure class=&quot;highlight powershell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Increase Terminal Buffer in VS Code</title>
    <link href="https://westerndevs.com/_/terminal-buffer/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/terminal-buffer/</id>
    <published>2021-05-08T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.384Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Got something in your terminal which is producing more output than you can scroll back through (I'm looking at you <code>terraform plan</code>)? You can adjust the setting in preferences:</p><p><img src="/images/2021-04-29-terminal-buffer.md/2021-04-29-15-04-52.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Got something in your terminal which is producing more output than you can scroll back through (I&#39;m looking at you &lt;code&gt;terraform plan&lt;/
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Transforms</title>
    <link href="https://westerndevs.com/_/xdt-transforms/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/xdt-transforms/</id>
    <published>2021-05-08T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.388Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>You can apply little transforms by just writing XML transformation on configuration files. For instance here is one for adding a section to the <code>system.web</code> section of the configuration file</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">xmlns:xdt</span>=<span class="string">"http://schemas.microsoft.com/XML-Document-Transform"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">system.web</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">machineKey</span> <span class="attr">xdt:Transform</span>=<span class="string">"Insert"</span> <span class="attr">decryptionKey</span>=<span class="string">"abc"</span> <span class="attr">validationKey</span>=<span class="string">"def"</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">system.web</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Here is one for removing an attribute</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">xmlns:xdt</span>=<span class="string">"http://schemas.microsoft.com/XML-Document-Transform"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">system.web</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">compilation</span> <span class="attr">xdt:Transform</span>=<span class="string">"RemoveAttributes(debug)"</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">system.web</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>How about changing an attribute based on matching the key?</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">xmlns:xdt</span>=<span class="string">"http://schemas.microsoft.com/XML-Document-Transform"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">appSettings</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">add</span> <span class="attr">key</span>"<span class="attr">MaxUsers</span>" <span class="attr">value</span>=<span class="string">"3"</span> <span class="attr">xdt:Transform</span>=<span class="string">"SetAttributes"</span> <span class="attr">xdt:Locator</span>=<span class="string">"Match(key)"</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">appSettings</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>If you happen to be using Octopus Deploy they have a feature you can add to your IIS deployment task to run these transformations</p><p><img src="/images/2021-05-06-xdt-transforms.md/2021-05-06-13-34-59.png" alt=""></p><h2>Testing</h2><p>There is a great little online testing tool at https://elmah.io/tools/webconfig-transformation-tester/ where you can plug in random things until you get them working.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;You can apply little transforms by just writing XML transformation on configuration files. For instance here is one for adding a section 
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Allocating a Serverless Database in SQL Azure</title>
    <link href="https://westerndevs.com/_/serverless-sql-azure-terraform/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/serverless-sql-azure-terraform/</id>
    <published>2020-11-18T19:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.380Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I'm pretty big on the SQL Azure Serverless SKU. It allows you to scale databases up and down automatically within a band of between 0.75 and 40 vCores on Gen5 hardware. It also supports auto-pausing which can shut down the entire database during periods of inactivity. I'm provisioning a bunch of databases for a client and we're not sure what performance tier is going to be needed. Eventually we may move to an elastic pool but initially we wanted to allocate the databases in a serverless configuration so we can ascertain a performance envelope. We wanted to allocate the resources in a terraform template but had a little trouble figuring it out.</p><a id="more"></a><p>Traditionally we've been using the resource <code>azurerm_sql_database</code> for our databases but this provider is starting to be deprecated in favour of <code>azurerm_mssql_database</code> which has better support for some of the more modern concept in SQL Azure. The <a href="https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/mssql_database#state" target="_blank" rel="noopener">documentation</a> is pretty good for it but while there was a <code>min_capacity</code> we couldn't find an equivalent <code>max_capacity</code>. Turns out you can set the max capacity using the SKU. So we had something like</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"azurerm_mssql_database"</span> <span class="string">"database"</span> &#123;</span><br><span class="line">  <span class="attr">name</span>                        = var.database_name</span><br><span class="line">  <span class="attr">server_id</span>                   = var.database_server_id</span><br><span class="line">  <span class="attr">max_size_gb</span>                 = var.database_max_size_gb</span><br><span class="line">  <span class="attr">auto_pause_delay_in_minutes</span> = -<span class="number">1</span></span><br><span class="line">  <span class="attr">min_capacity</span>                = <span class="number">1</span></span><br><span class="line">  <span class="attr">sku_name</span>                    = <span class="string">"GP_S_Gen5_6"</span></span><br><span class="line">  <span class="attr">tags</span> = &#123;</span><br><span class="line">    <span class="attr">environment</span> = var.prefix</span><br><span class="line">  &#125;</span><br><span class="line">  short_term_retention_policy &#123;</span><br><span class="line">    <span class="attr">retention_days</span> = <span class="number">14</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This allocates a database with a capacity of between 1 and 6 vCPU that has auto pause disabled. The S in the GP_S_Gen5_6 stands for serverless and the 6 denotes the maximum capacity.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I&#39;m pretty big on the SQL Azure Serverless SKU. It allows you to scale databases up and down automatically within a band of between 0.75 and 40 vCores on Gen5 hardware. It also supports auto-pausing which can shut down the entire database during periods of inactivity. I&#39;m provisioning a bunch of databases for a client and we&#39;re not sure what performance tier is going to be needed. Eventually we may move to an elastic pool but initially we wanted to allocate the databases in a serverless configuration so we can ascertain a performance envelope. We wanted to allocate the resources in a terraform template but had a little trouble figuring it out.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Running Stored Procedures Across Databases in Azure</title>
    <link href="https://westerndevs.com/_/cross-database-procs/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/cross-database-procs/</id>
    <published>2020-11-09T19:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.380Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>In a <a href="https://blog.simontimms.com/2020/11/05/2020-11-05-cross-database-queries/" target="_blank" rel="noopener">previous article</a> I talked about how to run queries across database instances on Azure using ElasticQuery. One of the limitations I talked about was the in ability to update data in the source database. Well that isn't entirely accurate. You can do it if you make use of stored procedures.</p><a id="more"></a><p>Running a stored proc on a remote database is a little bit weird looking but once you get your head around that then it is perfectly usable. Let's go back to the same example we used before with a products database an an orders database. In the products database let's add a stored procedure to add a new product and return the count of products.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">procedure</span> addProduct</span><br><span class="line"> @item <span class="keyword">nvarchar</span>(<span class="number">50</span>)</span><br><span class="line"><span class="keyword">as</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> Products(<span class="keyword">name</span>) <span class="keyword">values</span>(@item);</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) cnt <span class="keyword">from</span> products;</span><br><span class="line">go</span><br></pre></td></tr></table></figure><p>Now over in our orders database we can use our existing database connection to call this stored proc</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sp_execute_remote ProductsSource, </span><br><span class="line">                  N'addProduct @item', </span><br><span class="line">                  @params = N'@item nvarchar(50)', </span><br><span class="line">                  @item = 'long sleeved shirts';</span><br></pre></td></tr></table></figure><p>At first glance this is a little confusing so let's break it down.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp_execute_remote ProductsSource,</span><br></pre></td></tr></table></figure><p>This line instructs that we want to run a stored procedure and that it should use the ProductsSource data connection.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">N'addProduct @item',</span><br></pre></td></tr></table></figure><p>This line lists the stored proc to run and the parameters to pass to it. You'll notice that it is a NVarchar string passed as a single parameter.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@params = N'@item nvarchar(50)',</span><br></pre></td></tr></table></figure><p>This line lists all the parameters to pass and their type. If you have multiple then you'd comma separate them here: <code>N'@item nvarchar(50), @price number(10,2)'</code></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">@item</span> = <span class="string">'long sleeved shirts'</span>;</span><br></pre></td></tr></table></figure><p>This final line is an args-style array of the values for the parameters. Again if you had a second parameter you'd pass it in as separate item here <code>@item = 'long sleeved shirts', @price=10.99</code></p><p>Running this command gets us something like</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cnt  <span class="variable">$ShardName</span></span><br><span class="line">6  [<span class="attribute">DataSource</span>=testias.database.windows.net <span class="attribute">Database</span>=testias]</span><br></pre></td></tr></table></figure><p>You'll notice that nifty ShardName colum which tells you about the source. This is because you can use a shard map to execute the stored procedure against lots of shards at once.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In a &lt;a href=&quot;https://blog.simontimms.com/2020/11/05/2020-11-05-cross-database-queries/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;previous article&lt;/a&gt; I talked about how to run queries across database instances on Azure using ElasticQuery. One of the limitations I talked about was the in ability to update data in the source database. Well that isn&#39;t entirely accurate. You can do it if you make use of stored procedures.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Azure Processor Limits</title>
    <link href="https://westerndevs.com/_/processor-limits/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/processor-limits/</id>
    <published>2020-11-05T20:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.380Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Ran into a fun little quirk in Azure today. We wanted to allocate a pretty beefy machine, an M32ms. Problem was that for the region we were looking at it wasn't showing up on our list of VM sizes. We checked and there were certainly VMs of that size available in the region we just couldn't see them. So we ran the command</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">az </span><span class="string">vm </span><span class="built_in">list-usage</span> <span class="built_in">--location</span> <span class="string">"westus"</span> <span class="built_in">--output</span> <span class="string">table</span></span><br></pre></td></tr></table></figure><p>And that returned a bunch of information about the quota limits we had in place. Sure enough in there we had</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Name</span>                               <span class="keyword">Current</span> <span class="keyword">Value</span>   <span class="keyword">Limit</span></span><br><span class="line">Standard MS <span class="keyword">Family</span> vCPUs           <span class="number">0</span>               <span class="number">0</span></span><br></pre></td></tr></table></figure><p>We opened a support request to increase the quota on that CPU. We also had a weirdly low limit on CPUs in the region</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Total Regional vCPUs               <span class="number">0</span>               <span class="number">10</span></span><br></pre></td></tr></table></figure><p>Which support fixed for us too and we were then able to create the VM we were looking for.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ran into a fun little quirk in Azure today. We wanted to allocate a pretty beefy machine, an M32ms. Problem was that for the region we we
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Querying Across Databases In SQL Azure</title>
    <link href="https://westerndevs.com/_/elasticquery/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/elasticquery/</id>
    <published>2020-11-05T19:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.380Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I seem to be picking up a few projects lately which require migrating data up to Azure SQL from an on premise database. One of the things that people tend to do when they have on premise databases is query across databases or link servers together. It is a really tempting prospect to be able to query the <code>orders</code> database from the <code>customers</code> database. There are, of course, numerous problems with taking this approach not the least of which is making it very difficult to change database schema. We have all heard that it is madness to integrate applications at the database level and that's one of the reasons.</p><a id="more"></a><p>Unfortunately, whacking developers with a ruler and making them rewrite their business logic to observe proper domain boundaries isn't always on the cards. This is a problem when migrating them to SQL Azure because querying across databases, even ones on the same server, isn't permitted.</p><p><img src="https://blog.simontimms.com/images/elasticquery/brokenQuery.png" alt="Broken query across databases"></p><p>This is where the new <a href="https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-query-overview" target="_blank" rel="noopener">Elastic Query</a> comes in. I should warn at this point that the functionality is still in preview but it's been in preview for a couple of years so I think it is pretty stable. I feel a little bit disingenuous describing it as &quot;new&quot; now but it is new to me. To use it is pretty easy and doesn't even need you to use the Azure portal.</p><p>Let's imagine that you have two databases one of which contains a collection of Products and a second database that contains a list of Orders which contain just the product id. Your mission is to query and get a list of orders and the product name. To start we can set up a couple of databases. I called mine <code>testias</code> and <code>testias2</code> and I had them both on the same instance of SQL Azure but you don't have to.</p><p><img src="https://blog.simontimms.com/images/elasticquery/setup.png" alt="Two databases on the same server"></p><h2>Product Database</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> Products( </span><br><span class="line"><span class="keyword">id</span> uniqueidentifier primary <span class="keyword">key</span> <span class="keyword">default</span> newid(),</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">nvarchar</span>(<span class="number">50</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> Products(<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="string">'socks'</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> Products(<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="string">'hats'</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> Products(<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="string">'gloves'</span>);</span><br></pre></td></tr></table></figure><h2>Orders Database</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> orders(<span class="keyword">id</span> uniqueidentifier primary <span class="keyword">key</span> <span class="keyword">default</span> newid(),</span><br><span class="line"><span class="built_in">date</span> <span class="built_in">date</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> orderLineItems(<span class="keyword">id</span> uniqueidentifier primary <span class="keyword">key</span> <span class="keyword">default</span> newid(),</span><br><span class="line">orderId uniqueidentifier,</span><br><span class="line">productId uniqueidentifier,</span><br><span class="line">quantity <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">foreign</span> <span class="keyword">key</span> (orderId) <span class="keyword">references</span> orders(<span class="keyword">id</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">declare</span> @orderID uniqueidentifier = newid();</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> orders(<span class="keyword">id</span>, <span class="built_in">date</span>)</span><br><span class="line"><span class="keyword">values</span>(@orderID, <span class="string">'2020-11-01'</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> orderLineItems(orderId, productId, quantity) <span class="keyword">values</span>(@orderID, <span class="string">'3829A43D-FD2A-4B7C-9A09-23DBF030C1DC'</span>, <span class="number">10</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> orderLineItems(orderId, productId, quantity) <span class="keyword">values</span>(@orderID, <span class="string">'233BC430-BA3F-4F5C-B3EA-4B82867FC040'</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> orderLineItems(orderId, productId, quantity) <span class="keyword">values</span>(@orderID, <span class="string">'95A20D82-EC26-4769-8840-804B88630A01'</span>, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span> @orderId = newid();</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> orders(<span class="keyword">id</span>, <span class="built_in">date</span>)</span><br><span class="line"><span class="keyword">values</span>(@orderID, <span class="string">'2020-11-02'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> orderLineItems(orderId, productId, quantity) <span class="keyword">values</span>(@orderID, <span class="string">'3829A43D-FD2A-4B7C-9A09-23DBF030C1DC'</span>, <span class="number">16</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> orderLineItems(orderId, productId, quantity) <span class="keyword">values</span>(@orderID, <span class="string">'233BC430-BA3F-4F5C-B3EA-4B82867FC040'</span>, <span class="number">99</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> orderLineItems(orderId, productId, quantity) <span class="keyword">values</span>(@orderID, <span class="string">'95A20D82-EC26-4769-8840-804B88630A01'</span>, <span class="number">0</span>);</span><br></pre></td></tr></table></figure><p>Now we need to hook up the databases to be able to see each other. We're actually just going to make products visible from the orders database. It makes more sense to me to run these queries in the database which contains the most data to minimize how much data needs to cross the wire to the other database.</p><p>So first up we need to tell the Orders database about the credentials needed to access the remote database, products. To do this we need to use a SQL account on the products database. Windows accounts and integrated security doesn't currently work for this.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">master</span> <span class="keyword">key</span> encryption <span class="keyword">by</span> <span class="keyword">password</span> = <span class="string">'monkeyNose!2'</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> scoped credential ProductDatabaseCredentials </span><br><span class="line"><span class="keyword">with</span> <span class="keyword">identity</span> = <span class="string">'ProductsDBUser'</span>, </span><br><span class="line">secret = <span class="string">'wouNHk41l9fBBcqadwWiq3ert'</span>;</span><br></pre></td></tr></table></figure><p>Next we set up an external data source for the products</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">data</span> <span class="keyword">source</span> ProductsSource <span class="keyword">with</span> </span><br><span class="line">(<span class="keyword">type</span>=RDBMS, location = <span class="string">'testias.database.windows.net'</span>, </span><br><span class="line">database_name = <span class="string">'testias'</span>, credential = ProductDatabaseCredentials);</span><br></pre></td></tr></table></figure><p>Finally we create a table definition in the Orders database that matches the remote table (without any defaults or constraints).</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> Products( <span class="keyword">id</span> uniqueidentifier,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">nvarchar</span>(<span class="number">50</span>))</span><br><span class="line"><span class="keyword">with</span> ( data_source = ProductsSource)</span><br></pre></td></tr></table></figure><p>We now have a products table in the external tables section in the object explorer</p><p><img src="https://blog.simontimms.com/images/elasticquery/testtableview.png" alt="Tables from both databases"></p><p>We can query the external table and even cross it against the tables in this database</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">name</span>, ol.quantity <span class="keyword">from</span> orderLineItems ol <span class="keyword">inner</span> <span class="keyword">join</span> products p <span class="keyword">on</span> ol.productId = p.id</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">socks   16</span><br><span class="line">socks   10</span><br><span class="line">gloves  1</span><br><span class="line">gloves  99</span><br><span class="line">hats    2</span><br><span class="line">hats    0</span><br></pre></td></tr></table></figure><p>So it is possible to run queries across databases in Azure but it takes a little set up and a little bit of thought about how to best set it up.</p><h1>Possible Gotchas</h1><ul><li>I forgot to set up the database to be able to talk to Azure resources in the firewall so I had to go back and add that</li><li>Inserting to the external table isn't supported, which is good, make the changes directly in the source database</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I seem to be picking up a few projects lately which require migrating data up to Azure SQL from an on premise database. One of the things that people tend to do when they have on premise databases is query across databases or link servers together. It is a really tempting prospect to be able to query the &lt;code&gt;orders&lt;/code&gt; database from the &lt;code&gt;customers&lt;/code&gt; database. There are, of course, numerous problems with taking this approach not the least of which is making it very difficult to change database schema. We have all heard that it is madness to integrate applications at the database level and that&#39;s one of the reasons.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">The trimStart rabbit hole</title>
    <link href="https://westerndevs.com/_/typescript-definition/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/typescript-definition/</id>
    <published>2020-09-28T18:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.380Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I was bragging to <a href="https://westerndevs.com/bios/dave_paquette/">David</a> about a particularly impressive piece of TypeScript code I wrote last week</p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (body.<span class="keyword">trim</span>().<span class="keyword">startsWith</span>(<span class="string">'&lt;'</span>)) &#123; <span class="comment">//100% infallible xml detection</span></span><br></pre></td></tr></table></figure><p>He, rightly, pointed out that <code>trimStart</code> would probably be more efficient. Of course it would! However when I went to make that change there was only <code>trim</code>, <code>trimLeft</code> and <code>trimRight</code> in my TypeScript auto-complete drop down.</p><p><img src="https://blog.simontimms.com/images/trimStart/missing.png" alt="TrimStart and TrimEnd are missing"></p><p>Odd. This was for sure a real function because it appears in the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/trimStart" target="_blank" rel="noopener">MDN docs</a>.</p><p>A reasonable person would have used trimLeft and moved on but it was Monday and I was full of passion for programming. So I went down the rabbit hole.</p><p>Checking out the TypeScript directory in my node_modules I found that there were quite a few definition files in there. These were the definition files that described the JavaScript language itself rather than any libraries. Included in that bunch was one called <code>lib.es2019.string.d.ts</code>. This file contained changes which were made to the language in es2019.</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> String &#123;</span><br><span class="line">    <span class="comment">/** Removes the trailing white space and line terminator characters from a string. */</span></span><br><span class="line">    trimEnd(): <span class="built_in">string</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Removes the leading white space and line terminator characters from a string. */</span></span><br><span class="line">    trimStart(): <span class="built_in">string</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Removes the leading white space and line terminator characters from a string. */</span></span><br><span class="line">    trimLeft(): <span class="built_in">string</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Removes the trailing white space and line terminator characters from a string. */</span></span><br><span class="line">    trimRight(): <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>So I must be targeting the wrong thing! Sure enough in my <code>tsconfig.js</code> I was targeting <code>es5</code> on this project. When we started this was using an older version of node on lambda that didn't have support for more recent versions of ES. I checked and the lambda was running node 12.18.3 and support for ES2020 landed in node 12.9 so I was good to move up to es2020 as a target.</p><p>Incidentally you can check the running node version in JavaScript by running</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">console</span>.log(<span class="string">'Versions: '</span> + <span class="built_in">JSON</span>.stringify(process.versions));</span><br></pre></td></tr></table></figure><p>After updating my <code>tsconfig.js</code> and restarting the language server all was right in the world.</p><p><img src="https://blog.simontimms.com/images/trimStart/there.png" alt="The missing functions appear"></p>]]></content>
    
    <summary type="html">
    
      If you&#39;re missing expected functions in your TypeScript app the problem might be an incorrect target
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Flutter unit testing with native channels</title>
    <link href="https://westerndevs.com/_/flutter-tests-with-native/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/flutter-tests-with-native/</id>
    <published>2020-04-01T14:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.376Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Today I was digging through some unit tests in our flutter project that seemed to be failing on my machine but not necessarily in other places like our build pipeline. The problem was that we had some calls to async methods which were not being awaited properly. I fixed those up and they uncovered a bunch of more serious problems in our tests. We were calling out to validate a phone number with libphonenumber and now we were actually awaiting the call properly we saw this error</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[master  +0 ~2 -0 !]&gt; flutter <span class="built_in">test</span></span><br><span class="line">00:03 +27 -1: <span class="built_in">test</span>\unit\providers\create_account_provider_test.dart: Real mobile number - is valid [E]</span><br><span class="line">  MissingPluginException(No implementation found <span class="keyword">for</span> method isValidPhoneNumber on channel codeheadlabs.com/libphonenumber)</span><br><span class="line">  package:blah/providers/create_account_provider.dart 101:9  CreateAccountProvider.setMobileNumber</span><br><span class="line"></span><br><span class="line">00:03 +28 -2: <span class="built_in">test</span>\unit\providers\create_account_provider_test.dart: Valid state <span class="keyword">if</span> properties are valid [E]</span><br><span class="line">  MissingPluginException(No implementation found <span class="keyword">for</span> method isValidPhoneNumber on channel codeheadlabs.com/libphonenumber)</span><br><span class="line">  package:blah/providers/create_account_provider.dart 101:9  CreateAccountProvider.setMobileNumber</span><br></pre></td></tr></table></figure><p>As it turns out libphonenumber is actually a native implementation wrapped up with flutter. To communicate with this native code isn't possible in a test environment so it needs to be mocked. This can be done by mocking the channel.</p><p>In the setUp() for the unit tests I added a call to setMockMethodCallHandler like so</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> _channel = <span class="keyword">const</span> MethodChannel(<span class="string">'codeheadlabs.com/libphonenumber'</span>);</span><br><span class="line">setUp(() <span class="keyword">async</span> &#123;</span><br><span class="line">_channel.setMockMethodCallHandler((MethodCall methodCall) <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;);  </span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">tearDown(()&#123;</span><br><span class="line">_channel.setMockMethodCallHandler(<span class="keyword">null</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>With this call in place I was able to run the test without issue.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Today I was digging through some unit tests in our flutter project that seemed to be failing on my machine but not necessarily in other places like our build pipeline. The problem was that we had some calls to async methods which were not being awaited properly. I fixed those up and they uncovered a bunch of more serious problems in our tests. We were calling out to validate a phone number with libphonenumber and now we were actually awaiting the call properly we saw this error&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Solve WebForms Errors with PreCompilation</title>
    <link href="https://westerndevs.com/_/find-webforms-errors-with-precompilation/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/find-webforms-errors-with-precompilation/</id>
    <published>2020-04-01T00:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.376Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I have a webforms application that I help maintain. Today I made some change and managed to break one of the pages on the site. The error was unbelievably unhelpful.</p><p><img src="https://blog.simontimms.com/images/precompilewebforms/500.png" alt="Wut? 500 error with no useful details"></p><p>In older versions of ASP.NET it is nearly impossible to diagnose these sorts of errors. Was it something with the web.config? Did I mess up the dependency injection? I messed about a bit and found that if I deleted everything out of the <code>.aspx</code> file things worked. So it was the view. But what?</p><a id="more"></a><p>I don't know where the logs go for these sorts of errors but I couldn't find them. But knowing that the error was in the ASPX file I figured I could get the errors by compiling the files. You can actually precompile the ASPX files pretty easily in your post build step. It does take some time so I don't typically have it enabled for development but this is the command</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">%windir%</span><span class="symbol">\M</span>icrosoft.NET<span class="symbol">\F</span>ramework64<span class="symbol">\v</span>4.0.30319<span class="symbol">\a</span>spnet_compiler.exe -v / -p "$(SolutionDir)$(ProjectName)"</span><br></pre></td></tr></table></figure><p>Sure enough running that build gave me the error message I was looking for:</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">error </span>ASPPARSE: Literal content ('&lt;!--') is not allowed within a 'Telerik.Web.UI.GridColumnCollection'.</span><br></pre></td></tr></table></figure><p>This is the second time in a week XML comments caught me. But the story here is that if you're running into unexpected 500 errors on a webform page try compiling the page using <code>aspnet_compiler</code></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I have a webforms application that I help maintain. Today I made some change and managed to break one of the pages on the site. The error was unbelievably unhelpful.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.simontimms.com/images/precompilewebforms/500.png&quot; alt=&quot;Wut? 500 error with no useful details&quot;&gt;&lt;/p&gt;
&lt;p&gt;In older versions of ASP.NET it is nearly impossible to diagnose these sorts of errors. Was it something with the web.config? Did I mess up the dependency injection? I messed about a bit and found that if I deleted everything out of the &lt;code&gt;.aspx&lt;/code&gt; file things worked. So it was the view. But what?&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Allow Azure DevOps Hosted Agents Through Firewall</title>
    <link href="https://westerndevs.com/_/Allow-hosted-agent-through-firewall/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/Allow-hosted-agent-through-firewall/</id>
    <published>2020-01-10T14:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.376Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I have an on-premise (well in a third party data center but close enough) database which I'd like to update via a build in a hosted agent on Azure. We've done this before in Jenkins by just allowing a specific IP address through the firewall. However we're in the process of moving to DevOps for this build. Unfortunately, the hosted build agents don't have entirely predictable IP addresses. Every week Microsoft publishes a list of all the IP addresses in Azure. It is a huge json document and for our region (Central Canada) there are about 40 IP addresses ranges the build agent could be in. We want an automated way to update our firewall rules based on this list.</p><a id="more"></a><p>To do so we make use of the Azure Powershell extensions. The commandlet Get-AzNetworkServiceTag is an API based way to get the IP ranges. You can then pass that directly into the firewall rules like so</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$addrs</span> = ((<span class="built_in">Get-AzNetworkServiceTag</span> <span class="literal">-Location</span> canadacentral).Values|<span class="built_in">Where-Object</span> &#123; <span class="variable">$_</span>.Name <span class="operator">-eq</span> <span class="string">"AzureCloud.canadacentral"</span> &#125;).Properties.AddressPrefixes</span><br><span class="line"><span class="built_in">Set-NetFirewallRule</span> <span class="literal">-DisplayName</span> <span class="string">"Allow SQL 1433 Inbound"</span> <span class="literal">-RemoteAddress</span> <span class="variable">$addrs</span></span><br></pre></td></tr></table></figure><p>Running this once a week lets us keep the firewall up to date with the hosted agent ranges.</p><p>Bonus: If you want to see the remote addresses in your firewall rule currently then this will do it</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Get</span>-NetFirewallRule -<span class="keyword">Direction</span> Inbound -Action Allow -<span class="keyword">Enabled</span> <span class="keyword">True</span> -<span class="keyword">Verbose</span> | ? DisplayName -like <span class="string">"Allow SQL 1433 Inbound"</span> | <span class="keyword">Get</span>-NetFirewallAddressFilter |<span class="keyword">Select</span>-Object RemoteAddress -ExpandProperty RemoteAddress</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I have an on-premise (well in a third party data center but close enough) database which I&#39;d like to update via a build in a hosted agent on Azure. We&#39;ve done this before in Jenkins by just allowing a specific IP address through the firewall. However we&#39;re in the process of moving to DevOps for this build. Unfortunately, the hosted build agents don&#39;t have entirely predictable IP addresses. Every week Microsoft publishes a list of all the IP addresses in Azure. It is a huge json document and for our region (Central Canada) there are about 40 IP addresses ranges the build agent could be in. We want an automated way to update our firewall rules based on this list.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">UNION vs. UNION ALL in SQL Server</title>
    <link href="https://westerndevs.com/_/UNION-vs-UNION-ALL/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/UNION-vs-UNION-ALL/</id>
    <published>2019-12-30T14:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.376Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I really dislike database queries which are slow for no apparent reason. I ran into one of those today. It queries over a few thousands of well indexed rows and returned a handful, perhaps 3, records. Time to do this? 33 seconds. Well that's no good for anybody. Digging into the query I found that it actually used a <code>UNION</code> to join 3 sets of similar data together. I go by the rule of thumb that SQL operations which treat data as sets and do things with that in mind are efficient. I'm not sure where I read that but it has stuck with me over the years.  What it suggests is that you should avoid doing things like looping over rows or calling functions on masses of data.</p><p>As it turns out there are actually two different <code>UNION</code> operators in SQL Server: <code>UNION</code> and <code>UNION ALL</code>. They differ in how they handle duplicate entries. <code>UNION</code> will check each entry to ensure that it exists in the output only one time.</p><a id="more"></a><p>So if you had results like</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">ID</span>     <span class="keyword">Name</span></span><br><span class="line"> <span class="number">1</span>     Bob</span><br><span class="line"> <span class="number">2</span>     Jane</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> b</span><br><span class="line"></span><br><span class="line"><span class="keyword">ID</span>     <span class="keyword">Name</span></span><br><span class="line"> <span class="number">3</span>     Sally</span><br><span class="line"> <span class="number">2</span>     Jane</span><br></pre></td></tr></table></figure><p>The result of running</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> a</span><br><span class="line"><span class="keyword">union</span> </span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> b</span><br><span class="line"></span><br><span class="line"><span class="keyword">ID</span>     <span class="keyword">Name</span></span><br><span class="line"> <span class="number">1</span>     Bob</span><br><span class="line"> <span class="number">3</span>     Sally</span><br><span class="line"> <span class="number">2</span>     Jane</span><br></pre></td></tr></table></figure><p>Here the duplicate record 2 is only returned once. On the other hand <code>UNION ALL</code> will assume that the result sets are already unique and return whatever it is given</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> a</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> b</span><br><span class="line"></span><br><span class="line"><span class="keyword">ID</span>     <span class="keyword">Name</span></span><br><span class="line"> <span class="number">1</span>     Bob</span><br><span class="line"> <span class="number">2</span>     Jane</span><br><span class="line"> <span class="number">3</span>     Sally</span><br><span class="line"> <span class="number">2</span>     Jane</span><br></pre></td></tr></table></figure><p><code>UNION ALL</code> is, as a result of not doing this duplicate check, far faster than <code>UNION</code>. On the data sets I tried the savings were between 40% and 95%. It isn't always the right answer but is another tool on your toolbelt.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I really dislike database queries which are slow for no apparent reason. I ran into one of those today. It queries over a few thousands of well indexed rows and returned a handful, perhaps 3, records. Time to do this? 33 seconds. Well that&#39;s no good for anybody. Digging into the query I found that it actually used a &lt;code&gt;UNION&lt;/code&gt; to join 3 sets of similar data together. I go by the rule of thumb that SQL operations which treat data as sets and do things with that in mind are efficient. I&#39;m not sure where I read that but it has stuck with me over the years.  What it suggests is that you should avoid doing things like looping over rows or calling functions on masses of data.&lt;/p&gt;
&lt;p&gt;As it turns out there are actually two different &lt;code&gt;UNION&lt;/code&gt; operators in SQL Server: &lt;code&gt;UNION&lt;/code&gt; and &lt;code&gt;UNION ALL&lt;/code&gt;. They differ in how they handle duplicate entries. &lt;code&gt;UNION&lt;/code&gt; will check each entry to ensure that it exists in the output only one time.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Bulk Load and Merge Pattern</title>
    <link href="https://westerndevs.com/_/bulk-load-and-merge/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/bulk-load-and-merge/</id>
    <published>2019-10-12T04:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.376Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>The more years you spend programming the more you run into situations you've run into before. Situations you now know, instinctively, how to address. I suppose this is &quot;experience&quot; and is what I'm paid the medium dollars for. One such problem I've solved at least a dozen times over the years is updating a bunch of data in a database from an external source. This, as it turns out, can be a great source of poor performance if you don't know how to address it. Let's dig into my approach.</p><a id="more"></a><p>To start with let's give some examples of the problem</p><ul><li>update a database with the result of a web service call</li><li>load an Excel workbook or CSV file into the database</li><li>synchronize an external data source with your own cache in a database</li></ul><p>The approach that I commonly see people take is to get the records to load into the database and loop over them, checking them against existing records. It looks something like</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Update</span>(<span class="params">DbContext context, IEnumerable&lt;ExternalData&gt; toLoad</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">foreach</span>(<span class="keyword">var</span> record <span class="keyword">in</span> toLoad)&#123;</span><br><span class="line">        <span class="keyword">var</span> dbRecord = context.Find(record.Id);</span><br><span class="line">        <span class="keyword">if</span>(dbRecord != <span class="literal">null</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            dbRecord.Field1 = record.Field1;</span><br><span class="line">            ...</span><br><span class="line">            context.Save(dbRecord);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            context.Add(record);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This is a pretty logical approach. Any existing record is updated, any new record is inserted. Problem is that you're running 2 database operations for every record that comes in. Try to load 10k records and all of a sudden you're in for a world of hurt. It gets even scarier if you're running all this inside a transaction which might live a minute or two. Operations like this are likely to be subject to lock escalation up to table locks which is certainly not something you want.</p><h1>Bulk Loading</h1><p>Way back in my university days we had a database class which was so popular the professor taught 2 sessions back to back. This professor was famous for wearing brown sweaters no matter the time of year. Because we had two sessions every day I'd grab somebody from the previous class and ask what the class covered that day.</p><p>On this day the professor was talking about bulk loading, it was the subject of some of his research. I asked a fellow in the previous class what they covered</p><p>&quot;Bulk loading and how much faster it is than regular inserts&quot;</p><p>&quot;Oh yeah? How much faster?&quot;</p><p>&quot;312 times, I think it was&quot;</p><p>So down into the basement I trudged, into the windowless class room. The class started and the professor asked</p><p>&quot;How many times faster do you think bulk loading is?&quot;</p><p>He sat back, waiting for the ridiculous answers, comfortable in the knowledge that he'd spend the last month writing paper on exactly this subject.</p><p>&quot;312 times, sir&quot; I answered</p><p>He was flabbergasted that somebody would know this. He'd just spent the last month figuring out that exact number. Eventually I let him off the hook and told him where I'd found out his precise number but not until I span him some story about how Donald Kunth was my uncle.</p><p>Anyway the point of this story is that I'm a better person now and that bulk loading is way faster than doing individual inserts. When loading data into the database I like to load the data into a bulk loading table instead of directly into the destination table. That provides a staging area where changes can be made.</p><p>In C# the bulk loading API is a bit <a href="https://blogs.msdn.microsoft.com/nikhilsi/2008/06/11/bulk-insert-into-sql-from-c-app/" target="_blank" rel="noopener">comically dated</a> and relies on data tables. There are some nice wrappers for it including <a href="https://dapper-plus.net/bulk-insert" target="_blank" rel="noopener">dapper-plus</a>. Using bulk copy speeds up loading substantially, perhaps not 312 times but I've certainly seen 50-100x. This reduces the chances that the transaction will run for a long time and having it run against a non-production table makes things even less likely to be problematic.</p><p>With the data loaded we can now merge it into the live data, for this we can make use of merge.</p><h1>Merge Statement</h1><p>I have a long list of features that SQL server is, frustratingly, missing. On that list is a simple upsert statement where you can tell the database what to do if there is a conflict. Both <a href="http://www.postgresqltutorial.com/postgresql-upsert/" target="_blank" rel="noopener">Postgresql</a> and <a href="https://www.techbeamers.com/mysql-upsert/" target="_blank" rel="noopener">MySQL</a> have a nice syntax for upsert. On SQL Server you have to wade through the complex <code>MERGE</code> statement. The <a href="https://docs.microsoft.com/en-us/sql/t-sql/statements/merge-transact-sql?view=sql-server-ver15" target="_blank" rel="noopener">documentation</a> for <code>MERGE</code> has on off the longest grammars for a statement I've ever seen; as you would expect for such a powerful a command.</p><p>A very simple example looks like this</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">MERGE</span> HotelRooms <span class="keyword">AS</span> target  </span><br><span class="line">    <span class="keyword">USING</span> (<span class="keyword">SELECT</span> @roomNumber, @occupants <span class="keyword">from</span> bulkLoadHotelRooms) <span class="keyword">AS</span> <span class="keyword">source</span> (roomNumber, occupants)  </span><br><span class="line">    <span class="keyword">ON</span> (target.roomNumber = source.roomNumber)  </span><br><span class="line">    <span class="keyword">WHEN</span> <span class="keyword">MATCHED</span> <span class="keyword">THEN</span></span><br><span class="line">        <span class="keyword">UPDATE</span> <span class="keyword">SET</span> <span class="keyword">Name</span> = source.occupants  </span><br><span class="line">    <span class="keyword">WHEN</span> <span class="keyword">NOT</span> <span class="keyword">MATCHED</span> <span class="keyword">THEN</span>  </span><br><span class="line">        <span class="keyword">INSERT</span> (roomNumber, occupants)  </span><br><span class="line">        <span class="keyword">VALUES</span> (source.roomNumber, source.occupants)</span><br></pre></td></tr></table></figure><p>This will insert records into the table <code>HotelRooms</code> from the bulk load table <code>BulkLoadHotelRooms</code> matching them on the room number (the <code>MATCHED</code> clause). If there is already a room number there then the occupants are updated (the <code>NOT MATCHED</code> clause). Not shown here there is also the ability to delete records which aren't in the target table. Also not shown are about 10 more clauses. The documentation is certainly worthwhile reading.</p><h1>Wrapping Up</h1><p>Bulk loading and merging is the best approach I've found so far to load data into a database. I've loaded millions of records on dozens of projects using this approach. If there is a better way that you've found, I'd love to hear about it.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The more years you spend programming the more you run into situations you&#39;ve run into before. Situations you now know, instinctively, how to address. I suppose this is &amp;quot;experience&amp;quot; and is what I&#39;m paid the medium dollars for. One such problem I&#39;ve solved at least a dozen times over the years is updating a bunch of data in a database from an external source. This, as it turns out, can be a great source of poor performance if you don&#39;t know how to address it. Let&#39;s dig into my approach.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Debug PHP Inside A Container with VSCode</title>
    <link href="https://westerndevs.com/_/Debugging-php-in-container/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/Debugging-php-in-container/</id>
    <published>2019-07-05T23:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.376Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Sometimes good things happen to bad people and sometimes bad things happen to good people. I'll let you decide which one me developing a PHP application is. Maybe it is a bit of a mixture. This particular PHP app was a bit long in the tooth (what PHP app isn't) and ran on full VMs. My first operation was was to get it running inside a docker container because I couldn't be sure that my Windows development environment would be representative of production, then I wanted to be able to debug it. This is the story of how to do that.</p><a id="more"></a><p>Fortunately, I had some instructions on how to set up the VMs based on CentOS. Ah the good old days when installation instructions were written in word documents. The setup was a pretty standard LAMP stack and translated okay to a docker container.</p><p><img src="https://blog.simontimms.com/images/phpincontainer/lamp_stack.jpg" alt="LAMP stack - Linux, Apache, MySQL and PHP/Perl/Python"></p><p>Running the application was one thing, but I decided that what I really needed was the ability to attach a debugger to my PHP process. The PHP process inside the container. We are living in an age were VS Code is pretty amazing and it didn't fail to fulfill that promise this time. A recently announced feature in VS Code is the ability to split the front and back end of the editor. The persistence and language engines can run on a different machine from the user interface. In effect you're attaching to a remote sharing session except that the other end is inside the container.</p><p>Mind blown.</p><p>To set it up for PHP took a little bit it work. The first thing I did was install the xdebug extension for PHP. This I did by adding some lines to my Dockerfile.</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##### debugging environment #####</span></span><br><span class="line"><span class="comment"># install pecl</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum -y install php-pear git</span></span><br><span class="line"><span class="comment"># specific version of xdebug for the ancient php we're running</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pecl install xdebug-2.2.4</span></span><br><span class="line"><span class="comment"># add module to loaded modules</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">'zend_extension=/usr/lib64/php/modules/xdebug.so'</span> &gt;&gt; /etc/php.d/xdebug.ini</span></span><br><span class="line"><span class="comment"># set up the environment</span></span><br><span class="line"><span class="keyword">ENV</span> XDEBUG_CONFIG <span class="string">"remote_host=localhost remote_port=9000 remote_enable=1"</span></span><br></pre></td></tr></table></figure><p>This installs xdebug and tells it to connect to the development environment found on port 9000 which is going to be the VS Code back-end running in the container. You can connect to any host using this so if you needed to debug on some remote machine you could have xdebug connect to your local machine no problem.</p><p>Next I set up a <code>launch.json</code> in VS Code's <code>.vscode</code> directory which allowed VS Code to start debugging by listening to port 9000.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"version"</span>: <span class="string">"0.2.0"</span>,</span><br><span class="line">    <span class="attr">"configurations"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"Listen for XDebug"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"php"</span>,</span><br><span class="line">            <span class="attr">"request"</span>: <span class="string">"launch"</span>,</span><br><span class="line">            <span class="attr">"port"</span>: <span class="number">9000</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Finally I created a <code>.devcontainer/devcontainer.json</code> file which gives the remote extensions in VS Code knowledge of how to start up a container for development.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"Portal"</span>,</span><br><span class="line">    <span class="attr">"image"</span>: <span class="string">"portal"</span>,</span><br><span class="line">    <span class="attr">"appPort"</span>: [<span class="string">"8080:80"</span>],</span><br><span class="line">    <span class="attr">"extensions"</span>: [</span><br><span class="line">        <span class="string">"felixfbecker.php-debug"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"postCreateCommand"</span>: <span class="string">"git config --global core.autocrlf true"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The container is to forward port 80 to my localhost 8080 so that I can use the web browser to connect to the site. Inside the container I want the debugger extension installed so I list it under extensions. Any additional extensions like <code>bmewburn.vscode-intelephense-client</code> could also be listed here. Finally because I'm running on Windows and copying the source code over to a Linux image I run a command to change the line endings in git.</p><p>The last step is to install the Remote Development extensions which is what allows VS Code to be split between machines. Once it is installed you'll be prompted to reopen the folder inside a container.</p><p><img src="https://blog.simontimms.com/images/phpincontainer/launch_in_container.png" alt="The prompt when you open VS Code"></p><p>If you click reopen in container VS code restarts with the back end running in the container. You can tell by looking at the bottom left corner of the editor.</p><p><img src="https://blog.simontimms.com/images/phpincontainer/in_container.png" alt="Showing you're in a container"></p><p>With that all set up I was able to add break points and actually intercept calls to the PHP code.</p><p><img src="https://blog.simontimms.com/images/phpincontainer/at_breakpoint.png" alt="Hitting a breakpoint"></p><p>Super-cool!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Sometimes good things happen to bad people and sometimes bad things happen to good people. I&#39;ll let you decide which one me developing a PHP application is. Maybe it is a bit of a mixture. This particular PHP app was a bit long in the tooth (what PHP app isn&#39;t) and ran on full VMs. My first operation was was to get it running inside a docker container because I couldn&#39;t be sure that my Windows development environment would be representative of production, then I wanted to be able to debug it. This is the story of how to do that.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Durable Functions Analyzer</title>
    <link href="https://westerndevs.com/DurableFunctions/durable_functions_analyzer/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/DurableFunctions/durable_functions_analyzer/</id>
    <published>2019-02-18T00:00:00.000Z</published>
    <updated>2021-05-10T16:14:31.376Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>When it was announced the Roslyn would become the default compiler for C# in Visual Studio I was <a href="https://blog.simontimms.com/2014/04/04/roslyn-changes-everything/" target="_blank" rel="noopener">super excited</a>. I felt like it would generate all sorts of domain specific languages, custom flavors of C#, tons of custom error providers. So here we are 5 years later and almost none of it has come to pass. Why not?</p><a id="more"></a><p>Well turns out the compiler stuff is kind of hard. It is just a bridge too far for people to do any of the cool things I thought they would do. I guess we can add this to the long list of things that I'm wrong about.</p><p>But a few weeks ago I broke some code in a durable function because I was returning the wrong shaped data. I didn't find out until the code was deployed which is obviously later than I wanted. Because of the way that Durable Functions were constructed favoring magic strings and Objects it tends to be more susceptible to bugs which you wouldn't normally see in a statically typed language.</p><p>For instance consider this code</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="meta">FunctionName(<span class="meta-string">"HireEmployee"</span>)</span>]</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">async</span> Task&lt;Application&gt; <span class="title">RunOrchestrator</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    [OrchestrationTrigger] DurableOrchestrationContext context,</span></span></span><br><span class="line"><span class="function"><span class="params">    ILogger log</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">var</span> applications = context.GetInput&lt;List&lt;Application&gt;&gt;();</span><br><span class="line">    <span class="keyword">var</span> approvals = <span class="keyword">await</span> context.CallActivityAsync&lt;List&lt;Application&gt;&gt;(<span class="string">"ApplicationsFiltered"</span>, Guid.NewGuid());</span><br><span class="line">    log.LogInformation(<span class="string">$"Approval received. <span class="subst">&#123;approvals.Count&#125;</span> applicants approved"</span>);</span><br><span class="line">    <span class="keyword">return</span> approvals.OrderByDescending(x =&gt; x.Score).First();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>There are two magic strings in this code. The first is the name of the function in the annotation before the function declaration. The second is in the <code>CallActivityAsync</code> where a function called <code>ApplicationsFiltered</code> is called. If there is a typo in either of these strings the orchestration will fail at runtime.</p><p>You'll note too that we pass a Guid into that function. The function definition simply has an Object as the second argument so there is no type checking. Instead of passing in the Guid which is required there would be no compiler issues if we instead passed in a <code>Frog</code> or a <code>Puppy</code> or even an <code>int</code>.</p><p>I started working on a Roslyn analyzer which could solve some, or all of these short comings. I won't get into the technical parts of how to build an analyzer here (although I did just submit a conference talk on that).</p><p>It produces warnings (for now) when your functions aren't used correctly. Right now it will detect</p><ul><li>Incorrectly named functions</li><li>Incorrect return types from functions</li><li>Incorrect argument for functions</li><li>Orchestration annotations misapplied to arguments</li></ul><p>Here are some screenshots of it in action.</p><p><img src="https://blog.simontimms.com/images/roslynanalyzer/poc.png" alt="A misnamed function and a suggestion for what it should be called.">A misnamed function and a suggestion for what it should be called.</p><p><img src="https://blog.simontimms.com/images/roslynanalyzer/poc2.png" alt="An incorrect argument being detected">An incorrect argument being detected</p><p><img src="https://blog.simontimms.com/images/roslynanalyzer/poc3.png" alt="An incorrect return type being detected">An incorrect return type being detected</p><p><img src="https://blog.simontimms.com/images/roslynanalyzer/poc4.png" alt="Orchestration trigger on the wrong data type">Orchestration trigger on the wrong data type</p><p>If you want to try this out on your own project it is as easy as installing a <a href="https://www.nuget.org/packages/DurableFunctionsAnalyzer/" target="_blank" rel="noopener">nuget package</a>.</p><p>I'm looking for suggestions for new features or bugs in existing features. My tests are limited so any bug people can contribute will improve the product. Open an issue on <a href="https://github.com/stimms/DurableFunctionsAnalyzer" target="_blank" rel="noopener">github</a></p><p>Now I know how to build these analyzers I think I'll try to build more for internal applications.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;When it was announced the Roslyn would become the default compiler for C# in Visual Studio I was &lt;a href=&quot;https://blog.simontimms.com/2014/04/04/roslyn-changes-everything/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;super excited&lt;/a&gt;. I felt like it would generate all sorts of domain specific languages, custom flavors of C#, tons of custom error providers. So here we are 5 years later and almost none of it has come to pass. Why not?&lt;/p&gt;
    
    </summary>
    
      <category term="DurableFunctions" scheme="https://westerndevs.com/categories/DurableFunctions/"/>
    
    
  </entry>
  
</feed>
