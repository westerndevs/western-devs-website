<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Western Devs</title>
  
  <link href="/feed.xml" rel="self" type="application/atom+xml"/>
  <link href="https://westerndevs.com" rel="alternate" type="application/atom+xml"/>
  
  <updated>2023-03-04T03:49:50.994Z</updated>
  <id>https://westerndevs.com/</id>
  
  <author>
    <name>Western Devs</name>
	<uri>https://westerndevs.com</uri>
    <email>info@westerndevs.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title type="html">App Service Quota Issue</title>
    <link href="https://westerndevs.com/_/app-service-quota/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/app-service-quota/</id>
    <published>2023-03-04T05:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I was deploying an app service in a new region today and ran into a quota issue. The error message was:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: creating<span class="built_in"> Service </span>Plan: (Serverfarm Name <span class="string">"***devplan"</span> /<span class="built_in"> Resource Group </span><span class="string">"***_dev"</span>): web.AppServicePlansClient#CreateOrUpdate: Failure sending request: <span class="attribute">StatusCode</span>=401 -- Original Error: <span class="attribute">Code</span>=<span class="string">"Unauthorized"</span> <span class="attribute">Message</span>=<span class="string">"This region has quota of 0 instances for your subscription. Try selecting different region or SKU."</span></span><br></pre></td></tr></table></figure><p>This was a pretty simple deployment to an S1 app service plan. I've run into this before and it's typically easy to request a bump in quota in the subscription. My problem today was that it isn't obvious what CPU quota I need to request. I Googled around and found some suggestion that S1 ran on A series VMs but that wasn't something I had any limits on.</p><p>Creating in the UI gave the same error</p><p><img src="/images/2023-02-10-app-service-quota.md/2023-02-10-20-45-53.png" alt="">)</p><p>I asked around and eventually somebody in the know was able to look into the consumption in that region. The cloud was full! Well not full but creation of some resources was restricted. Fortunately this was just a dev deployment so I was able to move to a different region and get things working. It would have been pretty miserable if this was a production deployment or if I was adding onto an existing deployment.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I was deploying an app service in a new region today and ran into a quota issue. The error message was:&lt;/p&gt;
&lt;figure class=&quot;highlight rout
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Allow Comments in JSON Payload in ExpressJS</title>
    <link href="https://westerndevs.com/_/express-json-comments/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/express-json-comments/</id>
    <published>2023-02-16T05:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.998Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Officially comments are not supported in the JSON format. In fact this lack of ability to comment is one of the reasons that lead to the downfall of the JSON based project system during the rewrite of the .NET some years back. However they sure can be useful to support. In my case I wanted to add some comments to the body of a request to explain a parameter in Postman. I like to keep comments as close to the thing they describe as possible so I didn't want this on a wiki somewhere nobody would ever find.</p><p>The content looked something like</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"data"</span>: &#123;</span><br><span class="line">        <span class="attr">"form_data"</span>: &#123;</span><br><span class="line">            <span class="attr">"effective_date"</span>: <span class="string">"2023-02-23"</span>,</span><br><span class="line">            <span class="attr">"match_on_per_pay_period_basis"</span>: <span class="number">0</span>, <span class="comment">/* 0 if yes, 1 if no */</span></span><br><span class="line">            <span class="attr">"simple_or_tiered"</span>: <span class="number">1</span>, <span class="comment">/* 0 if simple 1 if tiered */</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This was going to an ExpressJS application which was parsing the body using <code>body-parser</code>. These days we can just use <code>express.json()</code> and avoid taking on that additional dependency. The JSON parsing in both these is too strict to allow for comments. Fortunately, we can use middleware to resolve the issue. There is a swell package called <code>strip-json-comments</code> which does the surprisingly difficult task of stripping comments. We can use that.</p><p>The typical json paring middleware looks like</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">app.use(express.json())</span><br><span class="line"></span><br><span class="line">or </span><br><span class="line"></span><br><span class="line">app.use(bodyParser.json())</span><br></pre></td></tr></table></figure><p>Instead we can do</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> stripJsonComments <span class="keyword">from</span> <span class="string">'strip-json-comments'</span>;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">app.use(express.text&#123;</span><br><span class="line">    type: <span class="string">"application/json"</span> <span class="comment">// </span></span><br><span class="line">&#125;) <span class="comment">//or app.use(bodyParser.text(&#123;type: "application/json&#125;))</span></span><br><span class="line">app.use(<span class="function">(<span class="params">req,res,next</span>)=&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(req.body)&#123;</span><br><span class="line">        req.body = stripJsonComments(req.body);</span><br><span class="line">    &#125;</span><br><span class="line">    next();</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>This still allows us to take advantage of the compression and character encoding facilities in the original parser while also intercepting and cleaning up the JSON payload.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Officially comments are not supported in the JSON format. In fact this lack of ability to comment is one of the reasons that lead to the 
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Excel and Ruby</title>
    <link href="https://westerndevs.com/_/ruby-excel/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/ruby-excel/</id>
    <published>2023-02-15T05:00:00.000Z</published>
    <updated>2023-03-04T03:49:51.002Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Excel is the king of spreadsheets and I often find myself in situation where I have to write our Excel files in an application. I'd say that as an application grows the probability of needing Excel import or export approaches 1. Fortunately, there are lots of libraries out there to help with Excel across just about every language. The quality and usefuleness of these libraries varies a lot. In Ruby land there seem to be a few options.</p><h2>Spreadsheet</h2><p>https://github.com/zdavatz/spreadsheet/</p><p>As the name suggests this library deals with Excel spreadsheets. It is able to both read and write them by using Spreadsheet::Excel Library and the ParseExcel Library. However it only supports the older XLS file format. While this is still widely used it is not the default format for Excel 2007 and later. I try to stay clear of the format as much as possible. There have not been any releases of this library in about 18 months but there haven't been any releases of the XLS file format for decades so it doesn't seem like a big deal.</p><p>The library can be installed using</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem <span class="keyword">install</span> spreadsheet</span><br></pre></td></tr></table></figure><p>Then you can use it like so</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">require</span> <span class="string">'spreadsheet'</span></span><br><span class="line"></span><br><span class="line">workbook = Spreadsheet.open(<span class="string">"test.xls"</span>)</span><br><span class="line">worksheet = workbook.worksheet <span class="number">0</span></span><br><span class="line">worksheet.rows[<span class="number">1</span>][<span class="number">1</span>] = <span class="string">"Hello there!"</span></span><br><span class="line">workbook.write(<span class="string">"test2.xls"</span>)</span><br></pre></td></tr></table></figure><p>There are some limitations around editing files such as cell formats not updating but for most things it should be fine.</p><h2>RubyXL</h2><p>https://github.com/weshatheleopard/rubyXL</p><p>This library works on the more modern XLSX file formats. It is able to read and write files with modifications. However there are some limitations such as being unable to insert images</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">require</span> <span class="string">'rubyXL'</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># only do this if you don't care about memory usage, otherwise you can load submodules separately</span></span><br><span class="line">  <span class="comment"># depending on what you need</span></span><br><span class="line"><span class="keyword">require</span> <span class="string">'rubyXL/convenience_methods'</span></span><br><span class="line"></span><br><span class="line">workbook = RubyXL::Parser.parse(<span class="string">"test.xlsx"</span>)</span><br><span class="line">worksheet = workbook[<span class="number">0</span>]</span><br><span class="line">cell = worksheet.cell_at(<span class="string">'A1'</span>)</span><br><span class="line">cell.change_contents(<span class="string">"Hello there!"</span>)</span><br><span class="line">workbook.write(<span class="string">"test2.xlsx"</span>)</span><br></pre></td></tr></table></figure><h2>CAXLSX</h2><p>https://github.com/caxlsx/caxlsx</p><p>This library is the community supported version of AXLSX. It is able to generate XLSX files but not read them or modify them. There is rich support for charts, images and other more advanced excel features. The</p><p>Install using</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem <span class="keyword">install</span> caxlsx</span><br></pre></td></tr></table></figure><p>And then a simple example looks like</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">require</span> <span class="string">'axlsx'</span></span><br><span class="line"></span><br><span class="line">p = Axlsx::Package.new</span><br><span class="line">workbook = p.workbook</span><br><span class="line"></span><br><span class="line">wb.add_worksheet(<span class="symbol">name:</span> <span class="string">'Test'</span>) <span class="keyword">do</span> <span class="params">|sheet|</span></span><br><span class="line">  sheet.add_row [<span class="string">'Hello there!'</span>]</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">p.serialize <span class="string">"test.xlsx"</span></span><br></pre></td></tr></table></figure><p>Of all the libraries mentioned here the documentation for this one is the best. It is also the most actively maintained. The examples directory https://github.com/caxlsx/caxlsx/tree/master/examples gives a plethora of examples of how to use the library.</p><h2>Fast Excel</h2><p>https://github.com/Paxa/fast_excel</p><p>This library focuses on being the fastest excel library for ruby. It is actually written in C to speed it up so comes with all the caveats about running native code. Similar to CAXLSX it is only able to read and write files and not modify them.</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">require</span> <span class="string">'fast_excel'</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># constant_memory: true streams changes to disk so it means that you cannot</span></span><br><span class="line">  <span class="comment"># modify an already written record</span></span><br><span class="line">workbook = FastExcel.open(<span class="string">"test.xlsx"</span>, <span class="symbol">constant_memory:</span> <span class="literal">true</span>)</span><br><span class="line">worksheet = workbook.add_worksheet(<span class="string">"Test"</span>)</span><br><span class="line"></span><br><span class="line">bold = workbook.bold_format</span><br><span class="line">worksheet.set_column(<span class="number">0</span>, <span class="number">0</span>, FastExcel::DEF_COL_WIDTH, bold)</span><br><span class="line">worksheet &lt;&lt; [<span class="string">"Hello World"</span>]</span><br><span class="line">workbook.close</span><br></pre></td></tr></table></figure><p>As you can see here the library really excels at adding consistently shaped rows. You're unlikely to get a complex spreadsheet with headers and footers built using this tooling.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Excel is the king of spreadsheets and I often find myself in situation where I have to write our Excel files in an application. I&#39;d say t
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Defining the Problem before the Solution</title>
    <link href="https://westerndevs.com/musings/defining-problem-before-the-soltuion/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/musings/defining-problem-before-the-soltuion/</id>
    <published>2023-01-27T23:24:33.221Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Developers love to code.</p><p>I know this, because I am a developer. My heart constantly wants to code up the solution to...well anything. What I have learned over the developing and architecting enterprise software solutions, and as the solo developer of <a href="https://github.com/davidwesst/website/" target="_blank" rel="noopener">my website project</a> is how this love of code can actually slow down and sometimes halt the development of a project or feature because we get too caught up in the tech, we don't take the time to reflect and solve the actual problem.</p><p>How do you fix this habit? Before you start coding up a solution, make sure you understand the problem you are trying to solve. Seems simple enough yet developers (like me) have the habit of jumping right into the code before they even really know what they are trying to solve.</p><p>Through my years of experience solving problems with technology, I have a couple of steps I go through to help inform my solution design for problems of a variety of problems. I apply these steps when I am trying to figure out how to integrate two enterprise systems and when I'm trying to figure out the best way to implement a new feature on my website.</p><p>The steps are the same, although the effort required will vary.</p><h1>Understanding the Problem</h1><p>And I don't mean coding problem.</p><p>I mean <em>business problem</em> or <em>real life problem</em> or whatever you want to call it, but it's not a code problem. Never have I ever been asked by a client to &quot;implement a binary tree&quot; or &quot;write a sorting algorithm for sorting an array&quot;. That's not to say those aren't problems, but they aren't <em>business problems</em>. These are technical problems, and they are fun to work on...sometimes. 😅</p><p>Business problems are the reason clients engage with software developers. The client wants software to fix their problem, and they seem to think that software is the solution. Before you code <em>anything</em>, take a few moments to answer the following about the problem you're preparing to solve with code.</p><h2>1) Why is this a problem?</h2><p>I am not suggesting you second guess the client, but rather try and empathize with your client and really understand why their problem is what it is. This is where you can start to understand whether or not software development fits into the solution to the problem. I have come across this many times, where after revisiting the problem with the client, we found the best solution was a change in their business process rather than adding tools to it.</p><p>Let's assume, for the sake of this post, that you see where software can help play a role in solving the problem.</p><h2>2) What happens if we do nothing?</h2><p><img src="/images/2023-01-27-defining-problem-before-the-soltuion/nothing-sign.jpg" alt="An faded wooden sign that says the word &amp;quot;Nothing&amp;quot; in large blocky letters, set against a clear blue sky. Photo by Evan Buchholz on Unsplash.com"></p><p>Sounds silly, I know, but doing nothing is always an option and people do it all the time. But why would someone choose to do nothing? Because <em>the risk doesn't outweigh the reward</em>.</p><p>By answering this question with your client, you get to understand the risks associated with the problem. This will inform your solution design, as if the risks are high you may want to invest more time and effort into parts of the design than others. It will also give you context on the priority of your solution in the mind of your client.</p><h2>3) What KPIs or Success Metrics can your client define upfront?</h2><p>The last thing I try to do is try and pull any key performance indicators (KPIs) or metrics that will help define success for the solution. I find that most of the time, this is about turning qualitative terms and statements into quantitative ones.</p><p>For example, &quot;We need to process these forms faster&quot; should change to something like &quot;We should be able to process at least 100 forms an hour&quot;. See the difference?</p><p>You are adding clear, measurable, success criteria for your solution. The terms &quot;these forms&quot; and &quot;faster&quot; are too vague to build on. Maybe fast enough to you is 1 form a day, oy maybe 1 form a second. Your client is the expert in their business, so you should ask them so you can understand the goals and potential constraints your solution needs to address.</p><h1>Redefine the Problem</h1><p>I know-- your hands are itchy from not coding, but assuming you took the time to understand the problem, the next step is to confirm your new found knowledge. The easiest way to do that is by explaining it to someone else, like your client. If your client agrees you nailed it, you nailed it and now you're ready to start<em>designing</em> (not coding) your solution.</p><p>One thing that is not uncommon is that your definition of the problem may sound different than the problem your client originally described. This is <em>normal</em>, as <em>you</em> are the technology problem solving expert.</p><p>The fact that your definition of the problem differs from your client's isn't necessarily a bad thing either. Many times, I have found that through my problem definition process, the client gains a better understanding of root cause of their problem and their mind will shift from their presumed solution, to something else.</p><h1>Example: Adding Non-Blog Content to my Website</h1><p>Let me walk you though the process on something not so enterprise-level, but small scale, like a solo-developed website project.</p><p>I hit a problem planning the next release of my website where I realized that it was going to be very complicated and cumbersome to add non-blog content to my website, such as the presentation materials from Prairie Dev Con <a href="https://www.davidwesst.com/talks/concensus-in-the-chaos/" target="_blank" rel="noopener">here</a> and <a href="https://www.davidwesst.com/talks/cots-to-cloud/" target="_blank" rel="noopener">here</a>. At this point, here is what we know:</p><blockquote><ol><li>Client = Me</li><li>Problem = Adding non-blog content to the website is difficult.</li></ol></blockquote><p>Like a good developer, I immediately started down the path of designing a custom application that would automate all the things that make adding content difficult. It was very fun, but after a couple of hours, I caught myself and took a step back and applied my problem definition process.</p><p>Let's go through it, and we start by understanding the problem.</p><h2>1) Why is it a problem?</h2><p>It is a problem because I want to continue to add different types of content to the website. The whole purpose of the site is to create a central hub for all my work, almost like a portfolio, but more like a &quot;hub&quot; for all things I create a share. The website is built to handle blog posts or document style content, but when you add more complicated content that is made up of more than just an article or webpage, you need to add links to other data (like files) which is a manual process and is error prone.</p><p>In short, it is a problem because maintaining non-article data will be difficult.</p><h2>2) What happens if we do nothing to solve the problem?</h2><p>You can see in the <a href="https://www.davidwesst.com/talks" target="_blank" rel="noopener">talks page</a> I have already added some non-article data, which is all currently managed through a JSON file that the website generator pickups and creates pages for. I also needed to upload the files to a public storage host (Azure Blob Storage) and use copy and paste the links into the JSON, which I messed up a few times.</p><p>This was my first attempt at &quot;doing nothing&quot; for this problem, and it was difficult. The plan is to add the back catalogue of presentations I have done over the past 10 years (or more probably), which will make that JSON file exceptionally difficult to manage.</p><p>When you frame it in the context of risk: doing nothing will very likely result in an massive increase in the number of errors in the data.</p><h2>3) What KPIs can we use to measure solution success?</h2><p>If we look at the original problem statement &quot;Adding non-blog content to the website is difficult&quot;, we need to translate the term &quot;difficult&quot; into a quantitative one. This would give us a measure to determine how much easier it is to add new content.</p><p>Pulling from the answer to question 2, it's really managing the JSON file that makes things difficult. And so I asked myself (the client), what makes managing a JSON file so difficult? There are plenty of tools for that already. And this is where the <em>real problem</em> revealed itself.</p><p>The relationships between the data leads to errors. Maintaining these relationships manually is exceptionally difficult, and we only have two relationships so far: presentation to event, and presentation to the presentation materials.</p><h2>Redefining the Problem</h2><p>Now that we know the <em>real</em> problem, we can redefine problem:</p><blockquote><p>Problem = The process of manually managing the relationships between content types and data is exceptionally error prone and not scalable.</p></blockquote><p>This updated problem is one that will inform the solution design moving forward. If you want to get specific about the tech needed, we have a very powerful and mature tool that will help solve data relationships: a relational database. How it informs the solution, is a whole other blog post or posts, but at least now we <em>know</em> what we are trying to solve and can use our technical expertise to solve it.</p><h1>Conclusion / TL;DR;</h1><p>Before you start designing solutions or coding, take the time to clearly define the problem you are working to solve with your client (which can be you, if its your own project). To define the problem, answer these questions first:</p><ol><li>Why is it a problem?</li><li>What happens if we do nothing to solve the problem?</li><li>What KPIs can we use to measure solution success?</li></ol><p>Once you have that, redefine the problem by wording it in a way that highlights the root issue to solve, along with the way to measure success. Assuming the client agrees with your redefined problem, you are ready to start using the big, beautiful brain of yours and start solution-ing!</p><p>Thanks for playing.</p><p>~ DW</p><hr><h1>Image Credit</h1><ul><li>&quot;Nothing Sign&quot; Photo by <a href="https://unsplash.com/@vnbuchholz92?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText" target="_blank" rel="noopener">Evan Buchholz</a> on <a href="https://unsplash.com/photos/z-Hu8pnt23s?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText" target="_blank" rel="noopener">Unsplash</a></li></ul>]]></content>
    
    <summary type="html">
    
      Before you create a solution, you need to understand the problem. It sounds obvious enough, yet I see developers (including myself) getting into the code and design phase before they really understand the problem they are trying to fix. These are the steps I take a properly understand a problem I am trying to solve, prior to coding or solution-ing anything.
    
    </summary>
    
      <category term="musings" scheme="https://westerndevs.com/categories/musings/"/>
    
    
      <category term="code" scheme="https://westerndevs.com/tags/code/"/>
    
      <category term="solution-architecture" scheme="https://westerndevs.com/tags/solution-architecture/"/>
    
      <category term="problem-definition" scheme="https://westerndevs.com/tags/problem-definition/"/>
    
      <category term="requirements-gathering" scheme="https://westerndevs.com/tags/requirements-gathering/"/>
    
      <category term="defining-value" scheme="https://westerndevs.com/tags/defining-value/"/>
    
  </entry>
  
  <entry>
    <title type="html">Docker Build Hangs When Adding Key with apt-key in WSL2</title>
    <link href="https://westerndevs.com/coding/problem-solution/docker-build-hangs-on-apt-key-in-wsl2/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/coding/problem-solution/docker-build-hangs-on-apt-key-in-wsl2/</id>
    <published>2023-01-12T02:43:58.005Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<h2>Problem</h2><p>When trying to add a key using <code>apt-key</code> on a Debian 11 docker image, the step seems to run infinitely.</p><p>The screenshot below highlights this problem when adding a key that is necessary to validate the mono-complete package.</p><p><img src="/images/2023-01-11-docker-build-hangs-on-apt-key-in-wsl2/console-screenshot.png" alt="A terminal window showing the steps of a docker build command along with their run times. The command that is currently being run is an apt-key command that is still running after 8078.8 seconds"></p><h3>Details</h3><p>I setup a <a href="https://containers.dev/" target="_blank" rel="noopener">DevContainer</a> to build Inky, a interactive fiction editor I like for game projects, without having to install all the build dependencies on my local machine. The Docker container build worked on my Linux machine, but would hang on my Windows 11 box, using Docker Desktop with WSL2. More specifically, it would run forever on the <code>apt-key</code> command, as specified by the <a href="https://www.mono-project.com/download/stable/#download-lin-debian" target="_blank" rel="noopener">mono install instructions</a>.</p><p>If you need an example, take a look at <a href="https://github.com/davidwesst/inky/tree/8a5809f0b5f0a480b37b759443479fa13b9cf18c" target="_blank" rel="noopener">my Inky repository fork at that specific point</a>.</p><h2>Solution</h2><p>The issue was that the command specifically references port 80 in the URL to the keyserver. In the end, I changed:</p><p><code>sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF</code></p><p>to</p><p><code>sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv-keys 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF</code></p><p>You can see the specifics in the <a href="https://github.com/davidwesst/inky/commit/52b9d1a2e577061ae1da735e05cf466712bb9279" target="_blank" rel="noopener">next commit in my example repository</a> in the following commit here.</p><h3>Reference</h3><p>I was put on the right track with a Stack Overflow post trying to solve a similar issue with <code>apt-key</code>. Scrolling through the answers, I found this one: <a href="https://unix.stackexchange.com/a/128704" target="_blank" rel="noopener">LINK</a></p><h3><code>apt-key</code> Deprecation Notice</h3><p>If you look at the <a href="https://manpages.debian.org/testing/apt/apt-key.8.en.html" target="_blank" rel="noopener">Debian documentation for <code>apt-key</code></a> or try running the command yourself, you might notice the deprecation warning. Underneath the hood, it runs the appropriate command in Debian 11, but will be gone after Debian 11 and Ubuntu 22.04.</p><p>Just something to note for those looking over this solution in the future.</p><h2>Conclusion / TL;DR;</h2><p>I needed to remove the port number from the keyserver URL used in my <code>apt-key</code> command.</p><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      The solution to the problem where an apt-key command seems to run forever in your docker build.
    
    </summary>
    
      <category term="coding" scheme="https://westerndevs.com/categories/coding/"/>
    
      <category term="problem-solution" scheme="https://westerndevs.com/categories/coding/problem-solution/"/>
    
    
      <category term="docker" scheme="https://westerndevs.com/tags/docker/"/>
    
      <category term="linux" scheme="https://westerndevs.com/tags/linux/"/>
    
      <category term="wsl2" scheme="https://westerndevs.com/tags/wsl2/"/>
    
      <category term="apt-key" scheme="https://westerndevs.com/tags/apt-key/"/>
    
      <category term="debian" scheme="https://westerndevs.com/tags/debian/"/>
    
      <category term="devcontainer" scheme="https://westerndevs.com/tags/devcontainer/"/>
    
  </entry>
  
  <entry>
    <title type="html">Highlight Reel for 2022</title>
    <link href="https://westerndevs.com/musings/highlight-reel-for-2022/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/musings/highlight-reel-for-2022/</id>
    <published>2023-01-05T21:47:02.098Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>While working on revamping my website and blog, I revisited a number of my old posts. Two of my favourites are the Highlight Reels for <a href="https://www.githubunwrapped.com/davidwesst" target="_blank" rel="noopener">2014</a> and <a href="https://github.com/cocobokostudios/videogamelibrary" target="_blank" rel="noopener">2015</a> as they document how I felt about myself and my accomplishments at that point in my life and career. Considering that this past year has been one of pretty extreme personal transformation, I thought it would be appropriate to document my self-reflection for 2022 in a similar style. The difference this time around will be that I focus on observed behaviours related to event and work, rather than the events themselves. More specifically, the behaviours that I like, love, and need to improve.</p><p>Don't worry-- it's not all feelings. It's data too. All my observed behaviours relate to my projects I worked on throughout the year on GitHub, which provides great insights into my contributions. I'll be using my GitHub contributions for 2022 to highlight the spots where I can identify the behaviour.</p><p>Why do this? Because I want to remind myself an others that if you feel like you are stuck, you are better off finding the source of the problem-- even if it makes you face some hard truths. By understanding the root problem, you can work at resolving it, even it it involves changing what you believe is your best approach to work.</p><h2>I <em>love to learn</em> about code</h2><p><img src="./gh2022-contributions_learning.png" alt="The GitHub contribution graph for user davidwesst, consisting of coloured squares ranging from grey for no contributions to bright green for many, for all the weeks in the year. There is a bright red, mouse-written work &amp;quot;learning&amp;quot; with an arrow pointing to a bright red circle around the squares for January and February 2022 where there appears to be a consistent amount of git activity."></p><p>At the end of 2021, I started looking at the job market and started to notice that the jobs I wanted (or thought I wanted) relied on skills that I have not been able to practice as part of my day job. Coding is no longer one of my responsibilities, only planning, designing, and providing oversight. This sparked the urge to refresh my skills and prove to myself that I <em>could</em> do for these jobs, and that all I had to do was put in the time.</p><p>And so began a series of LeetCode challenges, learning exercises, and review of various problems so that I could skill up and strengthen those coding muscles again. This is what you see in the contribution graph for the first 2-3 months of 2022.</p><p>Although this spark eventually faded as it does, I realized something about myself. I realized that it's not the code I love, but the learning about code and how to apply code in various ways. New languages, patterns and practices, solution architecture, whatever-- if it involves coding something, you can count I'll be interested.</p><h3>Lesson Learned: Burnout</h3><p>This is example highlight Q1 of 2022, yet there are plenty of other times where I spent time learning new tech. Experimenting with Go and Rust as part of my <a href="https://github.com/cocobokostudios/videogamelibrary" target="_blank" rel="noopener">VGL project</a> (more about that later). A brief experiment with Q# back in 2019 early 2020, and my continual urge to learn C/C++ along with the DevOps tools around it. These are all things that have sparked that <em>love of learning code</em> over the past few years, and each time it's the same pattern: spark of interest, dive deep into the learning, burn out because you don't know where to go with this knowledge.</p><p>Which brings me to the lesson learned: I need to direct my learning energy towards a goal. This way, when the excitement of learning something new fades I will still have a goal in my sights and continue to channel that energy towards something, rather then letting it fade out.</p><h2>I <em>love to build things</em> out of code</h2><p>At the end of the year, I looked at my <a href="https://www.githubunwrapped.com/davidwesst" target="_blank" rel="noopener">GitHub Unwrapped video</a> and was surprised by my top languages for 2022.</p><p><img src="/images/2023-01-05-highlight-reel-for-2022/gh2022-toplanguages.png" alt="A blue and white stocking is hung on an imaginary wall with snow coming down and a TypeScript logo sitting on top of it, denoting that TypeScript was my &amp;quot;top language&amp;quot; for the year, followed up by JavaScript in second, and HTML in third"></p><p>I was trying to figure out where I had written so much TypeScript, considering that for the past few months I have been living in JavaScript and HTML. Again, going back to my contribution graph I noticed another spike in activity in May.</p><p><img src="./gh2022-contributions_building.png" alt="The GitHub contribution graph made up of squares where a large number of the squares for May 2022 show contributions, along with many more from October to December. Both sections of the graph are circled in bright red, and between them is the word &amp;quot;building&amp;quot; with arrows pointing at them."></p><p>I remembered that I decided to repurpose my learning strategy, and rather than just doing LeetCode exercises and textbook studying to strengthen my atrophied coding muscles, I would study by building something. Something that <em>I</em> found useful, all while further strengthening my skills! This was the beginning of the <a href="https://github.com/cocobokostudios/videogamelibrary" target="_blank" rel="noopener">Video Game Library or &quot;VGL&quot; project</a> where I spent time building a TypeScript-React project and included some experiments with both Go and Rust to determine which language allowed me to leverage WASM (which was yet another rabbit hole I became excited about).</p><p>In the end I shelved the project because I was letting my learning drive the project. This meant anything I wanted to learn, I added scope to the project. In the end, it become too big and my original vision was lost, but the urge to build never fades, only the &quot;something&quot; that I am building.</p><p>Looking back beyond 2022-- the idea of building something has always driven me. Building a business, a video game, or a product. It doesn't matter, as long as <em>I am building it</em>.</p><p>Where it falls over is when the scope gets too large and overwhelming. This is not uncommon amongst creative types (just ask any game developer) but building something, ideally out of code, is something that drives me. If I can channel that excitement and passion on something I believe is worth it, I think I could produce and finish something I could be proud of.</p><p>I started to make this realization about myself and my drive to build things later in the year. This is why I came back to building my website that I had let fall into dormant. I wanted to channel that excitement, energy, and knowledge into something I found valuable. My website is something I have talked about improving for years and started redoing countless times. Looking back at the contribution graph, this represents a large part of the contributions for October, November, and December for 2022. This is further evidenced by the <a href="https://github.com/davidwesst/website/releases" target="_blank" rel="noopener">releases of the website</a> I published through the same time period.</p><h3>Same Drive, Different Approach</h3><p>Reflecting on my behaviour during the VGL project in May and the website work in the last quarter of the year-- the behaviour and drive was the same. I <em>loved building something</em>, yet the VGL project went onto the shelf, and the website finally managed to get some traction.</p><p>The difference was in my approach.</p><p>For the Video Game Library project, I let the excitement of learning and drive its development, which led to scope creep and dilution of the original project vision. With the website I took the time to plan and force myself to complete releases-- no matter how small.</p><p>This change in approach enabled in a longer focus on a single project. Ultimately, that kept my excitement for my website project going longer and I kept coming back to it over and over again to make small (or sometimes larger) improvements. In fact, I am continuing those improvements today as the website is far from complete-- but it's starting to represent the vision I started.</p><h2>I <em>like</em> (not love) to share</h2><p>I have tried sharing and producing content in various forms over the years, but with <a href="https://www.davidwesst.com/blog/prairie-dev-con-2022-takeaways/" target="_blank" rel="noopener">Prairie Dev Con returning in 2022</a>, I thought I would focus some energy into preparing and share content like I used to in my <a href="https://www.davidwesst.com/tags/mvp/" target="_blank" rel="noopener">Microsoft MVP days</a>. This meant lecture-style presentations and blogging.</p><p>After three live events in 2022, and almost a blog post a week since mid-October, I realized that I don't love sharing like I used to...rather I only <em>like it</em>. It's a subtle difference, but it is definitely different than it once was.</p><p>I like it because it is a <em>practical</em> way to document my work. I love learning and building things, and sharing those things is an easy way to document my progress for others-- but more importantly myself. With the blog posts, I documented things I learned for my website like the <a href="https://www.davidwesst.com/blog/open-graph-tools-and-resources-for-web-nerds/" target="_blank" rel="noopener">Open Graph protocol</a> or my <a href="https://www.davidwesst.com/blog/does-gdpr-apply-to-personal-websites/" target="_blank" rel="noopener">implementation of GDPR compliance</a>. For the presentations, I focused on what I knew and delivered two original sessions; one about <a href="https://www.davidwesst.com/talks/concensus-in-the-chaos/" target="_blank" rel="noopener">my day job and what it is means to be an IT Architect</a> and the other a <a href="http://localhost:8080/talks/cots-to-cloud/" target="_blank" rel="noopener">case study on how to do my day job</a>.</p><p>Though this experience this year, I found that I liked the process-- but didn't love it like I used to. To me, the presentations and blog posts were necessary for other outcomes. More specifically, the presentations were my ticket to touch base with other real-life speakers and tech professionals after a multi-year hiatus. The blog posts were my way of documenting, analyzing, and appreciating my own effort into my various side projects.</p><p>In the past, with the MVP program, I blogged and shared to receive validation from my peers and the MVP program itself. Those goals are not bad ones by any stretch, but since I don't have the MVP program pushing me, I need something else to help push me. That &quot;something&quot; is myself, and the outcomes I mentioned previously. Personally, I think that means I've grown quite a bit since I was an MVP and is an great example of how 2022 has been a year filled with huge change for myself and my attitude towards work.</p><p><img src="./gh2022-contributions_sharing.png" alt="The same GitHub contribution graph from the previous two pictures, except this time the mouse-drawn word &amp;quot;sharing&amp;quot; with an arrow leading from the word to a red circle which highlights the months of October, November and December of 2022 as there are a large number of green squares with varying degree of brightness denoted that there were a large number of contributions during these months."></p><h2>The <em>need</em> to improve</h2><p>I have mentioned the good things, the changed things, and now I will go over the things I need to improve (in my opinion).</p><h3>I <em>need</em> to accept my own skills and abilities</h3><p>Everybody is different and bring different value to the table. I have led a very privileged career and have had massive success in many different areas, yet for years I have rarely taken the time to appreciate those accomplishments.</p><p>Instead, I would get caught up in comparing myself to others and what I <em>couldn't</em> do, rather than what I <em>could</em> do. I would dwell on my lack of recent coding experience, rather than celebrate the time I've spent <a href="http://localhost:8080/talks/cots-to-cloud/" target="_blank" rel="noopener">migrating legacy systems into the cloud</a>. I would focus on the jobs I did not qualify for, rather than the ones that I did qualify for.</p><p>This cycle of focusing on what is missing is lose-lose situation. There will never be enough success. The grass will always be greener on the other side of fence, no matter how many times I jump over it.</p><p>I need to remind myself of this moving forward, and hopefully you can remember that for yourself as well.</p><h3>I <em>need</em> to do more, and talk less</h3><p>People refer to me as &quot;a talker&quot;, as in, I like to talk and I'm pretty good at it.</p><p>I leverage my talking skill in my day-to-day job, but when it comes what I am trying to build for myself I need to focus on doing the work rather than talking about it.</p><p>It might be cliché, but &quot;talk is cheap&quot; and I need to talk less and do more. Plain and simple.</p><h2>Conclusion / TL;DR;</h2><p>In short, I identified cyclical behaviours and patterns in myself that relate to the work I put into my various side projects and personal (and professional) development. In 2022, I noticed the following about myself:</p><ol><li>I <em>love</em> to learn about code</li><li>I <em>love</em> to build things out of the things I learn (in code)</li><li>I <em>like</em> to share what I build and learn (for future me, and anyone else willing to listen)</li></ol><p>The first two are my way of channelling creativity, which is why I love them so much. Although I used to <em>love</em> sharing my knowledge, at this point in my career and life, I <em>like</em> it as it is a practical way for me to document things as I discover them and connect with others, rather than as a method to be validated and rewarded.</p><p>In terms of how I can improve:</p><ol start="4"><li>I <em>need</em> to accept my own skills and abilities</li><li>I <em>need</em> to do more and talk less (but talk about it once it is actually done)</li></ol><p>I <em>need</em> to accept and embrace my current skills and abilities, rather than focusing on what I think I am lacking. I also need to focus more on implementing my ideas rather that talking about them. Once I have something built, then I can talk more about it-- but until it's built, I need to focus my energy and excitement on the build rather than the talk.</p><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      When a new year arrives, it is a great opportunity to take a moment to reflect on where you started at the beginning of the year, and where you ended. When I look back on 2022, I noticed events reflected in my GitHub contribution graph that highlight some common cycles in my own behaviour. I want to take a moment to document this, and hopefully you can use this an example to examine your own progress and behaviour patterns that might be aiding (or impeding) your own personal and professional growth.
    
    </summary>
    
      <category term="musings" scheme="https://westerndevs.com/categories/musings/"/>
    
    
      <category term="javascript" scheme="https://westerndevs.com/tags/javascript/"/>
    
      <category term="typescript" scheme="https://westerndevs.com/tags/typescript/"/>
    
      <category term="github" scheme="https://westerndevs.com/tags/github/"/>
    
      <category term="prdc-2022" scheme="https://westerndevs.com/tags/prdc-2022/"/>
    
      <category term="mvp" scheme="https://westerndevs.com/tags/mvp/"/>
    
      <category term="code" scheme="https://westerndevs.com/tags/code/"/>
    
      <category term="burnout" scheme="https://westerndevs.com/tags/burnout/"/>
    
  </entry>
  
  <entry>
    <title type="html">Happy Holidays from the Western Devs</title>
    <link href="https://westerndevs.com/_/happy-holidays-2022/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/happy-holidays-2022/</id>
    <published>2022-12-24T22:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name></name>
	  <email></email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Every year, the Western Devs try to put together a virtual holiday gathering across 7 timezones to catch-up, have fun, and celebrate the holiday season. To mark the occasion, we had AI generate a poem to help us enjoy the season along with an image for which we will not provide context for.</p><blockquote><p>'Twas the night before Christmas, and all through the landThe Western Devs group was busily at handWorking on projects, coding with careIn hopes that the deadlines would soon be met, with flair</p><p>he computers were humming, the monitors aglowAs the developers worked on code, to and froSome were debugging, some were designingAll with the goal of creating something exciting</p><p>But as the night wore on, and the work was almost throughThe developers stopped, and a cheer rose anewThey had made it, they had finished the taskNow it was time to put down the code and unwind at last</p><p>So they gathered around, for the holiday was hereRaised a glass to a year of hard work and good cheerHere's to the Western Devs group, may your future be brightMerry Christmas to all, and to all a good night!</p></blockquote><p>Have yourselves a great holiday season and new year!</p><p><img src="/images/2022-12-24-happy-holidays-2022/lobster.png" alt="a portrait of the lobster dressed for bed and sipping a glass of champagne after a one night stand in Seattle. The lobster is sitting on a hotel bed, wearing an oversized aqua robe, with a shirt and bowtie, but no pants, and a set of ski goggles."></p><p>Cheers!</p>]]></content>
    
    <summary type="html">
    
      From our computers to yours, we wanted to take a moment to share with your part of our annual Western Devs Holiday Extranvaganza virtual celebration!
    
    </summary>
    
    
      <category term="happy-holidays" scheme="https://westerndevs.com/tags/happy-holidays/"/>
    
      <category term="poem" scheme="https://westerndevs.com/tags/poem/"/>
    
      <category term="fun" scheme="https://westerndevs.com/tags/fun/"/>
    
  </entry>
  
  <entry>
    <title type="html">Speaking at Tech Events Helps You Grow</title>
    <link href="https://westerndevs.com/_/speaking-at-tech-events-helps-you-grow/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/speaking-at-tech-events-helps-you-grow/</id>
    <published>2022-12-20T21:59:37.185Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I was lucky enough to be selected to speak at all three <a href="https://www.prairiedevcon.com" target="_blank" rel="noopener">Prairie Dev Con 2022</a> events this year, after a hiatus from speaking at live tech events. The experience of submitting and delivering a couple of session reminded me how important speaking at these sorts of events has been over the years and now they account for a large part of my career growth. On top of that, I have had many people who are entering tech ask me about my experience and wanted to share it for others who might be wondering what benefits actually are.</p><h1>You need to sell yourself and your session</h1><p>When the call for speakers opens up, you are required to submit a summary of your talk and yourself. I call this the pitch process, as your submission is your moment to convince the event organizers you are worth betting on.</p><p>It might sound stressful, but its not. It's a pretty low key process considering you are just filling out a form, and it's low stakes. If you don't make the cut then, you cam try again next time.</p><p>The point is that you need take the time to think about wht you're worth the effort, because you are definitely worth it! You know it, so now is your chance to practice.</p><h1>Connecting with Other Speakers</h1><p>Once you're accepted, you get a chance to connect with other speakers. These folks are like minded people who are willing to spend their time sharing their experiences and expertise. Sit with people you don't know and have conversations. Introduce yourself. Talk about what you do and listen to what they do. When you're done, find them on LinkedIn and remind them where you met them.</p><p>I have met some of the best people this way and have continued to stay connected beyond the conference (shout out to the <a href="https://www.westerndevs.com" target="_blank" rel="noopener">WesternDevs</a>).</p><h1>A Live Studio Audience</h1><p>As much as I appreciate livestreaming and virtualized meetings, speaking in the same room as other humans is very different and definitely develops a different set of skills and strengths. The interaction you get with your audience during and after you deliver your session is something I have not been able to replicate in the digitally transformed world we live in today, in 2022.</p><p>Just to be clear, something will go wrong...and that's okay.</p><p>No matter how much you prep, something will go wrong. A demo will fail, a slide will be out of order, a question will be asked that you don't have the answer to. The key  is in how you react and respond to the situation. These &quot;mistakes&quot; are what has made me a better presenter in my day job. It has also helped me learn to stay calm and collected when pressure is being applied.</p><p><img src="/images/2022-12-20-speaking-at-tech-events-helps-you-grow/prdc2022-audience.png" alt="&amp;quot;Five rows of tables with white table clothes with people attentively looking forward at the speaker, who is not in frame, with a PowerPoint slide on the back wall describing solution architecture at the University of Manitoba"></p><h1>Side Note: Considerations Before Committing</h1><p>As a side, I wanted to note that not all conferences are created equally.</p><p>Before you submit your session take note on what the conference does to support their speakers. A few questions to ask yourself before you commit your time and effort to a conference:</p><ul><li>Do they cover your travel and accommodation?</li><li>Does it include your admission into the conference?</li><li>Do you still own your content when your done the conference?</li></ul><p>There are no right or wrong answers to these questions, but you should consider what you're getting out of the deal when you submit sessions to a conference beyond professional development.</p><p>Just remember that the speakers are the talent that makes a conference possible. Your work is valuable, and the conference team should ensure you feel appreciated, ome way or another.</p><h1>TL;DR; / Conclusion</h1><p>Speaking at in-person events, like tech conferences and user groups, is a a great way to grow as a professional. Key benefits are:</p><ul><li>You learn promote yourself and your session through the session submission process (a.k.a. the pitch process)</li><li>Connecting with other speakers who are as passionate as you are about sharing their tech experience</li><li>Reacting to a live audience and the mistakes you make in front of them</li><li>Don't forget that your effort is valuable and before you submit a session, make sure the event makes you feel like you are getting a fair deal</li></ul><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      A large part of my career growth is tied directly to speaking at tech events like conferences and user groups. I have had many people ask me about my experience and wanted to share it for others who might be wondering what benefits actually are. 
    
    </summary>
    
    
      <category term="prairie-dev-con" scheme="https://westerndevs.com/tags/prairie-dev-con/"/>
    
      <category term="public-speaking" scheme="https://westerndevs.com/tags/public-speaking/"/>
    
      <category term="prdc" scheme="https://westerndevs.com/tags/prdc/"/>
    
      <category term="community" scheme="https://westerndevs.com/tags/community/"/>
    
      <category term="presentations" scheme="https://westerndevs.com/tags/presentations/"/>
    
      <category term="conference" scheme="https://westerndevs.com/tags/conference/"/>
    
  </entry>
  
  <entry>
    <title type="html">Docker Desktop for Linux is not the same as Docker Engine</title>
    <link href="https://westerndevs.com/_/docker-desktop-is-not-docker-engine/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/docker-desktop-is-not-docker-engine/</id>
    <published>2022-12-14T02:28:36.457Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I like Docker Desktop. It provides me an easy-to-use GUI (graphical user interface) to manage my docker images I use for various tasks for building software. I use it on Windows, and now I'll be using it on Linux as <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener">it is available for some of the the more common distros</a>. Regardless of its greatness, it is not the same as <a href="https://docs.docker.com/engine/" target="_blank" rel="noopener">Docker Engine</a> running right on the metal (rather than a virtual machine, like Docker Desktop), and some of those differences caught me while testing my GitHub Workflows with <a href="https://github.com/nektos/act" target="_blank" rel="noopener">nektos/act</a>, which depends on Docker Engine to work.</p><p>To be fair, I should highlight that this is definitely a self-induced problem. The Docker Engine prerequisite is listed right on the  <a href="https://github.com/nektos/act#necessary-prerequisites-for-running-act" target="_blank" rel="noopener">README for the nektos/act</a>, and had I reviewed the documentation I probably would have saved myself the trouble. Still, in my web sleuthing for solutions to the problem I created for myself, I found others had hit similar issues, hence this post.</p><h2>The Context</h2><p>I discovered the problem when I attempted to test my GitHub Workflows locally using <a href="https://github.com/nektos/act" target="_blank" rel="noopener">nektos/act</a> which is a tool I have been using for the past few years in my software development. It does this by pulling down a docker image that simulates the GitHub runner and runs the workflow in that Docker container. I have done this a few times over, so went to one of my older projects where I set this up and pulled in the code to get it running.</p><p>Being that this was a fresh Linux install, I had not installed Docker yet. When I searched out the installation instructions for Docker on Linux, I was greeted with this announcement:</p><p><img src="/images/2022-12-13-docker-desktop-is-not-docker-engine/docker-desktop-for-linux-notice.jpeg" alt="Docker documentation page with a banner highlighting that Docker for Desktop now exists for Linux"></p><p>I have been using Docker for Desktop on Windows for a while now, and I am always happy to have software that exists across my Windows-Linux development environment ecosystem, and so I went about installing Docker for Desktop as my new Docker install.</p><p>After testing my new and shiny Docker (for Desktop) installation with the standard <code>docker run hello-world</code>, I was ready to get back to coding!</p><p>Or so I thought...</p><h2>The Problem (and Triaging it)</h2><p>This is where things went sideways and the problem appeared. I ran <code>act -j build</code> to my run my <code>build job</code> in a  workflow I know has worked previously and was greeted with the following error message:</p><blockquote><p>Cannot connect to Docker daemon. Is the docker daemon running?</p></blockquote><p>Not what I expected, considering I just tested out my fresh Docker install, but I tried pulling the image down myself with the <code>docker pull</code> command just to make sure things didn't break, and everything worked as expected.</p><p>With a bit of web sleuthing, I came across others who <a href="https://github.com/nektos/act/issues/1051" target="_blank" rel="noopener">reported the same issue</a> and noticed this link in particular:</p><blockquote><p>You could check if <code>/var/run</code> actually contains <code>docker.sock</code></p></blockquote><p>When checking this, I found that <code>docker.sock</code> was in fact NOT present. I immediate associated it with the Docker for Desktop installation, as that was the only new variable from my previous development environment.</p><h2>The Root Cause (Probably)</h2><p>This is part where I waste my time trying to figure out why did Docker for Desktop not install docker.sock. Rather that figuring out how to install the docker components that are missing.</p><p>Although I am no Docker expert, my understanding is that Docker for Desktop runs docker inside a VM rather than on the system itself, unlike Docker Engine. In fact, you can see a separate <a href="https://docs.docker.com/engine/context/working-with-contexts/" target="_blank" rel="noopener">Docker context</a> when you list out the contexts.</p><p><img src="./docker-context-output.jpeg" alt="Screenshot of a Linux terminal showing the Docker CLI output for docker context list command that lists the default docker context, which is the Docker Engine context, and the Docker for Desktop context for the user">.</p><p><strong>It should be noted</strong> that default context for Docker was listed, even though I had not installed Docker Engine yet. This lead me to believe something I installed was incorrectly configured, but really it was the fact that I had not installed the software I needed.</p><h2>The Solution / TL;DR;</h2><p>As technical as I made it sound, the real problem was that I was missing software. Specifically I was missing &quot;docker&quot; on my Linux machine, even though I installed Docker for Desktop. 😊</p><p>Well, if the problem is that I am missing software, then the solution must be to install the software. That software is <a href="https://docs.docker.com/engine/" target="_blank" rel="noopener">Docker Engine</a>, which sets up the Docker API right on the machine rather than though a VM like Docker for Desktop (as far as I understand it).</p><p>In conclusion, install the software dependencies the tools If you're running a Linux distro, as great as Docker for Desktop is-- you may still want to install Docker Engine. You can always switch contexts on where to run your own docker commands with the <code>docker context set</code> command, but it's worth double checking to make sure the tool you are using supports Docker for Desktop on Linux platforms.</p><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      With Docker for Desktop available for Linux (which I like), I managed to get myself confused regarding its role on my Linux-based development machine. This post clarifies a few things I discovered while triaging an issue I had trying to test my GitHub Workflows locally.
    
    </summary>
    
    
      <category term="docker" scheme="https://westerndevs.com/tags/docker/"/>
    
      <category term="linux" scheme="https://westerndevs.com/tags/linux/"/>
    
      <category term="docker engine" scheme="https://westerndevs.com/tags/docker-engine/"/>
    
      <category term="docker desktop" scheme="https://westerndevs.com/tags/docker-desktop/"/>
    
      <category term="github workflow" scheme="https://westerndevs.com/tags/github-workflow/"/>
    
  </entry>
  
  <entry>
    <title type="html">Prairie Dev Con 2022 Takeaways</title>
    <link href="https://westerndevs.com/_/prairie-dev-con-2022-takeaways/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/prairie-dev-con-2022-takeaways/</id>
    <published>2022-12-07T20:37:20.777Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Until I walked through the doors of the Prairie Dev Con in 2022, I did not realize how much I missed it. The talented speakers that come together always bring fresh ideas to my mind and give me pause to think about my own efforts and how I can learn from their experience. Although not a complete list, these ideas the ones that stood out the most from Prairie Dev Con 2022.</p><h2>API First Design (<a href="https://www.linkedin.com/in/joelhebert/" target="_blank" rel="noopener">Joël Hébert</a>)</h2><p>Joel did a great session about API first design, which was a very dense session, but he delivered the content in a way that was very approachable and allowed me to think of the benefits of doing API first design with tools like <a href="https://swagger.io" target="_blank" rel="noopener">Swagger.io</a> and <a href="https://www.openapis.org" target="_blank" rel="noopener">OpenAPI</a>.</p><p>It was great seeing the value of these tools, and hearing about the patterns and practices experienced API developers like Joel use to implement consistent and secure APIs.</p><h2>Developer Velocity Index (<a href="https://www.linkedin.com/in/ajenns/" target="_blank" rel="noopener">AJ Enns</a>)</h2><p>I went into this session thinking I was going to be fascinated with the subject, but that the concept would apply only to development leads or possibly coders, rather than an architect like me..</p><p>I was wrong.</p><p>The <a href="https://azure.microsoft.com/en-us/solutions/developer-velocity/" target="_blank" rel="noopener">Developer Velocity Index (DVI)</a>, is a way for any team (even if it is a one-person team, like me on my side projects) can help frame up and scope the abstract problem of figuring out how do to deliver more value.</p><p>I plan on applying the DVI to my side project adventures, self-development, and my enterprise day-job efforts as soon as possible.</p><h2>End to End Testing (<a href="https://www.davepaquette.com" target="_blank" rel="noopener">Dave Paquette</a> and <a href="https://www.linkedin.com/in/lavanya-mohan/" target="_blank" rel="noopener">Lavanya Mohan</a>)</h2><p>Although Dave and Lavanya delivered two completely separate sessions related to testing, the content they delivered worked together in a very interesting way.</p><p>Dave demonstrated and discussed <a href="https://playwright.dev" target="_blank" rel="noopener">Playwright</a> and end-to-end testing framework that resolved or improved the problems we commonly see with end-to-end testing. Lavanya demonstrated how someone <em>should apply</em> proper code management and development techniques when creating test code using a framework, like Playwright.</p><p>For me, together they demonstrated why the test recorded features of end-to-end frameworks is not the &quot;best approach&quot; to creating tests, but rather it is only the first step.</p><p>I feel that these ideas will be seeping into both my day-job and side projects in the very near future.</p><h2>Cloud Security (<a href="https://www.linkedin.com/in/adam-krieger-7a087048/" target="_blank" rel="noopener">Adam Krieger</a>)</h2><p>Adam closed the Prairie Dev Con season with his session, and managed to leave me with a lot of ideas and helped me identify gaps that I have been living with as a developer and as a solution architect.</p><p>Ensuring that developers are security-aware is something I didn't realize I have been missing in my own skills, but also should be looking for in the implementation of my solution designs.</p><h2>A Deal is a Deal (<a href="https://www.rodpaddock.com" target="_blank" rel="noopener">Rod Paddock</a>)</h2><p>Rod delivered a keynote in both Regina and Winnipeg, and each time I walked away with a positive outlook on my own professional and personal growth, but also with the reminder: A Deal Is A Deal.</p><p>Sounds simple enough, but in the past I have frequently found myself regretting decisions or deals I had made with myself or others. But, a deal is a deal, and even if you don't like it or regret it, you need to take a moment to learn from it and ensure the next deal is one you won't regret.</p><h2>TL;DR; / Conclusion</h2><p>In short, there were a lot of good ideas at Prairie Dev Con 2022. These are the ones that stood out to me the most:</p><ul><li>Consider API First Design with tools like Swagger.io and OpenAPI (Joël Hébert)</li><li>The Developer Velocity Index (DVI) is NOT just for developers, but for anyone looking to deliver value (AJ Enns)</li><li>End-to-End Testing is a thing that requires effort, but has major benefits with the right tools and patterns in practice (Dave Paquette and Lavanya Mohan)</li><li>Cloud Developers need not should be security-aware and not just depend others (Adam Krieger)</li><li>A deal is a deal, and if you don't like it, learn from it so the next one is better (Rod Paddock)</li></ul><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      The talented speakers that come together for Prairie Dev Con always bring fresh ideas to my mind and give me pause to think about my own efforts and how I can learn from their experience. Although not a complete list, these ideas the ones that stood out the most from Prairie Dev Con 2022.
    
    </summary>
    
    
      <category term="prairie-dev-con" scheme="https://westerndevs.com/tags/prairie-dev-con/"/>
    
      <category term="prdc-2022" scheme="https://westerndevs.com/tags/prdc-2022/"/>
    
      <category term="api-design" scheme="https://westerndevs.com/tags/api-design/"/>
    
      <category term="open-api" scheme="https://westerndevs.com/tags/open-api/"/>
    
      <category term="developer-velocity-index" scheme="https://westerndevs.com/tags/developer-velocity-index/"/>
    
      <category term="e2e-testing" scheme="https://westerndevs.com/tags/e2e-testing/"/>
    
      <category term="playwright" scheme="https://westerndevs.com/tags/playwright/"/>
    
      <category term="adiad" scheme="https://westerndevs.com/tags/adiad/"/>
    
  </entry>
  
  <entry>
    <title type="html">Open Graph Tools and Resources for Web Nerds (Like Me)</title>
    <link href="https://westerndevs.com/_/open-graph-tools-and-resources-for-web-nerds/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/open-graph-tools-and-resources-for-web-nerds/</id>
    <published>2022-12-01T09:18:34.509Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>The <a href="https://ogp.me" target="_blank" rel="noopener">Open Graph Protocol (OGP)</a> is an open standard that allows web pages to have deeper integration with a social graph, such as Facebook, Twitter, or LinkedIn. You know those cards that appear on Twitter or LinkedIn with tailored images for a link to a blog post? That is OGP in action.</p><p>With <a href="https://github.com/davidwesst/website/releases" target="_blank" rel="noopener">my recent adventures with reimplementing my website</a>, I wanted to leverage this on pages and posts, specifically with LinkedIn and it took a little more research to get it working right. So, for the web nerds like me looking to implement OGP on their projects, I wanted to share the resources I found useful to hopefully save them some time in finding the right resources.</p><h2><a href="https://ogp.me" target="_blank" rel="noopener"><code>ogp.me</code></a></h2><p>I am calling this the specification, or &quot;spec&quot;, and it probably the most important resource. The best part about this site is how approachable it is.</p><p>There are code snippets, explanations of all the object types and their properties, and its own list of tools (although they differ from the ones I am including on this list).</p><p>If you take one thing away from this post for your work with OGP, take this one.</p><h3>Reference</h3><ul><li><a href="https://ogp.me" target="_blank" rel="noopener">Open Graph protocol page</a></li></ul><h2>LinkedIn (and Facebook) Post Inspectors</h2><p>Both Facebook and LinkedIn provide a developer tool to analyze and verify your implemenation of OGP and has the added feature of busting whatever the social networks have cached for the pages you share.</p><p>These tools for triaging or assesing publically shared pages, but not so much when it comes to local development. That is where the next tool comes into play.</p><h3>Reference</h3><ul><li><a href="https://www.linkedin.com/post-inspector/" target="_blank" rel="noopener">LinkedIn Post Inspector</a></li><li><a href="https://developers.facebook.com/tools/debug/" target="_blank" rel="noopener">Facebook Sharing Debugger</a></li></ul><h2>Social Share Preview Web Extension</h2><p>Available for both <a href="https://chrome.google.com/webstore/detail/social-share-preview/ggnikicjfklimmffbkhknndafpdlabib" target="_blank" rel="noopener">Chromium Browsers</a> and <a href="https://addons.mozilla.org/en-US/firefox/addon/social-share-preview/" target="_blank" rel="noopener">Firefox</a>, this web extension allows you simulate what should appears for any page loaded up in your browser.</p><p>This tool saved me from having to continually publish the content to a public location for the post inspector, but note that it is just a <em>simulation</em> of what the tool thinks it should appear. It does not replace post inspector or proper testing on the site you are looking to share to.</p><p><img src="/images/2022-11-30-open-graph-tools-and-resources-for-web-nerds/social-share-preview-example.png" alt="A window displaying a preview of what a LinkedIn post of the 'How much is enough documentation?' blog post on davidwesst.com"></p><h3>Reference</h3><ul><li><a href="https://chrome.google.com/webstore/detail/social-share-preview/ggnikicjfklimmffbkhknndafpdlabib" target="_blank" rel="noopener">Chrome Extension</a></li><li><a href="https://addons.mozilla.org/en-US/firefox/addon/social-share-preview/" target="_blank" rel="noopener">Firefox Add-On</a></li></ul><h2>Browser Dev Tools (Obviously)</h2><p>If you are reading the post, then this one is an obvious one-- but sometimes we (like me) get so caught up on exploring new ways to solve my problem, we forget about the obvious ones.</p><p>OGP tags live in the <code>&lt;head&gt;</code> of your HTML page. If you are unsure why things are not working, make sure you run your browser dev tools of choice and check the <code>&lt;head&gt;</code> of the document and make sure the OGP tags you are expecting appear where they should be.</p><p>It seems simple, but depending on what tool, engine, or framework to output HTML, you may be surprised what shows up.</p><h3>Reference</h3><p>Open this post on a desktop browser and press the key combination <code>Ctrl + Shift + i</code> and you should see your browser dev tools pop open for the site.</p><h2>Conclusion / TL;DR;</h2><p>Read the <a href="https://ogp.me" target="_blank" rel="noopener">aproachable spec document</a>. That is the most important part takeaway from my OGP implemenation. It is very approachable and gives you a strong foundation to work from as you use other tools to triage and assess your implementation.</p><p>These are the tools I used to implement LinkedIn support, along with my browser dev tools.</p><ul><li><a href="https://www.linkedin.com/post-inspector/" target="_blank" rel="noopener">LinkedIn Post Inspector</a></li><li><a href="https://developers.facebook.com/tools/debug/" target="_blank" rel="noopener">Facebook Sharing Debugger</a></li><li><a href="https://chrome.google.com/webstore/detail/social-share-preview/ggnikicjfklimmffbkhknndafpdlabib" target="_blank" rel="noopener">Chrome Extension</a></li><li><a href="https://addons.mozilla.org/en-US/firefox/addon/social-share-preview/" target="_blank" rel="noopener">Firefox Add-On</a></li><li><code>Ctrl + Shift + i</code> on your desktop browser</li></ul><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      A compilation of tools and resources I used to implemented the Open Graph Protocol (OGP) for my website to make posts and pages more engaging on LinkedIn and other social networks.
    
    </summary>
    
    
      <category term="twitter" scheme="https://westerndevs.com/tags/twitter/"/>
    
      <category term="open graph" scheme="https://westerndevs.com/tags/open-graph/"/>
    
      <category term="web development" scheme="https://westerndevs.com/tags/web-development/"/>
    
      <category term="seo" scheme="https://westerndevs.com/tags/seo/"/>
    
      <category term="linkedin" scheme="https://westerndevs.com/tags/linkedin/"/>
    
      <category term="facebook" scheme="https://westerndevs.com/tags/facebook/"/>
    
  </entry>
  
  <entry>
    <title type="html">Does GDPR Apply to Personal Websites?</title>
    <link href="https://westerndevs.com/_/does-gdpr-apply-to-personal-websites/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/does-gdpr-apply-to-personal-websites/</id>
    <published>2022-11-19T01:10:07.083Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>A few weeks back, I <a href="https://github.com/davidwesst/website/releases/tag/v10.0.1" target="_blank" rel="noopener">released v10.0.1 of my website</a>. I use a static site generator to generate all the pages and publish it out into the internet for all the world to read. In that release, I added <a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview" target="_blank" rel="noopener">Application Insights</a> to provide me with some performance data, but also to get a bit of usage data (for those willing to share it).</p><p>What I found odd was that all the links and articles I came across seemed to talk about things at a high-level (i.e. defining GDPR) or assumed I was working at a large scale (i.e. enterprise software), but nothing small projects like my personal website.</p><p>Still, I managed to draw some of my own conclusions on how to handle GDPR for my personal website and wanted to document them somewhere.</p><h2>DISCLAIMER: This is not legal advice</h2><p>I am not a lawyer, so this is just an opinion from a developer. As a rule of thumb, I avoid taking legal advice from random folks on the internet. If you take advice from this article, take that bit and keep it.</p><p>I hope others (like you) use this post to draw your own conclusions or how you want to proceed with your own plan for handling GDPR.</p><p>But if you want <em>real</em> advice. Get a lawyer and talk to them.</p><h2>Short Answer: Yes</h2><p>Yes, it does apply to your personal website <strong>if</strong> are tracking information about your users <strong>and</strong> you are developing your own website or application.</p><h3>Developing Your Own Website or Application</h3><p>I mean developing as it coding it, publishing that code, and hosting it somewhere like Microsoft Azure or GitHub Pages. If you are publishing your own code, GDPR may apply to you.</p><p>If you are using a third party tool or platform, like Facebook or LinkedIn to host your blog posts-- you appear to be in the clear. When you use a third-party platform, the <em>platform</em>, not you, is responsible for GDPR compliance.</p><p>Even if you think you are clear of GDPR responsibility, make sure that you trust your chosen platform to comply to GDPR and other regulatory bodies out there, as your site depends on it.</p><h3>Tracking Information</h3><p>The GDPR is all about protecting personal information and giving control back to people navigating the internet. GDPR is not the only set of laws in play, as <a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375" target="_blank" rel="noopener">California</a>, <a href="https://iapp.org/media/pdf/resource_center/Brazilian_General_Data_Protection_Law.pdf" target="_blank" rel="noopener">Brazil</a>, and <a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda" target="_blank" rel="noopener">Canada</a> have their own versions of similar legislation, but many of these laws seem to have been inspired by GDPR and why I tend to focus on it.</p><p>At the personal website level, you need to consider whether or not you are collecting personal information from your users. This includes things like <a href="https://gdpr.eu/eu-gdpr-personal-data/" target="_blank" rel="noopener">IP addresses or cookie identifiers</a>.</p><p>If you are NOT collecting information like that, you are good to go! Just remember that services like Google Analytics or Disqus Comments use personally identifiable information to operate, so if you have decided to include one of those services on your site then you need to think about GDPR compliance.</p><h2>My Solution Highlights</h2><p>I concluded the GDPR-like laws apply to my personal website if I want to do any kind of usage tracking and understand how users are using my site.. This means it needs to be an opt-in policy that gives the user the option to do just that, <em>opt-in</em>.</p><p><img src="/images/2022-11-18-does-gdpr-apply-to-personal-websites/my-gdpr-dialogue.png" alt="A screenshot of the davidwesst.com blog page with a dialogue docked to the bottom with the statement: 'This site uses cookies to track usage in order to help improve the user experience. By clicking &amp;quot;Accept&amp;quot;, you consent to our use of cookies.' along with gray 'Accept' and 'Decline' buttons, and a blue link with the text 'Privacy Statement'"></p><p>The dialogue above is the only real visual evidence on the site now. As simple as that looks, a lot of thought went into it prior to implementation. Rather than doing a complete code review, I figured I would share the highlights.</p><h3>Understanding My Tools</h3><p>My default would just be to include something like Google Analytics, and be done with it, but with <a href="https://techstory.in/eu-declares-google-analytics-illegal-heres-why/" target="_blank" rel="noopener">GA being made illegal in the EU</a> and more countries creating their own GDPR-like legislation, I thought I would stay away from it and try something different.</p><p>I chose <a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview" target="_blank" rel="noopener">Application Insights</a> and took the time to learn how <a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/data-retention-privacy" target="_blank" rel="noopener">it handles data privacy and retention</a> and how the <a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/javascript?tabs=snippet#cookie-handling" target="_blank" rel="noopener">JavaScript SDK uses cookies</a>.</p><p>Regardless of what you choose for your analytics or tracking tool, the important part is that you understand how the tools are GDPR compliant and how the tracking technology works.</p><h3>Opt-In for Cookies</h3><p>You've seen million of them already, but those cookie banners have purpose. The <a href="https://gdpr.eu/cookies/" target="_blank" rel="noopener">GDPR website outlines the requirements</a> around using cookies, and many tools use them. The important thing is that <em>you</em> know how your website works, along with all the dependencies <em>you choose</em> to include.</p><p>In my case, the cookie banner enables cookies in Application Insights, which in turn enable usage data collection, only if they click &quot;Accept&quot;.</p><h3>Transparency</h3><p>This last point is less technical, and more about design. I am designing with transparency in the front of my mind. I added a <a href="https://www.davidwesst.com/about" target="_blank" rel="noopener">privacy statement to my about page</a> to explain the &quot;why&quot; around using Application Insights, and will share more specifics and document them accordingly.</p><h2>Conclusion / TL;DR;</h2><p>GDPR and the various GDPR-like laws definitely apply to you and your personal website or app project if you are building the code yourself, assuming you want to track information about your users.</p><p>The short story on this is that you need to draw your own conclusions and take responsibility for what you include in your website. If you are developing something to share outward into the world, you need to take the time to understand how the various tools you are included (such as Google Analytics or Application Insights) as well as the requirements for compliance.</p><h3>GDPR Resources</h3><p>Two resources I found useful in explaining GDPR requirements are provided on the site <a href="https://gdpr.eu/" target="_blank" rel="noopener">GDPR.eu</a>. If you are looking for more information, I definitely suggest checking out these links:</p><ul><li><a href="https://gdpr.eu/cookies/" target="_blank" rel="noopener">Cookies, the GDPR, and the ePrivacy Directive</a></li><li><a href="https://gdpr.eu/compliance/" target="_blank" rel="noopener">Everything you need to know about GDPR compliance</a></li></ul><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      While rebuilding my personal website in 2022, I wanted to know how or if GDPR applied to my little side project. My internet sleuthing did not bring up any clear and cut answers, but I put together some thoughts that might help others answer it for themselves.
    
    </summary>
    
    
      <category term="website" scheme="https://westerndevs.com/tags/website/"/>
    
      <category term="gdpr" scheme="https://westerndevs.com/tags/gdpr/"/>
    
      <category term="ldgp" scheme="https://westerndevs.com/tags/ldgp/"/>
    
      <category term="ccpa" scheme="https://westerndevs.com/tags/ccpa/"/>
    
      <category term="privacy" scheme="https://westerndevs.com/tags/privacy/"/>
    
      <category term="cookies" scheme="https://westerndevs.com/tags/cookies/"/>
    
  </entry>
  
  <entry>
    <title type="html">Bulk Insert SQL Geometry on .NET Core</title>
    <link href="https://westerndevs.com/_/bulk-insert-sql-geometry/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/bulk-insert-sql-geometry/</id>
    <published>2022-11-17T05:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I have been updating an application from full framework to .NET 6 this week. One of the things this app does is bulk load data into SQL Server. Normally this works just fine but some of the data is geography data which requires a special package to be installed: <code>Microsoft.SqlServer.Types</code>. This package is owned by the SQL server team so, as you'd expect, it is ridiculously behind the times. Fortunately, they are working on updating it and it is now available for Netstandard 2.1 in a preview mode.</p><p>The steps I needed to take to update the app were:</p><ol><li>Install the preview package for <code>Microsoft.SqlServer.Types</code></li><li>Update the SQL client package from System.Data.SqlClient to Microsoft.Data.SqlClient</li></ol><p>After that the tests we had for inserting polygons worked just great. This has been a bit of a challenge over the years but I'm delighted that we're almost there. We just need a non-preview version of the types package and we should be good to go.</p><h2>Gotchas</h2><p>When I'd only done step 1 I ran into errors like</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">System.InvalidOperationException : The given value of<span class="built_in"> type </span>SqlGeometry <span class="keyword">from</span> the data source cannot be converted <span class="keyword">to</span><span class="built_in"> type </span>udt of the specified target column.</span><br><span class="line">---- System.ArgumentException : Specified<span class="built_in"> type </span>is <span class="keyword">not</span> registered on the target server. Microsoft.SqlServer.Types.SqlGeometry, Microsoft.SqlServer.Types, <span class="attribute">Version</span>=16.0.0.0, <span class="attribute">Culture</span>=neutral, <span class="attribute">PublicKeyToken</span>=89845dcd8080cc91.</span><br></pre></td></tr></table></figure><p>I went down a rabbit hole on that one before spotting a post from MVP Erik Jensen https://github.com/ErikEJ/EntityFramework6PowerTools/issues/103 which sent me in the right direction.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I have been updating an application from full framework to .NET 6 this week. One of the things this app does is bulk load data into SQL S
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Removing Azure Backups in Terraform</title>
    <link href="https://westerndevs.com/_/azure-backus-protip/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/azure-backus-protip/</id>
    <published>2022-11-11T05:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>If you have a VM backup in your Terraform state and need to get rid of it be aware that it is probably going to break your <a href="https://blog.simontimms.com/2022/11/01/theory-of-terraform-github.-actions/" target="_blank" rel="noopener">deployment pipeline</a>. The reason is that Terraform will delete the item but then find that the resource still there. This is because backup deletion takes a while (say 14 days). Eventually the backup will delete but not before Terraform times out.</p><p>The solution I'm using is to just go in an manually delete the backup from the terraform state to unblock my pipelines.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">terraform state list | grep &lt;name of your backup&gt;</span><br><span class="line">-- make note of the resource identifier --</span><br><span class="line">terraform state rm &lt;found resource identifier&gt;</span><br></pre></td></tr></table></figure><p>Editing Terraform state seems scary but it's not too bad after you do it a bit. Take backups!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;If you have a VM backup in your Terraform state and need to get rid of it be aware that it is probably going to break your &lt;a href=&quot;https
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">How much is enough documentation?</title>
    <link href="https://westerndevs.com/_/how-much-is-enough-documentation/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/how-much-is-enough-documentation/</id>
    <published>2022-11-10T22:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Documentation takes a lot of different forms. Decision requests, diagrams, and just plain ol' word filled documents. Historically speaking, I have been guilty of being that developer that loathed documentation, waited until the last minute, and usually produced something that won't provide much help when it is actually needed.</p><p>Being a solution architect during the day, I wanted to apply some of my new found skills (and appreciation) for documentation while <a href="https://github.com/davidwesst/website/blob/main/CHANGELOG.md" target="_blank" rel="noopener">working on v10 of my website</a>. Ultimately, documentation is <em>necessary</em>, even on personal projects. If I think back to my own experience with my own projects, they can end up sitting on the shelve for a long time. When go back to revisit it, other than analyzing my own code (on prototype stuff) can be a serious time sink to even get things in a running state without any decent documentation.</p><h2>What do you <em>need</em>?</h2><p>And I do mean <em>needed</em> not <em>wanted</em>. Everyone <em>wants</em> documentation of all kinds, but what does an audience of one (i.e., your future self) <em>need</em> to get the project back off the shelve and into working order?</p><p>Like any good solution architect, I started to read, learn, and figure out what others consider &quot;enough documentation&quot; or &quot;good documentation&quot;. I also spent time defining the problem I needed the documentation to solve, and landed on the following docs being &quot;enough&quot;.</p><h3>The README</h3><p>It might seem obvious but, I have read enough of my own empty or default <code>README.md</code> files to know that this is easily the most important piece of documentation you write. Without it, the project will require code analysis to figure out what it <em>actually</em> is, and that is never good.</p><p>There are a lot of great examples <code>README.md</code> files on GitHub to look at, but I would suggest you start simple if you're just getting off the ground. My take was to include system requirements and the steps to setup, build, and start the project for the developer.</p><p>When searching for info on this, I really like <a href="https://www.freecodecamp.org/news/how-to-write-a-good-readme-file/" target="_blank" rel="noopener">this article from Hillary Nyakundi</a> provided a great &quot;how-to&quot; on making a good <code>README.md</code>.</p><h3>Decisions (also known as ADs or Architecture Decisions)</h3><p>This is one I picked up from my day job being a Solution Architect in a large enterprise. Decisions you make along the way need to be documented, even if it is only for yourself.</p><p>The idea is to document decisions that will have a long term impact on your project. Decided to document decisions? That can be documented. Decided that you only want your project to run on Azure? That can be documented. Decided to design your solution around a specific pattern? That can be documented.</p><p>You can document as many or as few decisions as you want. In the case of my website project, <a href="https://github.com/davidwesst/website/tree/main/docs/decisions" target="_blank" rel="noopener">I documented a few core decisions early on</a> because I wanted to remember <em>why I built it this way</em>. Even though I am adding content regularly and tweaking features frequently enough, I could shelve the development at any point.</p><p>In terms of format, there are plenty of ways to document decisions and why it is important, but I am not going to spend time explaining that. Instead I would recommend reading <a href="https://adr.github.io" target="_blank" rel="noopener">how GitHub documents decisions</a>. That is where I started, and they have a great breakdown of the different format and tools that can support you, if you're inclined to get into the tooling.</p><p>For the website, I <a href="https://github.com/davidwesst/website/blob/main/docs/decisions/0001-decisions-with-madr.md" target="_blank" rel="noopener">decided to use MADR as my decision document template</a> and documented &quot;why&quot; I chose it as the first decision for the project and <a href="https://github.com/davidwesst/website/blob/main/docs/decisions/0001-decisions-with-madr.md" target="_blank" rel="noopener">documented it</a>.</p><h3>Diagrams</h3><p>The last bit of documentation I feel I <em>need</em> (although it is not as important as the previous two) are solution diagrams.</p><p>Just like decision documentation, this is something that can take a lot of different forms. Personally, I am not a huge fan of diving into UML or any of the traditional diagram styles. I like diagrams that present well to multiple audiences and explain <em>one thing</em> well.</p><p><img src="/images/2022-11-10-how-much-is-enough-documentation/website-solution-overview.png" alt="A solution diagram example from the website project"></p><p>The above diagram is one I created to explain how I setup all the pieces inside of Microsoft Azure to host my website. The diagram answers the question &quot;What is necessary to host your application?&quot; which goes beyond the code in my case.</p><p>There is no real format that I applied here, but I scoped it to focus on the Azure Infrastructure and service I needed to rebuild the solution in Azure from scratch. Almost like a high-level guide to explain all the different pieces that need to be setup and handled.</p><p>In regards to diagram formatting, although I did not use it in this example, the <a href="https://c4model.com" target="_blank" rel="noopener">C4 model</a> is something I have been messing around with to describe systems and projects in my day job. If you need a little direction, or are struggling to figure out &quot;how to diagram&quot; your project, it might be worth a look.</p><h3>Notable Mention: <code>CHANGELOG.md</code></h3><p>I wanted to highlight this, but also point out that it is definitely not required. A <code>CHANGELOG.md</code> allows you to document your progress.</p><p>I based <a href="https://github.com/davidwesst/website/blob/main/CHANGELOG.md" target="_blank" rel="noopener">my CHANGELOG file</a> off of the format described at <a href="https://keepachangelog.com/en/1.0.0/" target="_blank" rel="noopener">keepachangelog.com</a>. It forced me to take a bit of time (really, like 15 minutes or so) to reflect on my effort and appreciate the effort I have put into the project. Plus, it tells the story of how the project has evolved over time; which, just like the decisions, provides context on how things got to where they are.</p><h2>Conclusion / TL;DR;</h2><p>In short, the documentation I <em>need</em> (not <em>want</em>) consists of the following, with the following priority:</p><ol><li><code>README.md</code> (that at least says how to setup, build, and run the project)</li><li>Decisions (using <a href="https://adr.github.io" target="_blank" rel="noopener">MADR</a> or some other format of your choosing)</li><li>Solution Diagrams (that answer <em>one specific question</em>)</li><li><code>CHANGELOG.md</code> (not required, but provides more context and forces you to appreciate the effort you have put into your project)</li></ol><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      Documentation is important, but it takes a lot of time and if you are a solo developer, what documentation to you really need? Still, good docs can provide the context I forget after putting a project on the shelf, or explains how to fix something in older code I use, but haven&#39;t touched in a long time. So how much is &#39;enough&#39; documentation and what types of documentation do I need to invest in give my future self the the best value for the effort I put in?
    
    </summary>
    
    
      <category term="madr" scheme="https://westerndevs.com/tags/madr/"/>
    
      <category term="c4-model" scheme="https://westerndevs.com/tags/c4-model/"/>
    
      <category term="decision" scheme="https://westerndevs.com/tags/decision/"/>
    
      <category term="diagram" scheme="https://westerndevs.com/tags/diagram/"/>
    
      <category term="documentation" scheme="https://westerndevs.com/tags/documentation/"/>
    
      <category term="README.md" scheme="https://westerndevs.com/tags/README-md/"/>
    
      <category term="CONTRIBUTING.md" scheme="https://westerndevs.com/tags/CONTRIBUTING-md/"/>
    
  </entry>
  
  <entry>
    <title type="html">How to fork (a repo) like a boss!</title>
    <link href="https://westerndevs.com/_/how-to-fork-like-a-boss/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/how-to-fork-like-a-boss/</id>
    <published>2022-11-02T21:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>My name is David Wesst and today I am going to teach you to fork like a boss! No special tools. No special creams. Just your clicking finger and a bit of confidence to use your coding skills.</p><p>Before I forked, I thought I forking wasn't for me. I thought, I am too old to fork, but man oh man was I wrong. But then came the day where a library I was using was missing a critical feature, and a quick search through the repository issues found <a href="https://github.com/solution-loisir/markdown-it-eleventy-img/issues/8" target="_blank" rel="noopener">that others were looking for that feature too</a>.</p><p><img src="/images/2022-11-02-how-to-fork-like-a-boss/gh-issue.jpg" alt="Screenshot of GitHub issue with title &amp;quot;Question about whether the relative path is base on current working dir or current md file?&amp;quot; with the first entry in the issue describing how their blog posts have images in the same directory as the post"></p><h2>Choosing to Fork</h2><p>This is the moment where I got to choose. I had a options for my next move:</p><ol><li>Add to the thread and hope for the best</li><li>Built my own solution from scratch</li><li>Take a look through the code and see if its forkable</li></ol><p>The first choice makes sense if you don't have the knowledge or skills.</p><p>The second choice feels easier, but that is only your fear of contributing getting the best of you. When you add to your codebase, you are adding more code to support in the long run and all comes with that.</p><p>The last choice might make you nervous of you haven't forked in a long time, but I assure you, if you can code, you can fork. So browse through the code and see if you can find the spot your forking can help.</p><h2>Defining Forkability</h2><p>This is very subjective, but when it comes to forkable projects for me, I look for the following things, in this order:</p><ol><li><code>CONTRIBUTING.md</code>, to give me a breakdown on how the community wants people to contribute</li><li>Tests, so I know I can mess around with the code without breaking existing functionality</li><li>Existing Issues and Pull Requests (PRs) to see what users, developers, and project owners are currently working on and their focus.</li></ol><p>In my recent contribution to <a href="https://github.com/solution-loisir/markdown-it-eleventy-img" target="_blank" rel="noopener">markdown-it-eleventy-img</a>, I went through the repo trying to figure out whether or not it was forkable. Although I didn't find a <code>CONTRIBUTING.md</code> (<a href="https://github.blog/2012-09-17-contributing-guidelines/" target="_blank" rel="noopener">but that could be a future PR</a>) but I found a set of tests, and even though I forgot in the moment, there was an existing issue from someone else about the same issue I was hoping to contribute!</p><p>And with that, I knew this project was forkable. So I pulled out my finger and clicked &quot;FORK&quot; like boss and coded up my solution, and <a href="https://github.com/solution-loisir/markdown-it-eleventy-img/pull/9" target="_blank" rel="noopener">submitted a PR</a>.</p><h2>Fork with Confidence and Respect</h2><p>If you look through the <a href="https://github.com/solution-loisir/markdown-it-eleventy-img/pull/9" target="_blank" rel="noopener">thread of the PR</a> you'll see that my solution went through a few iterations and changes after receiving feedback from the project owner.</p><p>This was a great conversation and it lead to a better solution implementation than my original submission, which made me exceptionally happy (and proud) of my contribution.</p><p>Even though it is volunteer labour, remember that both you AND the project owner/admins are choosing to spend their time reviewing and analyzing your work. Everyone is involved in the fork is investing time, and everyone should be treated with respect and as a professional.</p><p>Plus—this is a great opportunity to level-up your development soft skills. Enjoy yourself, but be timely and respect the investment everyone is making.</p><h2>Conclusion / TL;DR;</h2><p>To fork like a boss, all you need is a project ready for contributions, some confidence, and respect for others on the project:</p><ol><li>A <code>CONTRIBUTING.md</code></li><li>Tests</li><li>Existing Issues and Pull Requests (PRs)</li></ol><p>Thanks for playing.</p><p>~ DW</p>]]></content>
    
    <summary type="html">
    
      Everyone thinks about forking. It is a natural thing, yet how do get the job done and fork? I used to ask myself the same thing, until I learned these pro-tips and forked like a boss.
    
    </summary>
    
    
      <category term="github" scheme="https://westerndevs.com/tags/github/"/>
    
      <category term="pull requests" scheme="https://westerndevs.com/tags/pull-requests/"/>
    
      <category term="contribution" scheme="https://westerndevs.com/tags/contribution/"/>
    
      <category term="open source" scheme="https://westerndevs.com/tags/open-source/"/>
    
  </entry>
  
  <entry>
    <title type="html">Dealing with Set-Output Depreciation Warnings in Terraform github-actions</title>
    <link href="https://westerndevs.com/_/set-output-terraform/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/set-output-terraform/</id>
    <published>2022-11-01T04:00:00.000Z</published>
    <updated>2023-03-04T03:49:51.002Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I've got a build that is running terraform on github actions (I actually have loads of them) and I've been noticing that they are very chatty about warnings now.</p><p><img src="/images/2022-11-01-set-output-terraform.md/2022-11-01-06-46-18.png" alt="">)</p><p>The warning is</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">The </span>`<span class="built_in">set-output`</span> <span class="string">command </span><span class="string">is </span><span class="string">deprecated </span><span class="string">and </span><span class="string">will </span><span class="string">be </span><span class="string">disabled </span><span class="string">soon.</span> <span class="string">Please </span><span class="string">upgrade </span><span class="string">to </span><span class="string">using </span><span class="string">Environment </span><span class="string">Files.</span> <span class="string">For </span><span class="string">more </span><span class="string">information </span><span class="string">see:</span> <span class="string">https:</span>//<span class="string">github.</span><span class="string">blog/</span><span class="string">changelog/</span><span class="string">2022-10-</span><span class="string">11-github-</span><span class="string">actions-deprecating-</span><span class="string">save-state-</span><span class="string">and-set-</span><span class="string">output-commands/</span></span><br></pre></td></tr></table></figure><p>The history here without reading that link is basically that github are changing how we push variables to the pipeline for use in later steps. There were some security implications with the old approach and the new approach should be better</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Save</span> <span class="string">variable</span></span><br><span class="line">  <span class="attr">run:</span> <span class="string">echo</span> <span class="string">"SOMENAME=PICKLE"</span> <span class="string">&gt;&gt;</span> <span class="string">$GITHUB_STATE</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Set</span> <span class="string">output</span></span><br><span class="line">  <span class="attr">run:</span> <span class="string">echo</span> <span class="string">"SOMENAME=PICKLE"</span> <span class="string">&gt;&gt;</span> <span class="string">$GITHUB_OUTPUT</span></span><br></pre></td></tr></table></figure><p>Problem was that the steps on which I was having trouble didn't obviously use the <code>set-output</code> command.</p>  <figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> <span class="string">...</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Init</span> <span class="string">Terraform</span></span><br><span class="line">  <span class="attr">run:</span> <span class="string">terraform</span> <span class="string">init</span> </span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Validate</span> <span class="string">Terraform</span></span><br><span class="line">  <span class="attr">run:</span> <span class="string">terraform</span> <span class="string">validate</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p>I had to dig a bit to find out that it was actually the <code>terraform</code> command that was causing the problem. See as part of the build I install the terraform cli using the</p>  <figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">HashiCorp</span> <span class="bullet">-</span> <span class="string">Setup</span> <span class="string">Terraform</span></span><br><span class="line">  <span class="attr">uses:</span> <span class="string">hashicorp/setup-terraform@v2.0.2</span></span><br><span class="line">  <span class="attr">with:</span></span><br><span class="line">      <span class="attr">terraform_version:</span> <span class="number">1.1</span><span class="number">.9</span></span><br><span class="line">      <span class="attr">terraform_wrapper:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>Turns out that as of writing the latest version of the wrapper installed by the setup-terraform task makes use of an older version of the <code>@actions/core</code> package. This package is what is used to set the output and before version 1.10 it did so using <code>set-output</code>. A fix has been merged into the setup-terraform project but no update released yet.</p><p>For now I found that I had no need for the wrapper so I disabled it with</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">HashiCorp</span> <span class="bullet">-</span> <span class="string">Setup</span> <span class="string">Terraform</span></span><br><span class="line">  <span class="attr">uses:</span> <span class="string">hashicorp/setup-terraform@v2.0.2</span></span><br><span class="line">  <span class="attr">with:</span></span><br><span class="line">      <span class="attr">terraform_version:</span> <span class="number">1.1</span><span class="number">.9</span></span><br><span class="line">      <span class="attr">terraform_wrapper:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>but for future readers if there is a more recent version of setup-terraform than 2.0.2 then you can update to that to remove the warnings. Now my build is clean</p><p><img src="/images/2022-11-01-set-output-terraform.md/2022-11-01-06-57-27.png" alt="">)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I&#39;ve got a build that is running terraform on github actions (I actually have loads of them) and I&#39;ve been noticing that they are very ch
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">My Theory of GitHub Actions and IaC</title>
    <link href="https://westerndevs.com/_/theory-of-terraform-github-actions/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/theory-of-terraform-github-actions/</id>
    <published>2022-11-01T04:00:00.000Z</published>
    <updated>2023-03-04T03:49:51.002Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I do all sorts of random work and one of those is helping out on some infrastructure deployments on Azure. Coming from a development background I'm allergic to clicking around inside an Azure website to configure things in a totally non-repeatable way. So I've been using Terraform to do the deployments. We have built up a pretty good history of using Terraform  - today I might use Pulumi instead but the actual tool isn't all that important as opposed to the theory.</p><p>What I'm looking to achieve is a number of things</p><ol><li>Make deployments easy for people to do</li><li>Make deployments repeatable - we should be able to us the same deployment scripts to set up a dev enviornment or recover from a disaster with minimal effort</li><li>Ensure that changes are reviewed before they are applied</li></ol><p>To meet these requirements a build pipeline in GitHub actions (or Azure DevOps, for that matter) is an ideal fit. We maintain our Terraform scripts in a repository. Typically we use one repository per resource group but your needs may vary around that. There isn't any monetary cost to having multiple repositories but there can be some cognitive load to remembering where the right repository is (more on that later).</p><h2>Source Code</h2><p>Changes to the infrastructure definition code are checked into a shared repository. Membership over this code is fairly relaxed. Developers and ops people can all make changes to the code. We strive to make use of normal code review approaches when checking in changes. We're not super rigorous about changes which are checked in because many of the people checking in changes have ops backgrounds and aren't all that well versed in the PR process. I want to make this as easy for them as possible so they aren't tempted to try to make changes directly in Azure.</p><p>In my experience there is a very strong temptation for people to abandon rigour when a change is needed at once to address a business need. We need to change a firewall rule - no time to review that let's just do it. I'm not saying that this is a good thing but it is a reality. Driving people to the Terraform needs to be easy. Having their ad-hoc changes overwritten by a Terraform deploy will also help drive the point home. Stick and carrot.</p><h2>Builds</h2><p>A typical build pipeline for us will include 3 stages.</p><p><img src="/images/2022-11-01-theory-of-terraform-github.-actions.md/2022-11-01-07-22-50.png" alt="">)</p><p>The build step runs on a checkin trigger. This will run an initial build step which validates the terraform scripts are syntactically correct and well linted. A small number of our builds stop here. Unlike application deployments we typically want these changes to be live right away or at most during some maintenance window shortly after the changes have been authored. That deployments are run close to the time the changes were authored helps with our lack of rigour around code reviews.</p><p>The next stage is to preview what changes will be performed by Terraform. This stage is gated such that it need somebody to actually approve it. It is low risk because no changes to made - we run a <code>terraform plan</code> and see what changes will be made. Reading over these changes is very helpful because we often catch unintended consequences here. Accidentally destroying and recreating a VM instead of renaming it? Caught here. Removing a tag that somebody manually applied to a resource and that should be preserved? Caught here.</p><p><img src="/images/2022-11-01-theory-of-terraform-github.-actions.md/2022-11-01-07-45-43.png" alt="">)</p><p>The final stage in the pipeline is to run the Terraform changes. This step is also gated to prevent us from deploying it without proper approvals. Depending on the environment we might need 2 approvals or at least one approval that isn't the person writing the change. More eyes on a change will catch problems more easily and also socialize changes so that it isn't a huge shock to the entire ops team that we now have a MySQL server in the enviornment or whatever it may be.</p><h2>Tags</h2><p>Most Azure resources support tagging. These are basically just labels that you can apply to resources. We use tags to help us organize our resources. We have a tag called <code>environment</code> which is used to indicate what environment the resource is in. We have a tag called <code>owner</code> which is used to indicate who owns the resource. We have a tag called <code>project</code> which is used to indicate what project the resource is associated with. But for these builds the most important tags are <code>IaC Technology</code> and <code>IaC Source</code>. The first is used to tell people that the resources are part of a Terraform deployment. The second is used to indicate where on GitHub the Terraform scripts are located. These tags make it really easy for people to find the Terraform scripts for a resource and get a change in place.</p><p><img src="/images/2022-11-01-theory-of-terraform-github.-actions.md/2022-11-01-07-33-43.png" alt="">)</p><h2>Permissions</h2><p>I mentioned earlier that we like to guide ops people to make enviornment changes in Terraform rather than directly in Azure. One of the approaches we take around that is to not grant owner or writer permissions to resources directly to people be they ops or dev. Instead we have a number of permission restricted service principals that are used to make changes to resources. These service principals are granted permissions to specific resource groups and these service principals are what's used in the pipeline to make the changes. This means that if somebody wants to make a change to a resource they need to go through the Terraform pipeline.</p><p>We keep the client id and secret in the secrets of the github pipeline</p><p><img src="/images/2022-11-01-theory-of-terraform-github.-actions.md/2022-11-01-07-42-51.png" alt="">)</p><p>In this example we just keep a single repository wide key because we only have one enviornment. We'd make use of enviornment specific secrets if we had more than one environment.</p><p>This approach has the added bonus of providing rip stops in the event that we leak some keys somewhere. At worst that service principal has access only to one resource group so an attacker is limited to being able to mess with that group and not escape to the larger enviornment.</p><h2>Achieving our Goals</h2><p>To my mind this approach is exactly how IaC was meant to be used. We have a single source of truth for our infrastructure. We can make changes to that infrastructure in a repeatable way. We can review those changes before they are applied. All this while keeping the barrier to entry low for people who are not familiar with the code review process.</p><h2>Future Steps</h2><p>We already make use of Terraform modules for most of our deployment but we're not doing a great job of reusing these modules from project to project. We're hoping to keep a library of these modules around which can help up standardize things. For instance our VM module doesn't just provision a VM - it sets up backups and uses a standardized source image.</p><p>I also really like the idea of using the build pipeline to annotate pull requests with the Terraform changes using https://github.com/marketplace/actions/terraform-pr-commenter. Surfacing this directly on the PR would save the reviewers the trouble of going through the pipeline to see what changes are being made. However it would be added friction for our ops team as they'd have to set up PRs.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I do all sorts of random work and one of those is helping out on some infrastructure deployments on Azure. Coming from a development back
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Registering Terraform Providers</title>
    <link href="https://westerndevs.com/_/register-providers/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/register-providers/</id>
    <published>2022-08-12T04:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.998Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>If you're setting up a new Terraform project on Azure you might find yourself needing to register providers if you're running with an identity that doesn't have wide ranging access to the subscription. I ran into this today with the error</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">│ Error: Error ensuring Resource Providers are registered.</span><br><span class="line">│ </span><br><span class="line">│ Terraform automatically attempts to register the Resource Providers it supports to</span><br><span class="line">│ ensure it's able to provision resources.</span><br><span class="line">│ </span><br><span class="line">│ If you don't have permission to register Resource Providers you may wish to <span class="keyword">use</span> the</span><br><span class="line">│ <span class="string">"skip_provider_registration"</span> flag <span class="keyword">in</span> the Provider <span class="keyword">block</span> <span class="keyword">to</span> <span class="keyword">disable</span> this functionality.</span><br><span class="line">│ </span><br><span class="line">│ Please note that <span class="keyword">if</span> you opt <span class="keyword">out</span> <span class="keyword">of</span> <span class="keyword">Resource</span> Provider Registration <span class="keyword">and</span> Terraform tries</span><br><span class="line">│ <span class="keyword">to</span> provision a <span class="keyword">resource</span> <span class="keyword">from</span> a <span class="keyword">Resource</span> Provider which <span class="keyword">is</span> unregistered, <span class="keyword">then</span> the <span class="keyword">errors</span></span><br><span class="line">│ may appear misleading - <span class="keyword">for</span> example:</span><br><span class="line">│ </span><br><span class="line">│ &gt; API <span class="keyword">version</span> <span class="number">2019</span>-XX-XX was <span class="keyword">not</span> <span class="keyword">found</span> <span class="keyword">for</span> Microsoft.Foo</span><br><span class="line">│ </span><br><span class="line">│ Could indicate either that the <span class="keyword">Resource</span> Provider <span class="string">"Microsoft.Foo"</span> requires registration,</span><br><span class="line">│ but this could also indicate that this Azure Region doesn<span class="string">'t support this API version.</span></span><br><span class="line"><span class="string">│ </span></span><br><span class="line"><span class="string">│ More information on the "skip_provider_registration" flag can be found here:</span></span><br><span class="line"><span class="string">│ https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs#skip_provider_registration</span></span><br><span class="line"><span class="string">│ </span></span><br><span class="line"><span class="string">│ Original Error: Cannnot register providers: Microsoft.StoragePool. Errors were: Cannot register provider Microsoft.StoragePool with Azure Resource Manager: resources.ProvidersClient#Register: Failure responding to request: StatusCode=403 -- Original Error: autorest/azure: Service returned an error. Status=403 Code="AuthorizationFailed" Message="The client '</span>************<span class="string">' with object id ''************'' does not have authorization to perform action '</span>Microsoft.StoragePool/<span class="keyword">register</span>/<span class="keyword">action</span><span class="string">' over scope '</span>/subscriptions<span class="comment">/***' or the scope is invalid. If access was recently granted, please refresh your credentials.".</span></span><br><span class="line"><span class="comment">│ </span></span><br><span class="line"><span class="comment">│   with provider["registry.terraform.io/hashicorp/azurerm"],</span></span><br><span class="line"><span class="comment">│   on environment.tf line 21, in provider "azurerm":</span></span><br><span class="line"><span class="comment">│   21: provider "azurerm" &#123;</span></span><br></pre></td></tr></table></figure><p>The account running terraform in my github actions pipeline is restricted to only have contributor over the resource group into which I'm deploying so it's unable to properly set up providers. Two things needed to fix it:</p><ol><li>Tell terraform to not try to register providers</li><li>Register the providers manually</li></ol><p>For 1 the provider block in the terraform file needs to be updated to look like</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  <span class="attribute">provider</span> <span class="string">"azurerm"</span> &#123;</span><br><span class="line">    <span class="section">features</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="attribute">skip_provider_registration</span> = <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>For 2 it requires logging into the azure portal and registering the providers manually. Go to the subscription and select <code>Resource Providers</code> then search for the one you need, select it and hit <code>Register</code>. In my case the provider was already registered and the problem was just Terraform's attempt to register it without sufficient permission.</p><p><img src="/images/2022-08-11-register_providers.md/2022-08-11-07-07-29.png" alt="">)</p><pre><code></code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;If you&#39;re setting up a new Terraform project on Azure you might find yourself needing to register providers if you&#39;re running with an ide
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title type="html">Debugging Azure Container Instance Startup</title>
    <link href="https://westerndevs.com/_/debug-azure-container-instances-startup/" rel="alternate" type="text/html"/>
    <id>https://westerndevs.com/_/debug-azure-container-instances-startup/</id>
    <published>2022-08-04T04:00:00.000Z</published>
    <updated>2023-03-04T03:49:50.994Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>https://westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I have some container instances which are failing to start up properly and the logs in the portal are blank. This makes debugging them kind of difficult.</p><p>On the command line running</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">az container logs -g &lt;resource group name&gt; -n &lt;container group name&gt; --container &lt;container name&gt;</span><br></pre></td></tr></table></figure><p>Just gave me an output of <code>None</code>. Not useful either.</p><p>Fortunately, you can attach directly to the logs streams coming out of the container which will give you a better idea of what is going on.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">az container attach -g &lt;resource group name&gt; -n &lt;container group name&gt; --container &lt;container name&gt;</span><br></pre></td></tr></table></figure><p>This was able to give me output like</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Start</span> streaming <span class="keyword">logs</span>:</span><br><span class="line">/usr/<span class="keyword">local</span>/lib/python3<span class="number">.9</span>/site-packages/environ/environ.py:<span class="number">628</span>: UserWarning: /ric-api/core/.env doesn<span class="string">'t exist - if you'</span>re <span class="keyword">not</span> configuring your environment separately, <span class="keyword">create</span> one.</span><br><span class="line">  warnings.warn(</span><br><span class="line">Traceback (most recent <span class="keyword">call</span> <span class="keyword">last</span>):</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/environ/environ.py"</span>, line <span class="number">273</span>, <span class="keyword">in</span> get_value</span><br><span class="line">    <span class="keyword">value</span> = self.ENVIRON[<span class="keyword">var</span>]</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/os.py"</span>, line <span class="number">679</span>, <span class="keyword">in</span> __getitem__</span><br><span class="line">    <span class="keyword">raise</span> KeyError(<span class="keyword">key</span>) <span class="keyword">from</span> <span class="keyword">None</span></span><br><span class="line">KeyError: <span class="string">'DB_PORT'</span></span><br><span class="line"></span><br><span class="line">During handling <span class="keyword">of</span> the above <span class="keyword">exception</span>, another <span class="keyword">exception</span> occurred:</span><br><span class="line"></span><br><span class="line">Traceback (most recent <span class="keyword">call</span> <span class="keyword">last</span>):</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/ric-api/manage.py"</span>, line <span class="number">22</span>, <span class="keyword">in</span> &lt;<span class="keyword">module</span>&gt;</span><br><span class="line">    <span class="keyword">main</span>()</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/ric-api/manage.py"</span>, line <span class="number">18</span>, <span class="keyword">in</span> <span class="keyword">main</span></span><br><span class="line">    execute_from_command_line(sys.argv)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/core/management/__init__.py"</span>, line <span class="number">419</span>, <span class="keyword">in</span> execute_from_command_line</span><br><span class="line">    utility.execute()</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/core/management/__init__.py"</span>, line <span class="number">413</span>, <span class="keyword">in</span> <span class="keyword">execute</span></span><br><span class="line">    self.fetch_command(subcommand).run_from_argv(self.argv)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/core/management/base.py"</span>, line <span class="number">354</span>, <span class="keyword">in</span> run_from_argv</span><br><span class="line">    self.execute(*args, **cmd_options)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/core/management/commands/runserver.py"</span>, line <span class="number">61</span>, <span class="keyword">in</span> <span class="keyword">execute</span></span><br><span class="line">    super().execute(*args, **options)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/core/management/base.py"</span>, line <span class="number">398</span>, <span class="keyword">in</span> <span class="keyword">execute</span></span><br><span class="line">    <span class="keyword">output</span> = self.handle(*args, **options)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/core/management/commands/runserver.py"</span>, line <span class="number">68</span>, <span class="keyword">in</span> handle</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> settings.DEBUG <span class="keyword">and</span> <span class="keyword">not</span> settings.ALLOWED_HOSTS:</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/conf/__init__.py"</span>, line <span class="number">82</span>, <span class="keyword">in</span> __getattr__</span><br><span class="line">    self._setup(<span class="keyword">name</span>)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/conf/__init__.py"</span>, line <span class="number">69</span>, <span class="keyword">in</span> _setup</span><br><span class="line">    self._wrapped = <span class="keyword">Settings</span>(settings_module)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/django/conf/__init__.py"</span>, line <span class="number">170</span>, <span class="keyword">in</span> __init__</span><br><span class="line">    <span class="keyword">mod</span> = importlib.import_module(self.SETTINGS_MODULE)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/importlib/__init__.py"</span>, line <span class="number">127</span>, <span class="keyword">in</span> import_module</span><br><span class="line">    <span class="keyword">return</span> _bootstrap._gcd_import(<span class="keyword">name</span>[<span class="keyword">level</span>:], <span class="keyword">package</span>, <span class="keyword">level</span>)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"&lt;frozen importlib._bootstrap&gt;"</span>, line <span class="number">1030</span>, <span class="keyword">in</span> _gcd_import</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"&lt;frozen importlib._bootstrap&gt;"</span>, line <span class="number">1007</span>, <span class="keyword">in</span> _find_and_load</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"&lt;frozen importlib._bootstrap&gt;"</span>, line <span class="number">986</span>, <span class="keyword">in</span> _find_and_load_unlocked</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"&lt;frozen importlib._bootstrap&gt;"</span>, line <span class="number">680</span>, <span class="keyword">in</span> _load_unlocked</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"&lt;frozen importlib._bootstrap_external&gt;"</span>, line <span class="number">850</span>, <span class="keyword">in</span> exec_module</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"&lt;frozen importlib._bootstrap&gt;"</span>, line <span class="number">228</span>, <span class="keyword">in</span> _call_with_frames_removed</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/ric-api/core/settings.py"</span>, line <span class="number">114</span>, <span class="keyword">in</span> &lt;<span class="keyword">module</span>&gt;</span><br><span class="line">    <span class="string">'PORT'</span>: env(<span class="string">'DB_PORT'</span>),</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/environ/environ.py"</span>, line <span class="number">123</span>, <span class="keyword">in</span> __call__</span><br><span class="line">    <span class="keyword">return</span> self.get_value(<span class="keyword">var</span>, <span class="keyword">cast</span>=<span class="keyword">cast</span>, <span class="keyword">default</span>=<span class="keyword">default</span>, parse_default=parse_default)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/usr/local/lib/python3.9/site-packages/environ/environ.py"</span>, line <span class="number">277</span>, <span class="keyword">in</span> get_value</span><br><span class="line">    <span class="keyword">raise</span> ImproperlyConfigured(error_msg)</span><br><span class="line">django.core.exceptions.ImproperlyConfigured: <span class="keyword">Set</span> the DB_PORT environment <span class="keyword">variable</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-14</span>T14:<span class="number">37</span>:<span class="number">17.6003172</span>Z stderr F</span><br><span class="line"></span><br><span class="line"><span class="keyword">Exception</span> <span class="keyword">in</span> <span class="keyword">thread</span> <span class="keyword">Thread</span><span class="number">-1</span>:</span><br><span class="line">Traceback (most recent <span class="keyword">call</span> <span class="keyword">last</span>):</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"threading.py"</span>, line <span class="number">932</span>, <span class="keyword">in</span> _bootstrap_inner</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"threading.py"</span>, line <span class="number">870</span>, <span class="keyword">in</span> run</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"D:\a\1\s\build_scripts\windows\artifacts\cli\Lib\site-packages\azure/cli/command_modules/container/custom.py"</span>, line <span class="number">837</span>, <span class="keyword">in</span> _stream_container_events_and_logs</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"D:\a\1\s\build_scripts\windows\artifacts\cli\Lib\site-packages\azure/cli/command_modules/container/custom.py"</span>, line <span class="number">791</span>, <span class="keyword">in</span> _stream_logs</span><br><span class="line">AttributeError: <span class="string">'NoneType'</span> <span class="keyword">object</span> has <span class="keyword">no</span> <span class="keyword">attribute</span> <span class="string">'split'</span></span><br></pre></td></tr></table></figure><p>Looks like I missed adding a <code>DB_PORT</code> to the environmental variables</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I have some container instances which are failing to start up properly and the logs in the portal are blank. This makes debugging them ki
    
    </summary>
    
    
  </entry>
  
</feed>
